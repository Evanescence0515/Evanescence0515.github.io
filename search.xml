<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>表格数据学习方法综述阅读(上)</title>
      <link href="/2025/05/28/Tabular-Review-1/"/>
      <url>/2025/05/28/Tabular-Review-1/</url>
      
        <content type="html"><![CDATA[<p>表格数据(tabular data)是日常生活中最常见的数据格式，为了挖掘表格数据中的有效信息，提出了很多相关的算法。这篇综述概括了表格数据的机器学习与深度学习方法，原文来自于南京大学LAMDA实验室中的<a href="https://github.com/LAMDA-Tabular">LAMDA-tabular课题组</a>，<a href="https://arxiv.org/abs/2504.16109">文章地址</a>。</p><h1 id="1-3"><a href="#1-3" class="headerlink" title="1-3"></a>1-3</h1><p>对于tabular data的一些简单介绍，略过</p><h1 id="4-特定方法的分类"><a href="#4-特定方法的分类" class="headerlink" title="4 特定方法的分类"></a>4 特定方法的分类</h1><p>作者将模型分为三类：特化方法(specialized methods), 迁移方法(transferable methods), 广义方法(general methods)。</p><h2 id="Specialized-method"><a href="#Specialized-method" class="headerlink" title="Specialized method"></a>Specialized method</h2><p>作者从3个角度入手讲述特化模型的方法：<br>Feature Aspect：特征角度来看，模型主要针对数据特征的关系进行建模。<br>Sample Aspect：从样本特征来看，模型通过最大化每个样本最邻近样本的作用来预测。<br>Objective Aspect：从客观角度，修改损失函数和整体目标(Overall objective)来引导模型特定的模式与偏好，注入inductive  bias(推断偏倚)。</p><h3 id="Feature-Aspect"><a href="#Feature-Aspect" class="headerlink" title="Feature Aspect"></a>Feature Aspect</h3><p>特征角度来看，模型主要针对数据特征的关系进行建模。<br>传统特征工程主要依赖于人手工设计特征，随着深度学习的进展，诸多特征相关的模型出现，例如特诊编码、选择、投影和交互。</p><h4 id="Feature-Encoding"><a href="#Feature-Encoding" class="headerlink" title="Feature Encoding"></a>Feature Encoding</h4><p>注意力机制让我们可以像自然语言处理中的词嵌入一样对于特征进行tokenization，将所有特征转变为嵌入。<br><strong>Categorical Encoding</strong><br>最主要使用的两种策略是序列编码(Ordinal Encoding)和独热编码(One-hot Encoding)。更加先进的编码方式还有Target Encoding，通过将该类的结局变量(target)的均值赋为该类的编码。该方法主要用于该变量与结局有很强的相关性。在留一法(Leave-one-out embedding)中，每个类都被赋予除了该变量的其他的结局均值。<br><strong>Numerical Encoding</strong><br><em>MLP-PLR</em>引入了2种数值编码方式：Piecewise Linear Encoding(PLE：分段线性编码) 和 Periodic Activation Function(周期性激活函数)。这两种方法可以与其他分类方法结合来提高表现。PLE基于特征分箱，为原始标量值生成了替代的初始表示。周期性激活函数考虑到：嵌入框架都是将所有特征独立处理，这让结合变量在嵌入过程中变得不可能。因此，周期激活函数会训练激活前的系数，而不仅仅是固定不变。<br><strong>Feature Tokenization</strong><br>它将特征转为embedding，因为特征表示是非常稀疏的，常用的方法就是将其转化为低维度表示(这里主要是将图片转为图特征向量)。<br>广义的特征tokenization可以被表示如下：<br>$$T_{i,j}&#x3D;b_{j}+\tau(x_{i,j};\Psi)\in \mathbb{R}^t$$<br>其中,$\tau(\cdot)$是特征分词器模块，将输入$x_{i} \in \mathbb{R}^d$转为嵌入$T_{i,j} \in \mathbb{R}^t$，$b_{j}$是第j个特征的偏倚，$\Psi$是可学习参数。<br><em>AutoInt</em>将分类变量和数值变量同时编码为低维度的变量。<em>TabTransformer</em>将每个分类变量手机用Column Embedding嵌入一个t维度的参数嵌入中。<em>SAINT</em>在传入 transformer编码器前，先将数值变量映射到一个t维的空间内。<em>FT-Transformer</em>使用了transformer架构。其中，数值变量使用了逐元素加法$T_{i}^{num}&#x3D;b_{i}^{num} + x_{i}^{num}W_{i}^{num}$；分类变量则使用了查表法$T_{i}^{cat} &#x3D; b_{i}^{cat} + e_{i}^TW_{i}^{cat}$，其中$e_{i}^T$是对应类的独热向量。</p><h4 id="Feature-Selection"><a href="#Feature-Selection" class="headerlink" title="Feature Selection"></a>Feature Selection</h4><p>高维度的数据常常会带来过拟合，模型过度关注无关的特征从而忽视了更加重要的特征，特征选择留下了最重要的特征避免过拟合。<br>传统树学习使用自动的特征选择来评估每个特征与结局之间的关联。决策树使用了基尼系数或者信息增益；随机森林使用了计算每个特征贡献度的方法；最近现代学习方法经常模拟树结构的方法来进行特征选取。<br><em>GrowNet</em>和<em>NODE</em>主要模仿了集成学习的方法，受GBDT启发，GrowNet设计了使用多个DNN构建多个弱学习器，每个学习器输入初始变量和前一层的输出；NODE使用可导遗忘决策树(Differentiable Oblivious Decision Tree)作为基学习器，在每层使用bagging和每个多层结构间使用stacking；为了让GAM(广义加性模型)可量化且高效，NODE-GAM将NODE改为GAM并允许GAM学习快速、非线性的跳跃以适应真实数据。<br><em>TabNET</em>和<em>GRANDE</em>更加关注树模型如何处理特征。TabNET不仅仅通过自监督学习保留了深度神经网络的表征学习能力，同时还融合了树模型的可解释性和稀疏特征选取能力；GRANDE认为树模型中的硬分裂(hard splits：某个特征的值满足条件就完全走一条路径)是深度模型的关键优势，并由此提出了一种利用梯度下降来学习硬、轴对称(axis-aligned：仅基于一个特征分裂，对立的是oblique split，需要结合多个特征进行分裂)的树集成模型，将轴对称分裂带来的有效归纳偏差与梯度下降优化带来的灵活性结合。</p><h4 id="Feature-Projection"><a href="#Feature-Projection" class="headerlink" title="Feature Projection"></a>Feature Projection</h4><p>特征映射旨在将特征转为中间形式，加强表达能力。特征映射可被分为两类：MLP变体和专门设计的架构。这些方法旨在加强模型对于复杂特征的表达能力：<br><strong>MLP Variant</strong>：<em>RTDL</em>研究了类似Resnet和基于transformer架构的模型，提出了简单但是有效的调整，尤其是MLP架构，其使用了多个包含线性层、ReLU激活函数和Dropout的块的堆叠，这将原始特征转为了固定维度的潜在表征，最终一个线性层作为分类头。这篇文章强调：如果有合理的超参数，简单的MLP和ResNet也能达到benchmarks。<br>另外一个同期的研究通过给MLP装备了一组正则化现代套件。通过多种正则方法的堆叠，形成了一种正则化鸡尾酒的方法。这个研究揭示了两种重要发现：1) 原版MLP(vanilla MLP: 有趣的是vanilla有”香草”的意思)通过正则化可以超过许多为面板数据设计的特化的、现代的神经网络架构；2) 这样的MLP甚至可以超过XGBoost。<em>RealMLP</em>探索了包括预处理、超参数调参、架构、正则化和初始化的多个角度。<br><strong>Special Designed Architectures</strong>：对于单元，受到归一化方法容易导致干扰，<em>SNN</em>提出了SELU(Scaled Exponential Linear Unit)；<em>NAMs</em>使用ExU(exp-centered hidden units)来提升对于跳跃函数(jumpy function)的学习能力；<em>BiSHop</em>使用双组分方法(dual-component approach：指的是一种将<strong>两个主要部分、机制或因素</strong>结合起来解决问题、建模、分析的策略。它体现的是“<strong>两个互补或协同的部分</strong>共同作用”。)使用两个有方向性、彼此连接的学习模块按顺序评估数据的行和列，他使用了现代Hopfield层</p><h4 id="Feature-Interaction"><a href="#Feature-Interaction" class="headerlink" title="Feature Interaction"></a>Feature Interaction</h4><p>广义形式可以表示为:<br>$$\hat{y_{i}} &#x3D; f(\mathcal{H}(x_{i}; \Theta))$$<br>其中$x_{i} \in \mathbb{R}^d$是输入向量，$\mathcal{H}(\cdot)$为特征交互模块，提取输入的特征依赖性并产生高维度的特征交互项；$f(\cdot)$是预测头。<br>特征交互可以被广泛的分为两类：自动交互模块的设计和潜在交互的挖掘。这些方法旨在加强模型学习复杂交互项和潜在特征结构的能力。<br><strong>Automatic Feature Interaction Modules</strong>：这些方法并不假设特定的特征类型，相仿，其关注提高模型中特征交互过程，让模型可以学到复杂且高维度的特征相关性。<em>DCNv2</em>通过Cross Network架构，它使用低秩方法(low-rank methods: 将高维度的参数矩阵$W \in \mathbb{R}^{d\times d}$化为两个低维度的矩阵$U,V \in \mathbb{R}^{d\times r}, W &#x3D; UV^\mathbf{T}$，以避免过拟合，非常有趣的方法，如果看过transformer的架构就会发现: <em>transformer在embedding的过程中input embedding和output embedding共用矩阵，这其实也是一种降低过拟合的方法</em>)在子空间中近似特征交叉(feature crosses:指的是将多个原始特征组合起来，比如将“性别 + 年龄”合成一个组合特征)，然后通过门控机制将这些子空间融合.<em>AutoInt</em>将原始稀疏的高维度特征向量(例如one-hot之后的类别)转为低维度空间并通过注意力机制将交互层堆叠(就是对于每个样本进行注意力操作)；不像AutoInt，<em>TabTransformer</em>只将类别变量嵌入内容嵌入，数值特征直接与交互后的上下文嵌入向量进行拼接。当只有数值变量时，其表现得像MLP，只有分类变量时，其表现得像AutoInt.<br><em>DANets</em>提出了表格数据中潜在特征组的存在，在每个特征组内的特征是相互之间相关的。它学习将特征分组并进行进一步的特征抽象；<em>SwitchTab</em>提出了一种思想：在表格特征中提取样本特异性的显著特征和样本共享的互信息(Mutual Information)；<em>ExcelFormer</em>认为DNN为每个特征赋予了一个权重，这会让模型纳入无关变量，为了解决这个问题，它引入了用于特征交互的“半透性注意力”(Semi-Permeable Attention)，这样可以让有较少信息的特征从有更多信息的模型中获取信息，同时避免高信息特征受到低信息特征的干扰。<em>AMFormer</em>提出了一种假说：算数特征交互项对于深度表格模型是重要的，基于Transformer架构，它提出了为了提取加性和乘性交互项的组件。</p><h3 id="Sample-Aspect"><a href="#Sample-Aspect" class="headerlink" title="Sample Aspect"></a>Sample Aspect</h3><p>从样本特征来看，模型通过最大化每个样本最邻近样本的作用来预测。<br>广义的模型公式可以表示如下：<br>$$<br>\hat{y_{i}}&#x3D;f(\mathcal{R}(x_{i}, \mathcal{D}; \Phi))<br>$$<br>其中，$\mathcal{D}$为所有样本的集合，$\mathcal{R}(\cdot)$是样本交互模块。$\Phi$是$\mathcal{R}$的可学习参数。$f(\cdot)$是预测头，用于将特征转为最终的输出。<br>样本角度可以被简单分为两个主要策略，第一个策略通过representation training(表征学习)学习样本特征之间的关系；第二个策略使用“基于检索的模型”(Retrieval-based model)通过如何检索并使用临近样本的作用。<br><strong>Sample Interaction</strong>：这个方法通过在表征学习过程中，使用样本间的相关性来训练得到一个更加鲁棒的表征。在训练过程中，因为没有交互，所有模型会变得更加敏感。<br><em>SAINT</em>引入样本间的attention而不仅仅是属性间的attention，提高了行分类的准确率；<em>NPT</em>将其扩展为非参数Transformer，而Hopular使用了Hopfield网络，这与SAINT其实是本质上相同的。Trompt认为特征的重要性在不同样本中是不同的，在特征提取过程中，它将样本之间的信息作为prompts。<em>PTaRL</em>识别了在表格数据中的两种情况：纠缠与局部化，并使用原型生成(prototype generation)和表示投影(representation project)来产生更加清晰且一致的决策。<br><strong>Neighbor Retrieval</strong>：这种方法构造了高质量的内容来帮助提取有价值的邻居，并找到高效的方法来利用他们之间的关系。训练样本被用于协助测试。<em>DNNR</em>向KNN中引入本地梯度估计和Taylor多项式逼近；<em>TabR</em>将所有候选样本编码并使用类注意力机制来检索样本。<em>ModernNCA</em>使用了传统NCA方法并引入了深度学习策略与架构。<br><em><strong>有趣的是，作者在这里留下了一段话：目前的基于近邻的方法类似于in-context learning(上下文学习)，尤其是最近的TabPFN；LoCalPFN也使用了本地回归来获取更有解释性的决策边界，这也正是使用了本地信息。</strong></em></p><h3 id="Objective-Aspect"><a href="#Objective-Aspect" class="headerlink" title="Objective Aspect"></a>Objective Aspect</h3><p>从客观角度，修改损失函数和整体目标(Overall objective)来引导模型特定的模式与偏好，注入inductive  bias(推断偏倚)。<br>就像L1-正则化(LASSO)、L2-正则化(Ridge)，Objective-aspect methods在深度学习中是这些传统方法的拓展，通过修改损失函数和正则化因子获取推断偏倚。这里Objective Aspect又可以分为两类，一类是Training Objective可以用特化能力来增强模型，另一类则引入正则化因子，增强模型的泛化能力。<br><strong>Training Objective</strong>：<em>PTaRL</em>构建了原型生成的投影空间并学习了全局原型的解耦表征。使用了一个多样性约束（diversification constraint），用于校准表示（representation calibration）并引入了一个矩阵正交化约束（matrix orthogonalization constraint），以保证不同原型之间的独立性（independence）。<br><strong>Training Regularization</strong>：<em>RLNs</em>通过在训练过程中引入了高效调参方案克服了难以驾驭的超参数，这种方法最小化一种特别的反事实损失。RLNs中，正则化因子与模型参数同时被优化并最终得到一个稀疏的网络。<em>TANGOS</em>使用了基于正则化的提升方法，它通过正则化神经元属性来保证神经元特化且正交。<em>Regularization cocktails for MLPs</em>通过特定数据集合的13种正则化方法，能让简单的神经网络效果大大提升，甚至超过树学习模型(XGboost)</p><h1 id="5-从特化模型到迁移模型-From-specialized-to-transferable-model"><a href="#5-从特化模型到迁移模型-From-specialized-to-transferable-model" class="headerlink" title="5 从特化模型到迁移模型(From specialized to transferable model)"></a>5 从特化模型到迁移模型(From specialized to transferable model)</h1><p>从头训练一个模型会非常困难，取而代之的是训练一个预训练的模型(PTM: Pre-Training Model)。<br>使用预训练模型主要分为两个阶段：1. 表格模型的预训练；2.根据下游任务使用特定的适应策略来训练模型。正式的说，一个well-trained模型$g_{\Theta}$可以被用于加速$\mathcal{D}$上的模型$f_{\theta}$。为了使用$g_{\Theta}$中的专业信息，一种适应策略被使用：$f_{\theta}&#x3D;\mathbf{Adapt}(f_{\theta_{0}} | \mathcal{D}, g_{\Theta})$其中$\theta_{0}$是模型的初始化。这种标注可以被拓展到PTM之外。使用PTM的挑战在于将PTM与表格模型相关联。基于PTM的来源，我们将PTM分为3种类型：<br><strong>Homogeneous Transferable Tabular Model</strong>：同质性迁移模型，PTM可能与表格模型共享相同的任务，但是却有不同的分布，即$Pr(\mathcal{D}’) \neq Pr(\mathcal{D}) \space or \space g \neq f$<br><strong>Heterogeneous Transferable Tabular Model</strong>：异质性迁移模型，任务不同。<br><strong>Cross-Modal Transferable Tabular Model</strong>：跨模态迁移模型，PTM可以是另外一种模态，比如视觉或者语言模型，比如属性的语义学信息，就是将大语言模型作为PTM用以提供潜在的语义学信息。<br><strong>迁移模型的好处与坏处</strong>：好处：加速收敛、减少数据量、减少可学习参数量，减少计算量和调参量。</p><h2 id="Homogeneous-Transferable-Tabular-Model"><a href="#Homogeneous-Transferable-Tabular-Model" class="headerlink" title="Homogeneous Transferable Tabular Model"></a>Homogeneous Transferable Tabular Model</h2><p>这方面研究在深度学习时代之前便已出现，一个代表性的方法就是有偏正则化(biased regularization：在深度学习和机器学习中引入先验偏好或结构性偏差的正则化技术，其核心目的是引导模型朝特定方向学习，而不仅仅是防止过拟合)，通过最小化PTM和目标模型的差别：<br>$$\min_{W}\mathscr{l}(W)+|W-W’|<em>{F}^2&#x3D;\min</em>{\Delta W}\mathscr{l}(\Delta W+W’)+|\Delta W|_{F}^2$$<br>对于相似的模型，可以通过修改训练目标为权重残差。对于MLP，可以通过比较两者的预测结果。<br><strong>Supervised Pre-training Objectives</strong>：一种将目标变量融入预训练的方法是使用输入干扰(例如对于某变量遮蔽后训练)作为一种对于标准监督学习目标的增强方法。<br><strong>Self-Supervised Pretraining Objectives</strong>：自监督预训练目标包括：masked language model, contrastive pre-training, hybrid method. <strong>masked language model(MLM)</strong>，无监督训练目标，每个样本中随机的特征会被遮蔽，遮蔽的值会通过多目标分类方法来预测。<em>VIME</em>使用干扰的表格数据预测哪部分向量被遮掩并试图为自监督学习重新构建特征向量。他们通过使用已经训练的编码器为每个样本产生多个增广的样本，具体方法就是1.对于每个样本使用多种遮蔽方法，2.然后使用模型对遮蔽的特征进行填充以恢复该值以实现数据的增强和表示学习。<em>SubTab</em>发现通过特征子集重构数据效果会比使用具有干扰的数据更好地捕捉潜在表示。<em>SEFS</em>通过随机选取输入特征重构初始的输入并同时估计用以定义哪个特征被选中的阈值向量(gate vector)。<em>MET</em>使用所有特征表征的连接代替平均，并使用对抗重建损失(Adversarial reconstruction loss：一种类似于GAN的损失函数，由重建损失和对抗损失组成，前者就是常见的损失，后者则是判别器判断重建数据是否真实的损失)；<strong>Contrastive Pre-training</strong>，对比预训练使用数据增广来生成正样本对或者同一个样本的两个不同的增广视图，损失函数鼓励一个特征提取器将正样本对映射为相似的特征。对比学习的主要因素就是产生特定案例的正例样本和负例样本。<em>SCARF</em>会为每一个输入样本生成一个增强版本，他的方式是从样本所有特征中随机选出一部分特征，并将这些选中的特征值替换为该特征的边缘分布中随机抽取的值；<em>STab</em>依赖于多个权重共享的神经网络，通过利用停止梯度操作，可以通过更加复杂的正则化策略来学习特征中的不变性，避免了崩溃到平凡解(即所有样本的表示均相同)；<em>DoRA</em>通过样本间的前置任务(pretext task)和样本间的对比学习来学习上下文化表示(Contextualized representations)；<em>DACL+</em> 为了克服对于特定领域的依赖，使用Mixup噪声来产生相似和不相似的样本。<strong>Hybrid Methods</strong>：结合了多种方法，包括有监督的、无监督的。<em>LFR</em>通过同时重构多个随机生成映射函数来训练；<em>ReConTab</em>同时使用自监督学习和半监督学习，它使用了正则化方法来筛选变量，同时使用有标签的对比学习来蒸馏最相关的信息用以下游任务。</p><h2 id="Heterogeneous-Transferable-Tabular-Model"><a href="#Heterogeneous-Transferable-Tabular-Model" class="headerlink" title="Heterogeneous Transferable Tabular Model"></a>Heterogeneous Transferable Tabular Model</h2><p>早期的异质性模型主要关注特征级别的异质性，一个主要的假设是：存在一部分特征是相同，另外一部分特征不同，我们可以利用那部分相同特征的权重。主要工作有<em>OPID</em>，<em>ReForm</em>。神经模型的有点就是我们可以很轻松的调参(fine-tuned)，我们可以冻结大部分的参数，只关注少部分的参数(例如分类头)来加速调参并减少过拟合。<br><strong>Reuse PTM Pre-trained from One Dataset</strong>：这种方法主要关注预训练模型和目标任务的数据集之间的不同。<br><strong>Reuse PTM Pre-trained from Multiple Datasets</strong>：<em>XTab</em>通过利用独立特征（independent features）和联邦学习（federated learning）来预训练共享组件（shared component）。</p><h2 id="Reusing-a-Pre-trained-Language-Model"><a href="#Reusing-a-Pre-trained-Language-Model" class="headerlink" title="Reusing a Pre-trained Language Model"></a>Reusing a Pre-trained Language Model</h2><p>标准情况下，有两种类型的语义学信息可以被使用：第一，每个特征的属性名称，$\mathcal{A}&#x3D; A_{1}, \dots, A_{d}$；第二，meta-information例如文本描述，被记录为”meta_descript”可以进一步增加理解，学习过程可以被公式化为:<br>$$\hat{y_{i}}&#x3D;f(x_{i}, \mathcal{A}|\mathcal{D},\mathbf{meta_{descript}})$$<br>这里语义学信息作为连接特征空间的桥梁和促进从预训练模型向下游任务知识迁移的工具。<br><strong>Language Models for Feature Tokenization</strong>：当特征空间改变时，语言学方法假设语义学关联性在特征描述之间存在且依赖于大语言模型捕捉这些关联的能力。例如，特征“occupation”和特征”organization”之间存在语义学关联，这使得这个特征可以被反复使用。<br><em>TransTab</em>根据表格数据中存在的词语训练一个分词器，并将列描述和表格作为输入，输入到一个门控transformer模型，这个模型时通过自监督学习或者有监督对比学习来训练的，并在迁移任务与特征连续学习的任务中验证；<em>PTab</em>使用一种相似的方式，使用多个被分词后的表格数据学习上下文表示；<em>UniTabE</em>编码并融合来自于列名称、数据类型和单元格值的信息并转化为一系列的tokens，使用Transformer与LSTM的编码器-解码器的架构。它使用了多单元格遮盖与对比学习进行预训练，在这里一个样本的子向量被当作正样本，其他样本或者其他样本的子集被作为负样本。<em>CM2</em>使用了一种提出了一个跨表格的预训练框架，能够整合属性名称与特征值。它使用了pMTM(prompt-based Masked Table Modeling)自监督目标，列名被作为prompt来帮助预测遮掩的特征；<em>TP-BERTa</em>按照类似的方法，但是加上了数值离散化策略、数量级标记化和微调更小的预训练语言模型(RoBERTa)；<em>CARTE</em>使用图注意力机制，关注列名和近邻输入，使用对比学习并构建了graphlet(图中所有不同构的子图)。<br><strong>Language Models for Features Engineering</strong>：<em>Binder</em>识别模型无法直接回答的问题并使用LLMs产生辅助特征；<em>CAAFE</em>探索使用LLMs，基于任务语义和特征语义进行生成，并用 TabPFN 来评估这些特征的质量；<em>FeatLLM</em>使用基于样本的prompting来加强特征生成，让LLMs有能力产生新的特征；<em>TaPTaP</em>为了捕捉广义表格数据中的数据分布，在大规模语义库中进行训练。训练完成后，可用于生成高质量的合成表格数据。<br><strong>Language Models for Textual Serialization</strong>：使用预训练语言模型的直接方法包括将表格数据转化为文本数据，让LLMs可以直接推断特征与标签之间的关系。<em>LIFT</em>、<em>TabLLM</em>、<em>UniPredict</em>。但是文本序列化方法依旧存在许多挑战，比如特征数过多时可能造成prompt过长、受限于语义学信息的可用性和外部模型能力。</p><h2 id="Reusing-a-Pre-trained-Vision-Model"><a href="#Reusing-a-Pre-trained-Vision-Model" class="headerlink" title="Reusing a Pre-trained Vision Model"></a>Reusing a Pre-trained Vision Model</h2><p>最主要的挑战在于：将表格数据转化为图像。在自然图片中，临近的像素经常有相同的语义学相关性，但是表格数据缺少这种空间结构。同时，表格数据的特征是插入不变性，意味着交换顺序不会影响样本的意义(有些类似于图神经网络)。<br><strong>Dimensionality Reduction Transformation</strong>：<em>DeepInsight</em>使用t-SNE将表格数据转入2D空间并通过凸包分析、旋转等方法构建图片；<em>REFINED</em>使用贝叶斯度量多维度放缩来保证样本在低维度表征中的距离以维持结构相似的模型依旧保有最近的关系。<br><strong>Table Reorganization Transformation</strong>：表格数据库可以被当作一个矩阵。<em>TAC</em>使用CNN；<em>ICTD</em>和<em>TablEye</em>有相同的思路，产生一个图像，其中像素点暗度对于特征值。<br><strong>Image Marker Transformation</strong>：将特征值编码为可视的标记。例如<em>Super-TML</em>、<em>Tab2Visual</em>。<br>通过将表格数据转为图像，这些方法可以让强大的图像处理模型用于表格数据。<br>最近时间有些紧张，因为已经进入考试月了(悲),所以先写一半，剩余部分有空再写吧(希望有时间)。</p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GNN</title>
      <link href="/2025/05/10/GNN/"/>
      <url>/2025/05/10/GNN/</url>
      
        <content type="html"><![CDATA[<p>图是我们身边非常常见的结构，最近的一些研究让我们能够使用图结构的优势，在许多领域，如抗生素的研究、物理仿真、虚假新闻的识别，交通预测和推荐系统都有了最新的研究与实践。<br>这篇学习&#x2F;总结博客参考了biliili上<a href="https://www.bilibili.com/video/BV1iT4y1d7zP">李沐</a>的带读以及<a href="https://distill.pub/2021/gnn-intro/">A Gentle Introduction to GNN</a><br>这篇文章探索并解释了现代图神经网络，我们将工作分为4个部分：1. 什么类型的数据可以以图的形式记录；2. 图结构的特点与优势：相较于CNN或者传统深层神经网络；3. 建造一个GNN模型：从一个骨架到SOTA；4. 提供一个GNN playground供读者探究(会超链接回原文章)。</p><h1 id="What-a-Graph-is"><a href="#What-a-Graph-is" class="headerlink" title="What a Graph is"></a>What a Graph is</h1><h2 id="图是一系列实体之间的关系"><a href="#图是一系列实体之间的关系" class="headerlink" title="图是一系列实体之间的关系"></a>图是一系列实体之间的关系</h2><p>如果我们用图论的知识来看，图的描述其实有多种方式，如：邻接矩阵、集合的表示。我们这里采用相对容易接受的集合表示方法：<br>一个图主要由 <strong>节点(Nodes)</strong> 和 <strong>边(Edges)</strong> 构成。以下图为例：其中存在5个节点，与6条边。<br><img src="/2025/05/10/GNN/graph_demo.png" alt="graph_demo" title="graph_demo"><br>其中点集合为$V &#x3D; { A,B,C,D,E }$。边集合为$E &#x3D; { AB, BC,CD,DE,AE, CE }$上图边为无向的，所以也被称为无向图(有向图); 又因为没有重复边，所以被称为简单图；上图可以通过集合套集合的方法表示，即$G&#x3D; { V,E }$<br>由于篇幅问题，我们仅仅引入简单的概念，图论是一个非常庞大的研究方向，如果对图论与图相关算法感兴趣，可以查看<a href="https://oi-wiki.org/graph/">图论相关博客</a></p><h2 id="GNN中的图"><a href="#GNN中的图" class="headerlink" title="GNN中的图"></a>GNN中的图</h2><p>有趣的是，在GNN中，每个节点与边并不是我们想象的用单个数字代表其权重，而是通常由一个向量表示，我们称其为embedding(嵌入)<br>此外，在V,E之外，还有一个全局嵌入(U)，其表示的是图中的边数与点数。</p><h2 id="可以转化为图的数据"><a href="#可以转化为图的数据" class="headerlink" title="可以转化为图的数据"></a>可以转化为图的数据</h2><ol><li>化学分子</li><li>图像(像素为节点)</li><li>文本(词语为节点)</li><li>社交网络</li></ol><h2 id="图解决的问题"><a href="#图解决的问题" class="headerlink" title="图解决的问题"></a>图解决的问题</h2><h3 id="图层面"><a href="#图层面" class="headerlink" title="图层面"></a>图层面</h3><p>寻找图中的环</p><h3 id="点层面"><a href="#点层面" class="headerlink" title="点层面"></a>点层面</h3><p>将一个图分为两张图</p><h3 id="边层面"><a href="#边层面" class="headerlink" title="边层面"></a>边层面</h3><p>学习社交网络中的关系(关系抽取)</p><h1 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h1><p>GNN是对图上所有的属性(边、点、全局属性)进行可优化的变换，这个变换依旧保持图的对称性。”graph-in, graph-out”输入是图，输出是图，修改图的属性但是不影响图片的联通性(不影响结构)</p><h2 id="最简单的GNN"><a href="#最简单的GNN" class="headerlink" title="最简单的GNN"></a>最简单的GNN</h2><p>对于点、边、全局向量输入MLP得出新的点、边、全局变量<br><em>例如：判断图中顶点属于1还是属于2，就是对于顶点中每个点的向量输入MLP并输出一个softmax的结果：1 or 2</em><br>如果点、边向量不存在，则需要通过pooling(池化？)来根据该点的附近点、边向量获得该点的向量。</p><h2 id="信息传递"><a href="#信息传递" class="headerlink" title="信息传递"></a>信息传递</h2><p>但是，我们很容易就会发现，这样的GNN对于图信息的利用效率其实是很低的：我们没有用到图中点与点之间的关系，而是简单的用3个独立MLP进行了向量的更新。<br>所以我们提出了<strong>信息传递</strong>的思路</p><ol><li>最简单的信息传递就是汇聚，将一个点的向量和与其相连的所有点的向量相加后再输入MLP内进行更新，这样就可以用到点的邻接关系了。<em>类似于卷积操作，但是这里的卷积权重均为1，且每次卷积就是对于每个点进行求和</em></li><li>那我们考虑，能不能把边的信息也纳入其中？所以可以首先把顶点的向量传入边，然后再把边的信息传入点。</li><li>但是到现在都没有用到全局信息，为了使用全局信息，我们会加入一个master node(context vector)，这就是U，其与所有边和点相连。所以在更新点与边的时候，会利用到U；同时，在更新U的时候也会使用边与点的信息。</li></ol><h1 id="Playground"><a href="#Playground" class="headerlink" title="Playground"></a>Playground</h1><p><a href="https://distill.pub/2021/gnn-intro/">A Gentle Introduction to GNN</a></p><hr><p>Cover image icon by <a href="https://www.flaticon.com/authors/becris" title="Becris">Becris</a> from <a href="https://www.flaticon.com/free-icons/deep-learning" title="deep learning icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>因果推断初步——反因果框架</title>
      <link href="/2025/05/10/CausalInferenceIntro/"/>
      <url>/2025/05/10/CausalInferenceIntro/</url>
      
        <content type="html"><![CDATA[<p>在这篇文章中，你将会了解到：什么是bias，为什么我们在研究中存在bias，以及如何消除bias。<br>We sometimes call the potential outcome that happened, factual, and the one that didn’t happen, counterfactual.<br>$Y_{0i}$ is the <strong>potential</strong> outcome for unit i without treatment, it can also be written as $Y_{i}(0)$<br>$Y_{1i}$ is the <strong>potential</strong> outcome for unit i with treatment, it can also be written as $Y_{i}(1)$<br>we define the <strong>individual effect</strong> as $Y_{1i}-Y_{0i}$ , which can not be accumulated for the counterfactual. so we can only accumulate <strong>Average treatment effect</strong> which is also denoted as <strong>ATE</strong>:<br>$$ATE &#x3D; E[Y_{1}-Y_{0}]$$<br>we can also estimate <strong>Average treatment effect on the treated</strong> which is also called <strong>ATT</strong><br>$$ATT&#x3D;E[Y_{1}-Y_{0}|T&#x3D;1]$$</p><h1 id="Bias"><a href="#Bias" class="headerlink" title="Bias"></a>Bias</h1><p>$$\begin{aligned}<br>E[Y|T&#x3D;1]-E[Y|T&#x3D;0]&amp;&#x3D;E[Y_{1}|T&#x3D;1]-E[Y_{0}|T&#x3D;0]<br>\\&amp;&#x3D;E[Y_{1}|T&#x3D;1]-E[Y_{0}|T&#x3D;0] + E[Y_{0}|T&#x3D;1] - E[Y_{0}|T&#x3D;1]<br>\\&amp;&#x3D;E[Y_{1}-Y_{0}|T&#x3D;1]+E[Y_{0}|T&#x3D;1]-E[Y_{0}|T&#x3D;0]<br>\end{aligned}$$<br>以上公式中，前者为ATT也就是我们所希望估计的, 后者为Bias<br>也就是说相关性&#x3D;ATT+Bias。<br>if $E[Y_{0}|T&#x3D;1]&#x3D;E[Y_{0}|T&#x3D;0]$<br>then <strong>assosiation &#x3D; causation</strong><br>furthermore, if we assume that the untreated and the treated only differ in the treatment itself, we can conclude that:<br>$$E[Y|T&#x3D;1]-E[Y|T&#x3D;0]&#x3D;E[Y_{1}-Y_{0}|T&#x3D;0]&#x3D;E[Y_{1}-Y_{0}|T&#x3D;1]$$<br>which means <strong>ATT&#x3D;ATE</strong><br>To eliminate bias, we should <strong>Randomized Trial</strong></p><hr><p>Thanks for watching! and this my learning note of the blog of <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>.<br>感谢观看，这是我学习<a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>博客的笔记。<br>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 因果推断 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 因果推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循证医学9-12周回顾</title>
      <link href="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="非参数检验"><a href="#非参数检验" class="headerlink" title="非参数检验"></a>非参数检验</h1><h2 id="非参数检验的适应条件"><a href="#非参数检验的适应条件" class="headerlink" title="非参数检验的适应条件"></a>非参数检验的适应条件</h2><ol><li>等级顺序资料</li><li>偏态资料</li><li>未知分布资料</li><li>各组资料的变异度大，方差不齐，变换也不能达到齐性</li><li>数据一端或两端有不确定值的资料</li><li>初步分析<br><em>可以举几个例子：1. 不满足参数检验的要求；2. 血糖水平高于最高值会显示high</em></li></ol><h2 id="非参数检验的缺点"><a href="#非参数检验的缺点" class="headerlink" title="非参数检验的缺点"></a>非参数检验的缺点</h2><p>容易出现第II类错误，即假阴性概率增大，本应显示出显著性差异的结果但是却并没有出现显著性差异。</p><h2 id="两组配对设计资料的比较"><a href="#两组配对设计资料的比较" class="headerlink" title="两组配对设计资料的比较"></a>两组配对设计资料的比较</h2><p>Wilcoxon符号秩和检验</p><ol><li>符号检验</li><li>配对设计差值的符号秩检验：其实就是对差值进行符号检验</li></ol><h2 id="单样本资料的符号秩和检验"><a href="#单样本资料的符号秩和检验" class="headerlink" title="单样本资料的符号秩和检验"></a>单样本资料的符号秩和检验</h2><p>Wilcoxon符号秩和检验。对标单样本正态检验</p><h2 id="成组设计两样本比较的秩和检验"><a href="#成组设计两样本比较的秩和检验" class="headerlink" title="成组设计两样本比较的秩和检验"></a>成组设计两样本比较的秩和检验</h2><p>Wilcoxon秩和检验</p><h2 id="成组设计多个样本比较的秩和检验"><a href="#成组设计多个样本比较的秩和检验" class="headerlink" title="成组设计多个样本比较的秩和检验"></a>成组设计多个样本比较的秩和检验</h2><p>Kruskal Wallis H检验</p><h3 id="原始数据的多个样本比较"><a href="#原始数据的多个样本比较" class="headerlink" title="原始数据的多个样本比较"></a>原始数据的多个样本比较</h3><p>对标参数检验中的ANOVA，用于揭示多组数据的中位数是否完全相同</p><h3 id="多个样本两两比较的秩和检验"><a href="#多个样本两两比较的秩和检验" class="headerlink" title="多个样本两两比较的秩和检验"></a>多个样本两两比较的秩和检验</h3><p>对标参数检验中的SNK-Q, LSD-T检验</p><h1 id="回归与相关"><a href="#回归与相关" class="headerlink" title="回归与相关"></a>回归与相关</h1><p>回归与相关并不相同，从概念上讲，相关其实是一种双重映射，而回归是单射。从直觉上讲，相关其实是一个相对模糊的概念，并不具有因果性，而回归其实是显示出一种简单的因果性：是自变量的改变会导致因变量改变程度的一种反映。</p><h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2><h3 id="回归方程"><a href="#回归方程" class="headerlink" title="回归方程"></a>回归方程</h3><p>$$Y &#x3D; \alpha +\beta X + \epsilon$$<br>$\alpha$：回归直线的截距<br>$\beta$：回归直线的斜率，又称为回归系数<br>$\epsilon$：误差项，在线性回归中我们认为其满足均值为0，方差为1的假设，所以在完成线性回归后我们将会对其进行残差检验，以研究其是否满足我们的前提。</p><h3 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h3><h4 id="F检验"><a href="#F检验" class="headerlink" title="F检验"></a>F检验</h4>$$\begin{aligned}\sum(Y-\bar{Y})^2 &= \sum((\hat{Y}- \bar{Y}) + (Y - \hat{Y}))^2 \\&=\sum(\hat{Y} - \hat{Y})^2 + \sum(Y - \hat{Y})^2\end{aligned}$$<p>$Y$：真实值<br>$\hat{Y}$：预测值<br>$\bar{Y}$：均值</p>$$F = \frac{MS_{回归}}{MS_{误差}}=\frac{\frac{SS_{回归}}{\nu_{回归}}}{\frac{SS_{误差}}{\nu_{误差}}}$$<p>其中$\nu_{总}&#x3D;n-1, \nu_{回归} &#x3D; 1, \nu_{误差} &#x3D; n-2$</p><h4 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h4><p>回归系数的区间估计</p>$$b \pm t_{\frac{\alpha}{2},n-2}S_{b}, S_{b}=\sqrt{ \frac{MS_{误差}}{l_{XX}} }$$<p>均值的区间估计</p>$$\hat{Y}\pm t_{\frac{\alpha}{2},n-2}S_{\hat{Y}}, S_{\hat{Y}}=S_{YX}\sqrt{ \frac{1}{n} + \frac{(X_{0}-\hat{X})^2}{\sum(X-\bar{X})^2}}$$<p>其中$l_{XX}=\sum(X-\bar{X})^2, S_{YX}=\sqrt{ \frac{\sum(Y-\hat{Y})^2}{n-2} }=\sqrt{ \frac{SS_{剩}}{n-2} }$<br>个体Y值的容许区间</p>$$\hat{Y}\pm t_{\frac{\alpha}{2},n-2}S_{Y}, S_{Y}=S_{YX}\sqrt{ 1 + \frac{1}{n} + \frac{(X_{0}-\hat{X})^2}{\sum(X-\bar{X})^2}}$$<h3 id="残差分析"><a href="#残差分析" class="headerlink" title="残差分析"></a>残差分析</h3><p>线性回归模型满足以下四个前提要求：线性、独立、正态性、等方差。<br>这里线性的条件很容易理解；对于独立的条件，其实就是为了避免样本之间的相关性，例如我们要研究药物浓度与时间的关系，但是样本中存在相同人的不同时间的样本，那可能会出现该人的某个时间段的检查数值与之前某个时间的检查数值相关。那么我们在进行回归的时候会发现，如果前一个时间段浓度高，该时间段浓度也会高。也就意味着，有一部分的误差并不能通过对于时间的回归来解释，这里我们需要使用<strong>时间序列分析</strong>以最大化对于不同时间段相同人的数据的利用率。<br>正态性与等方差性则是进行线性回归的前提，如果不满足则优化的方法其实是有问题的。<br>为了验证以上4个前提，我们常使用残差分析。<br>残差分析我们可以认为是<strong>线性回归的粪便检查</strong>，线性回归完成后我们需要研究<strong>回归后还剩下什么</strong>，残差就是回归后的边角料，如果边角料中存在很明显的趋势，那我们就不能丢弃这一部分的数据，我们仍然需要进一步挖掘。而这一趋势其实就是数据不满足以上线性回归四前提的实际体现。所以也可以认为，线性回归的能力(消化能力)其实并不强，一但数据复杂度增高(消化难度增加)，就难以继续使用线性回归挖掘数据(消化并吸收营养)，所以需要进行残差回归以确定线性回归可以充分利用该数据。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>线性回归不能外推、要有实际意义、<strong>要先绘图</strong>(非常重要，这是线性回归乃至后面的时间序列分析、断点回归、样条插值的必需前提)、要假设检验(应该不会有人忘记，因为软件自动进行)</p><h2 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h2>$$r = \frac{\sum(X-\bar{X})(Y-\bar{Y})}{\sqrt{ \sum(X - \bar{X})^2\sum(Y-\bar{Y})^2 }}=\frac{l_{XY}}{\sqrt{ l_{XX}l_{YY} }}$$<p>大部分类似于回归</p><h2 id="秩相关"><a href="#秩相关" class="headerlink" title="秩相关"></a>秩相关</h2><p>适用于：不满足双变量正态分布、总体分布未知、等级表示的原始数据</p><h2 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h2><p>类似于线性回归</p><h2 id="筛选自变量"><a href="#筛选自变量" class="headerlink" title="筛选自变量"></a>筛选自变量</h2><p>后退法、前进法、逐步法<br>这里筛选自变量其实还有一个很重要的原因，就是可能原来不显著的结果在筛选变量后变得显著。</p><h1 id="重复测量资料的方差分析"><a href="#重复测量资料的方差分析" class="headerlink" title="重复测量资料的方差分析"></a>重复测量资料的方差分析</h1><p>重复测量实验能不能进行普通的成组检验(参数或非参数)？答案是否定的，因为不管是参数与非参数检验均需要保证样本之间的独立性和随机性，但是重复测量的数据一定有相关性。<br>为了避免时间因素，所以需要同时考虑分组与重复测量的时间点.</p><h2 id="随机区组设计方差分析法"><a href="#随机区组设计方差分析法" class="headerlink" title="随机区组设计方差分析法"></a>随机区组设计方差分析法</h2><p>前提：满足“球对称”假设</p><h3 id="重复测量数据的两因素两水平分析"><a href="#重复测量数据的两因素两水平分析" class="headerlink" title="重复测量数据的两因素两水平分析"></a>重复测量数据的两因素两水平分析</h3><p>当前后差值不满足方差齐性时。进行重复测量设计方差分析，分析表的阅读方式与之前的随机区组设计类似。</p><h3 id="两因素多水平重复测定资料的方差分析"><a href="#两因素多水平重复测定资料的方差分析" class="headerlink" title="两因素多水平重复测定资料的方差分析"></a>两因素多水平重复测定资料的方差分析</h3><p>进行重复测量设计方差分析，分析表的阅读方式与之前的随机区组设计类似。</p><h1 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h1><h2 id="交叉设计"><a href="#交叉设计" class="headerlink" title="交叉设计"></a>交叉设计</h2><p>分组同时需要分为2阶段，不同阶段进行不同处理。<br>前提：需要满足无延后效应</p><h2 id="拉丁方设计"><a href="#拉丁方设计" class="headerlink" title="拉丁方设计"></a>拉丁方设计</h2><p>通过拉丁字母组成方阵，在同一行或同一列内没有重复的字母。<br>这样你就会发现，在每个时间段每种处理方式都有1个样本。</p><h2 id="正交设计"><a href="#正交设计" class="headerlink" title="正交设计"></a>正交设计</h2><h3 id="表头设计"><a href="#表头设计" class="headerlink" title="表头设计"></a>表头设计</h3><p><img src="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_8.png" alt="picForEvibased_8" title="picForEvibased_8"><br>设计流程如下：</p><ol><li>如果我们希望研究的是每个因子的2阶交互因子。</li><li>将A，B放在1，2列内。</li><li>对于$A \times B$我们查看A,B因子所处的列1，2列，查交互作用表中1行2列，得到3。所以将$A \times B$放于第3列，</li><li>将C放在第4列，研究$A \times C$，我们查看1行4列得到第5列，将其放置在第5列。</li></ol><h1 id="生存时间资料分析"><a href="#生存时间资料分析" class="headerlink" title="生存时间资料分析"></a>生存时间资料分析</h1><h2 id="生存资料的特点"><a href="#生存资料的特点" class="headerlink" title="生存资料的特点"></a>生存资料的特点</h2><ol><li>存在删失值(如何处理？)</li><li>效应变量有2种</li><li>分布类型复杂</li></ol><h3 id="小样本生存率的K-M估计"><a href="#小样本生存率的K-M估计" class="headerlink" title="小样本生存率的K-M估计"></a>小样本生存率的K-M估计</h3><p>删失值不纳入死亡率的计算。</p><h3 id="大样本生存率的寿命表法估计"><a href="#大样本生存率的寿命表法估计" class="headerlink" title="大样本生存率的寿命表法估计"></a>大样本生存率的寿命表法估计</h3><p>删失人员只作为半个人。</p><h3 id="log-rank检验"><a href="#log-rank检验" class="headerlink" title="log-rank检验"></a>log-rank检验</h3><p>用于检验2组人群生存率是否存在差异性</p><h3 id="Cox风险比例模型"><a href="#Cox风险比例模型" class="headerlink" title="Cox风险比例模型"></a>Cox风险比例模型</h3><p>可以研究不同协变量对于生存率的影响</p><p>非参数检验的流程<br><img src="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/%E9%9D%9E%E5%8F%82%E6%95%B0%E6%A3%80%E9%AA%8C.drawio.png" alt="非参数检验" title="非参数检验"><br>生存分析的流程<br><img src="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/%E7%94%9F%E5%AD%98%E5%88%86%E6%9E%90.drawio.png" alt="生存分析" title="生存分析"></p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CLIP</title>
      <link href="/2025/05/08/CLIP/"/>
      <url>/2025/05/08/CLIP/</url>
      
        <content type="html"><![CDATA[<p>CLIP将计算机视觉与自然语言处理相结合，获得更加优秀的迁移性能与zero-shot效果。同时打破了固定标签的定式。</p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>针对目前已有的计算机视觉系统，大部分都是使用固定的标签集合，这限制了它的泛化性能和可用性。<br>于是作者选择通过图片的语言文本来进行图像识别。作者爬取了4亿张图片以进行模型的预训练。在预训练完成后，作者在30多个任务上进行了测试。<br>在ImageNet数据集内，CLIP模型在zero-shot的情况下便已经与训练完成的Resnet50打成平手。</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>GPT作为一个”Text-in-text-out”的经典案例，反映了弱监督工作的可行性，于是作者决定提出使用图片与文字结合，进行CLIP模型的研究。<br>已有相关研究VirTex, ICMLM和ConVIRT方法虽然接近，但是数据集规模较少，而有些弱监督模型的准确率较高，其依赖的是极度大量数据集，所以作者考虑到是否能够同时满足以上条件，进而研究出新的方法。在预实验结果中，使用已有模型(ConVIRT)与新的数据，其模型在zero-shot上成功体现出极好的效果。同时<strong>模型效果与模型大小呈现正相关</strong>。</p><h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>作者发现目前已有数据集不能满足训练需求，所以选择自己开发数据集。</p><h2 id="Pre-Training-Method"><a href="#Pre-Training-Method" class="headerlink" title="Pre-Training Method"></a>Pre-Training Method</h2><p>作者针对该数据的标签，决定使用“图像-文本配对”的方法来进行训练，这是因为如果采用标签生成或者词袋模型，训练过程较慢。<br>同时作者也采用对比学习的方法进行训练。<br>作者在训练过程中其实是发现了两个重要的事情。</p><h3 id="非线性映射"><a href="#非线性映射" class="headerlink" title="非线性映射"></a>非线性映射</h3><p>CLIP（Contrastive Language–Image Pre-training）在其两个编码器（图像编码器与文本编码器）末端各插入了一个 <strong>线性映射</strong>（linear projection）层，将各自的表示向量映射到同一多模态嵌入空间，以便计算余弦相似度并进行对比损失优化。在早期的对比或自监督学习框架（如 SimCLR、MoCo 等）中，人们常使用 <strong>非线性映射头</strong>（two-layer MLP + ReLU + BN）来获得更好的特征表示；而 CLIP 的作者发现，去掉这层非线性映射，仅保留简单的线性映射，训练效率与效果几乎无差异，因此选择了更为简洁的设计。</p><h3 id="未出现过拟合"><a href="#未出现过拟合" class="headerlink" title="未出现过拟合"></a>未出现过拟合</h3><p>作者在训练过程中未出现过拟合。<em>其实挺好理解的，这么大的数据集能过拟合也是神人了</em><br>作者对于数据的处理也仅仅只有裁剪，而并未采用更多的高级方法。作者对于温度系数 $t$ 也仅仅只是进行</p><h2 id="Choosing-and-Scaling-the-Model"><a href="#Choosing-and-Scaling-the-Model" class="headerlink" title="Choosing and Scaling the Model"></a>Choosing and Scaling the Model</h2><h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">image_encoder: Resnet or Vision Transformer</span><br><span class="line">text_encoder: CBOW or Text Transformer</span><br><span class="line">I: n * h * w * c, minibatch of aligned images</span><br><span class="line">T: n * l, minibatch of aligned texts</span><br><span class="line">t: learned temperature parameter</span><br><span class="line"></span><br><span class="line"># extract feature representations of each modality</span><br><span class="line">I_f = image_encoder(I) #[n, d_i]</span><br><span class="line">T_f = text_encoder(T) #[n, d_t]</span><br><span class="line"></span><br><span class="line"># joint multimodal embedding [n, d_e]</span><br><span class="line"># linear projectin</span><br><span class="line"># 这里是多模态常见的合成方法</span><br><span class="line">I_e = l2_normalize(np.dot(I_f, W_i), axis = 1)</span><br><span class="line">T_e = l2_normalize(np.dot(T_f, W_t), axis = 1)</span><br><span class="line"></span><br><span class="line"># scaled pairwise cosine similarities</span><br><span class="line">logits = np.dot(I_e, T_e.T) * np.exp(t)</span><br><span class="line"></span><br><span class="line"># symmetric loss function</span><br><span class="line"># 这里的正样本是对角线上的数据，也就是第一排第一个，第二排第二个。这里对比学习的思路。</span><br><span class="line">labels  = np.arrang(n)</span><br><span class="line">loss_i = cross_entropy_loss(logits, labels, aixs = 0)</span><br><span class="line">loss_t = cross_entropy_loss(logits, labels, aixs = 1)</span><br><span class="line">loss = (loss_i + loss_t)/2</span><br></pre></td></tr></table></figure><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>作者训练了5个ResNets和3个Vision Transformers<br>ResNet: ResNet-50, ResNet-101, EfficientNet-style model 4x, 16x and 64x the compute of a ResNet-50<br>Vision Transformer: ViT-B&#x2F;32 Vit-B&#x2F;16 ViT-L&#x2F;14<br>训练32个epoch，Adam优化器<br>作者对于ViT-L&#x2F;14在336像素的图片上又额外训练了一个epoch，并将其标注为ViT-L&#x2F;14@336px. 后面使用的模型均为ViT-L&#x2F;14@336px</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p><img src="/2025/05/08/CLIP/CLIP_inference.png" alt="CLIP_inference" title="CLIP_inference"></p><ol><li>通过Prompt Engineering构造选项(备选方案如plane, car, dog -&gt; A photo of plane, car, dog)经过Text Encoder计算为向量。</li><li>将图片经过Encoder转化为图像，计算图像与词向量的余弦相似度</li></ol><h3 id="Prompt-Engineering-and-Ensembling"><a href="#Prompt-Engineering-and-Ensembling" class="headerlink" title="Prompt Engineering and Ensembling"></a>Prompt Engineering and Ensembling</h3><p>作者在该段提出了：多义性(polysemy)和标签多为短句的问题。并对于这两种问题，其提出使用提示词模板来解决，例如模板”A photo of a {label}”. 该方法提升准确率1.3%<br>同时，对于特定数据集，可以将模型进一步扩充，如对于Oxford-IIIT Pets, 则可将模板改为”A photo of a {label}, a type of pets”.</p><h3 id="效果分析"><a href="#效果分析" class="headerlink" title="效果分析"></a>效果分析</h3><ol><li>CLIP(zero-shot) vs linear probe Resnet50: 对于有具体物体的模型CLIP表现更佳，而抽象概念的数据则相对较差(如数字、纹理)。</li><li>CLIP vs previous few-shot method: 远超既往小样本学习结果。CLIP在zero-shot的情况下，准确率已经和BiT-M的16-shot的效果相近。但是在部分few-shot上CLIP反而不如自己的zero-shot。</li><li>CLIP使用linear probe效果，全数据集训练效果依旧强劲。</li></ol><h1 id="Comparison-to-Human-Performance"><a href="#Comparison-to-Human-Performance" class="headerlink" title="Comparison to Human Performance"></a>Comparison to Human Performance</h1><p><img src="/2025/05/08/CLIP/Comparison_to_human.png" alt="Comparison_to_human" title="Comparison_to_human"></p><h1 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h1><ol><li>距离已有模型的SOTA有较大距离，只是优于ResNet50的Baseline.</li><li>CLIP对于部分数据的效果不佳，比如细分类的数据集、抽象概念的数据(数字、异常提取)。</li><li>对于数据分布偏差极大的数据集，效果依旧较差。例如MNIST数据集效果较差，作者分析是因为400M图片中均无MNIST类似的图片。</li><li>CLIP不是生成式模型，仍然需要提供一些选项。</li><li>CLIP模型对于数据的应用并不高效。</li><li>希望能够产生一种新的，针对Zero-shot的数据集。</li><li>数据并无清洗，可能存在偏见。</li><li>CLIP在few-shot的情况下并不如zero-shot优秀。</li></ol><hr><p>Cover image icon by <a href="https://www.flaticon.com/authors/becris" title="Becris">Becris</a> from <a href="https://www.flaticon.com/free-icons/deep-learning" title="deep learning icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Propensity Score</title>
      <link href="/2025/05/06/Propensity-Score/"/>
      <url>/2025/05/06/Propensity-Score/</url>
      
        <content type="html"><![CDATA[<p>The propensity score makes it so that you don’t have to condition on the entirety of X to achieve independence of the potential outcomes on the treatment. It is sufficient to condition on this single variable, which is the propensity score<br>$$(Y_{0},Y_{1}) \perp T|e(x)$$<br><em>The propensity score is the conditional probability of receiving the treatment, right? So we can think of it as some sort of function that converts X into the treatment T. The propensity score makes this middle ground between the variable X and the treatment T. If we show this in a causal graph, this is what it would look like.</em><br><img src="/2025/05/06/Propensity-Score/casual_7.png" alt="casual_7" title="casual_7"></p><h1 id="law-of-iterated-expectations"><a href="#law-of-iterated-expectations" class="headerlink" title="law of iterated expectations"></a><strong>law of iterated expectations</strong></h1><p>$$E[X]&#x3D;E[E[X|Y]]$$<br><em>Proof</em></p>$$\begin{aligned}E[E[Y|X]]&=\int_{-\infty}^\infty\int_{-\infty}^\infty yp_{Y|X}(y|x)p_{X}(x)dydx\\\\&=\int_{-\infty}^\infty\int_{-\infty}^\infty yp(x,y)dydx\\\\&=\int_{-\infty}^\infty y\int_{-\infty}^\infty p(x,y)dxdy\\\\&=\int_{-\infty}^\infty yp_{Y}(y)dy\\\\&=E[Y]\end{aligned}$$<p>具体内容参考<a href="https://www.zhihu.com/question/22996373/answer/3274277491">统计学基础</a><br> 其实我们可以看出，所谓$e(x)$就是$E[T|X]$也就是情形X下收到treatment的概率<br> $$E[T|e(x)]&#x3D;E[E[T|e(x),X]|e(x)]&#x3D;E[e(x)|e(x)]&#x3D;e(x)$$<br>其中$E[T|e(x),X]&#x3D;E[T|X]&#x3D;e(x)$</p><h1 id="Inverse-Probability-of-Treatment-Weighting-IPTW"><a href="#Inverse-Probability-of-Treatment-Weighting-IPTW" class="headerlink" title="Inverse Probability of Treatment Weighting (IPTW)"></a>Inverse Probability of Treatment Weighting (IPTW)</h1>$$E[Y|X,T=1]-E[Y|X,T=0]=E\left[ \frac{Y}{e(x)}|X,T=1 \right]P(T)-E\left[ \frac{Y}{1-e(x)}|X,T=0 \right](1-P(T))$$<p>直观上理解就是本来应该不被治疗的样本如果接受了治疗，那这个样本在分析的过程中会更加有价值<br>我们可以将其化简为$$E\left[ Y\frac{{T-e(x)}}{e(x)(1-e(x))} \right]$$<br><em>Proof</em></p>$$\begin{aligned}E[Y|X,T=1]-E[Y|X,T=0]&=E\left[ \frac{Y}{e(x)}|X,T=1 \right]P(T)-E\left[ \frac{Y}{1-e(x)}|X,T=0 \right](1-P(T))\\\\&=E\left[ \frac{{YT}}{e(x)}\bigg|X \right]-E\left[ \frac{Y(1-T)}{1-e(x)}\bigg|X \right]\\\\&=E\left[ \frac{YT(1-e(x))}{e(x)(1-e(x))}-\frac{Y(1-T)e(x)}{e(x)(1-e(x))} \bigg| X\right]\\\\&=E\left[ Y\frac{{T-e(x)}}{e(x)(1-e(x))} \bigg | X\right ]\end{aligned}$$<p><strong>positivity assumption</strong> of causal inference: Notice that this estimator requires that $e(x)$ and $1−e(x)$ are larger than zero. In words, this means that everyone needs to have at least some chance of receiving the treatment and of not receiving it. Another way of stating this is that the treated and untreated distributions need to overlap.</p><h1 id="Propensity-Score-Estimation"><a href="#Propensity-Score-Estimation" class="headerlink" title="Propensity Score Estimation"></a>Propensity Score Estimation</h1><p>代码见<a href="https://matheusfacure.github.io/python-causality-handbook/11-Propensity-Score.html">11 - Propensity Score — Causal Inference for the Brave and True</a></p><h1 id="Standard-Error"><a href="#Standard-Error" class="headerlink" title="Standard Error"></a>Standard Error</h1><p>首先考虑加权平均的方差$$\sigma^2_{w}&#x3D;\frac{\sum_{i&#x3D;1}^nw_{i}(y_{i}-\hat{\mu})^2}{\sum_{i&#x3D;1}^nw_{i}}$$<br>However, we can only use this if we have the true propensity score. If we are using the estimated version of it, $\hat{P}(x)$, we need to account for the errors in this estimation process. The easiest way of doing this is by bootstrapping the whole procedure. This is achieved by sampling with replacement from the original data and computing the ATE like we did above. We then repeat this many times to get the distribution of the ATE estimate.</p><h1 id="Common-Issues-with-Propensity-Score"><a href="#Common-Issues-with-Propensity-Score" class="headerlink" title="Common Issues with Propensity Score"></a>Common Issues with Propensity Score</h1><p><strong>Propensity score doesn’t need to predict the treatment very well. It just needs to include all the confounding variables</strong>.<br><em>To see this, consider the following example (adapted from Hernán’s Book). You have 2 schools, one of them apply the growth mindset seminar to 99% of its students and the other to 1%. Suppose that the schools have no impact on the treatment effect (except through the treatment), so it’s not necessary to control for it. If you add the school variable to the propensity score model, it’s going to have a very high predictive power. However, by chance, we could end up with a sample where everyone in school A got the treatment, leading to a propensity score of 1 for that school, which would lead to an infinite variance. This is an extreme example, but let’s see how it would work with simulated data.</em><br>其实就是当treatment和non treatment组之间特征没有过多的重叠时，对于接近0.5的概率附近样本较少，这会让方差增大<strong>This lack of balancing can generate some bias, because we will have to extrapolate the treatment effect to unknown regions.As a general rule of thumb, you are in trouble if any weight is higher than 20 (which happens with an untreated with propensity score of 0.95 or a treated with a propensity score of 0.05).</strong><br><strong>if the distributions don’t overlap, your data is probably not enough to make a causal conclusion anyway. To gain some further intuition about this, we can look at a technique that combines propensity score and matching</strong><br><img src="/2025/05/06/Propensity-Score/casual_8.png" alt="casual_8" title="casual_8"></p><h1 id="Propensity-Score-Matching"><a href="#Propensity-Score-Matching" class="headerlink" title="Propensity Score Matching"></a>Propensity Score Matching</h1><p>就是针对Propensity Score进行一次matching，从这个角度看，Propensity Score其实就是一种维度压缩，而我们就是再计算经过维度压缩后的特征的matching<br>值得注意的是，倾向性评分匹配并不适合bootstrap以估计SE[ON THE FAILURE OF THE BOOTSTRAP FOR MATCHING ESTIMATORS](<a href="https://economics.mit.edu/sites/default/files/publications/ON%20THE%20FAILURE%20OF%20THE%20BOOTSTRAP%20FOR.pdf">On the Failure of the Bootstrap for Matching Estimators</a>)</p><hr><p>Thanks for watching! and this my learning note of the blog of <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>.<br>感谢观看，这是我学习<a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>博客的笔记。<br>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 因果推断 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 因果推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Stats Review</title>
      <link href="/2025/05/06/Stats-Review/"/>
      <url>/2025/05/06/Stats-Review/</url>
      
        <content type="html"><![CDATA[<blockquote><p><em>“Some equations are dangerous if you know them, and others are dangerous if you do not. The first category may pose danger because the secrets within its bounds open doors behind which lies terrible peril. The obvious winner in this is Einstein’s iconic equation $E&#x3D;mc^2$, for it provides a measure of the enormous energy hidden within ordinary matter. […] Instead I am interested in equations that unleash their danger not when we know about them, but rather when we do not. Kept close at hand, these equations allow us to understand things clearly, but their absence leaves us dangerously ignorant.”</em></p></blockquote><p align="right">——Howard Wainer</p># Moivre’s equation$$SE=\frac{\sigma}{\sqrt{ n }}$$SE: standard error; $\sigma$: standard deviation; n: sample sizeeg: fewer students $\neq$ better eduacation, sometimes just **Greater SE**<p><img src="/2025/05/06/Stats-Review/casual_1.png" alt="casual_1" title="casual_1"></p><p>As Taleb puts it in his book, Fooled by Randomness:</p><blockquote><p>Probability is not a mere computation of odds on the dice or more complicated variants; it is the acceptance of the lack of certainty in our knowledge and the development of methods for dealing with our ignorance.</p></blockquote><h1 id="Standard-Error-of-Our-Estimates"><a href="#Standard-Error-of-Our-Estimates" class="headerlink" title="Standard Error of Our Estimates"></a>Standard Error of Our Estimates</h1><p>first calculate standard deviation:<br>$$\hat{\sigma}&#x3D;\sqrt{ \frac{1}{N-1}\sum^N_{i&#x3D;1}(x_{i}-\bar{x})^2 }$$<br>$$SE&#x3D;\frac{\sigma}{\sqrt{ n }}$$</p><h1 id="Confidence-Intervals"><a href="#Confidence-Intervals" class="headerlink" title="Confidence Intervals"></a>Confidence Intervals</h1><p>To calculate the confidence interval, we use the <strong>central limit theorem</strong>. This theorem states that <strong>means of experiments are normally distributed</strong>. From statistical theory, we know that 95% of the mass of a normal distribution is between 2 standard deviations above and below the mean. Technically, 1.96, but 2 is close enough.<br>The Standard Error of the mean serves as our estimate of the distribution of the experiment means. So, if we multiply it by 2 and add and subtract it from the mean of one of our experiments, we will construct a 95% confidence interval for the true mean.<br>你提到的这个观点其实非常重要，关于信赖区间（Confidence Interval，简称CI）的解释确实有一些常见误解。在频率统计学中，信赖区间并不是直接描述“某个特定区间包含真实均值的概率”，而是描述了通过重复实验或样本抽取，使用相同的统计方法计算出的区间包含真实参数的频率。<br>具体来说，95%置信区间的解释是：如果你在同样的条件下进行很多次独立的实验，每次计算置信区间，那么有95%的置信区间会包含真实的总体参数（例如，均值）。但这并不意味着某一个特定的区间有95%的概率包含真实值，因为真实值要么在这个区间内，要么不在。<br>为了更清晰地理解，可以举个例子：<br>假设我们进行100次相同的实验，每次都计算一个95%的置信区间。假如有95次的区间包含了真实的总体均值，而5次不包含，那么我们可以说：我们的统计方法是可靠的，95%的信赖区间会包含真实的均值。但对于单个实验的结果，我们不能说“这个区间有95%的概率包含真实均值”。<br>简而言之，CI是描述统计方法的长期表现，而不是对某个具体实验结果的概率评估。</p><h1 id="Hypothesis-Testing"><a href="#Hypothesis-Testing" class="headerlink" title="Hypothesis Testing"></a>Hypothesis Testing</h1><p>$$\mathcal{N}(\mu_{1}, \sigma_{1}^2)+\mathcal N(\mu_{2}, \sigma_{2}^2)&#x3D;\mathcal{N}(\mu_{1}+\mu_{2}, \sigma^2_{1}+\sigma_{2}^2)$$<br>$$\mathcal{N}(\mu_{1}, \sigma_{1}^2)-\mathcal N(\mu_{2}, \sigma_{2}^2)&#x3D;\mathcal{N}(\mu_{1}-\mu_{2}, \sigma^2_{1}+\sigma_{2}^2)$$<br>And the same for SE<br>$$\begin{aligned}<br>&amp;\mu_{diff} &#x3D; \mu_{1} - \mu_{2}<br>\\<br>&amp;SE_{diff} &#x3D; \sqrt{ SE_{1}^2+ SE_{2}^2 }&#x3D;\sqrt{ \frac{\sigma_{1}^2}{N_{1}} + \frac{\sigma_{2}^2}{N_{2}} }<br>\end{aligned}$$</p><h2 id="z-statistic"><a href="#z-statistic" class="headerlink" title="z-statistic"></a>z-statistic</h2>$$\begin{aligned}z &=\frac{{\mu_{diff}-H_{0}}}{SE}\\\\&=\frac{{\mu_{1}-\mu_{2}-H_{0}}}{\sqrt{ \frac{\sigma_{1}^2}{N_{1}} + \frac{\sigma_{2}^2}{N_{2}} }}\end{aligned}$$<p>The z statistic is a measure of how extreme the observed difference is. We will use contradiction to test our hypothesis that the difference in the means is statistically different from zero. We will assume that the opposite is true; we will assume that the difference is zero. This is called a <strong>null hypothesis</strong>, or $H_{0}$ .<br>Under $H_{0}$, the z statistic follows a standard normal distribution. So, if the difference is indeed zero, we would see the z statistic within 2 standard deviations of the mean 95% of the time. The direct consequence is that if z falls above or below 2 standard deviations, we can reject the null hypothesis with 95% confidence.<br><strong>To specify, $H_{0}$ stands for $\mu_{1}-\mu_{2}$, which is always 0</strong><br><strong>z-statistic</strong>（z统计量）在假设检验中通常用于检验两个样本均值之间的差异，尤其是在满足某些条件下，比如样本量较大（通常n &gt; 30）或者总体标准差已知的情况下。z检验常见的应用有：</p><ol><li><strong>单样本z检验</strong>：用于检验一个样本的均值是否与已知的总体均值有显著差异。<ul><li>例如，假设你想检验某个工厂生产的产品的平均重量是否等于标称值。</li></ul></li><li><strong>两样本z检验</strong>：用于检验两个独立样本的均值是否有显著差异。<ul><li>例如，你想比较两个不同工厂生产的产品的平均重量是否相同。</li></ul></li><li><strong>z检验的条件</strong>：通常要求已知总体标准差，或者样本量足够大以使得样本标准差可以较好地估计总体标准差。这个条件也可以通过<strong>中心极限定理</strong>来理解，即大样本的分布趋近于正态分布。</li></ol><h1 id="P-value"><a href="#P-value" class="headerlink" title="P-value"></a>P-value</h1><p><strong>the p-value is the probability of obtaining test results at least as extreme as the results actually observed during the test, assuming that the null hypothesis is correct</strong><br>P值是假设零假设成立的前提下，获取至少与实验结果一样极端的数据的概率<br>It measures how unlikely it is that you are seeing a measurement if the null hypothesis is true. Naturally, this often gets confused with the probability of the null hypothesis being true. Note the difference here. The p-value is NOT $P(H_{0}|data)$, but rather $P(data|H_{0})$.<br>也就是说，P-value不是说给定数据的前提下，$H_{0}$成立的概率，而是假设$H_{0}$成立的前提下，获得该数据的概率<br><img src="/2025/05/06/Stats-Review/casual_2.png" alt="casual_2" title="casual_2"><br>以上为单边检验，此外还有双边检验，<strong>双边检验</strong>关注参数是否偏离某个值，无论偏离的方向是增大还是减小。双边检验相较于单边更加难以显著，这是因为双边同时需要考虑两边的偏差，而单边只需要考虑一边的偏差，也就意味着单边其实已经有了一个前提，也就是我们已知偏差会位于左侧(或者右侧)，正是这个已知的事实减少了样本空间的大小，让概率升高。</p><h2 id="双边检验的必要性"><a href="#双边检验的必要性" class="headerlink" title="双边检验的必要性"></a><strong>双边检验的必要性</strong></h2><h3 id="a-无法预知偏离的方向时"><a href="#a-无法预知偏离的方向时" class="headerlink" title="a. 无法预知偏离的方向时"></a><strong>a. 无法预知偏离的方向时</strong></h3><ul><li>如果没有足够的理论依据或先验知识来预测偏差的方向，双边检验是<strong>唯一合理的选择</strong>。在这种情况下，使用单边检验可能导致忽视另一个方向上的潜在效应。</li></ul><h3 id="b-安全性和准确性考虑"><a href="#b-安全性和准确性考虑" class="headerlink" title="b. 安全性和准确性考虑"></a><strong>b. 安全性和准确性考虑</strong></h3><ul><li>在医学、工程和其他关键领域，错误地选择单边检验可能会导致过度自信或误判。尤其在某些实验中，我们无法确保效应的方向，如果单边检验的假设方向错误，可能会导致严重的后果。例如，药物效果的测试，如果只假设药物会增强效果而忽视了副作用，可能会导致对副作用的忽视。</li></ul><h3 id="c-多假设检验中的一致性"><a href="#c-多假设检验中的一致性" class="headerlink" title="c. 多假设检验中的一致性"></a><strong>c. 多假设检验中的一致性</strong></h3><ul><li>在某些复杂的多假设检验场景中，使用双边检验可以保持检验的一致性。例如，分析基因表达时，如果我们事先不知道某个基因是否会上调或下调，双边检验可以确保我们对上调和下调的效应都进行充分检验。</li></ul><hr><p>Thanks for watching! and this my learning note of the blog of <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>.<br>感谢观看，这是我学习<a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>博客的笔记。<br>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 因果推断 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 因果推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Beyond Confounders</title>
      <link href="/2025/05/06/Beyond-Confounders/"/>
      <url>/2025/05/06/Beyond-Confounders/</url>
      
        <content type="html"><![CDATA[<h1 id="Good-Control"><a href="#Good-Control" class="headerlink" title="Good Control"></a>Good Control</h1><p>Sometimes treatment’s effect on the outcome is much smaller than other factors, in order to figure out the effect of treatment, we should control other factors because:<br><strong>If a variable is a good predictor of the outcome, it will explain away a lot of its variance.</strong><br>To demonstrate this, let’s resort to the partialling out way of breaking regression into 2 steps.<br>First, we will regress the treatment, email, and the outcome, payments, on the additional controls, credit limit and risk score.<br>Second, we will regress the residual of the treatment on the residuals of payments, both obtained in step 1. (This is purely pedagogical, in practice you won’t need to go through all the hassle).<br>To wrap it up, anytime we have a control that is a good predictor of the outcome, even if it is not a confounder, adding it to our model is a good idea. It helps lowering the variance of our treatment effect estimates. Here is a picture of what this situation looks like with causal graphs.<br><img src="/2025/05/06/Beyond-Confounders/casual_4.png" alt="casual_4" title="causal_4"></p><p>其实这里与我们之前将confounder针对treatment回归的有相似之处又有不同之处：<br>之前将confounder针对treatment的回归主要依赖于confounder同时对treatment和outcome有影响，所以我们需要打断confounder的路径，造成随机化的情况。<br>而这里的factor其实并非confounder，这里是由于多种因素同时存在造成的“大数吃小数”的情况，所以需要将factor对outcome回归后，在将残差对于treatment回归。</p><h1 id="Bad-Control"><a href="#Bad-Control" class="headerlink" title="Bad Control"></a>Bad Control</h1><p>we should <strong>NOT</strong> add controls that are just good predictors of the treatment, because they will increase the variance of our estimates.<br>控制与treatment强相关的因素将会导致treatment的分组不均匀，从而提高variance，进而导致结果的不显著。</p><h2 id="Selection-Bias"><a href="#Selection-Bias" class="headerlink" title="Selection Bias"></a>Selection Bias</h2><p><strong>selection bias is when we control for a common effect or a variable in between the path from cause to effect.</strong>(参考[[Graph Casual Model]]中的Selection Bias)<br>Here is some examples:</p><ol><li>Adding a dummy for paying the entire debt when trying to estimate the effect of a collections strategy on payments.</li><li>Controlling for white vs blue collar jobs when trying to estimate the effect of schooling on earnings</li><li>Controlling for conversion when estimating the impact of interest rates on loan duration</li><li>Controlling for marital happiness when estimating the impact of children on extramarital affairs</li><li>Breaking up payments modeling E[Payments] into one binary model that predict if payment will happen and another model that predict how much payment will happen given that some will: E[Payments|Payments&gt;0]*P(Payments&gt;0)</li></ol><h2 id="COP-A-special-case-of-Selection-Bias"><a href="#COP-A-special-case-of-Selection-Bias" class="headerlink" title="COP: A special case of Selection Bias"></a>COP: A special case of Selection Bias</h2><p>这个问题来自与一个常见的问题：如果遇到0，是否要将其舍去，其实这个问题就是针对舍去0的模型：<br>我们在针对一些相对稀疏的outcome进行推断时，常常倾向于删去0值，但是这样会导致我们舍去了一部分正常为0的数据，以基因表达为例；<br>如果我们对于某群体给予某种药物，则必然有一部分基因在大部分情况下均不表达，这时有人提出：为什么我们不只看那部分表达的个体在治疗前后的基因表达改变的情况。<br>但是，这个想法是错误的！<br>直观上讲，就是我们大可以将群体分为2群，一群是在药物治疗后基因表达增加，而这个群体本身就有基因表达；二群是在药物治疗后基因表达从0到1，这个群体本身无基因表达。如果我们简单去掉0数据，则可能带来：二群的治疗前的数据的丢失。最后在研究因果效应时会导致因果效应偏小。<br>理论上推导如下：</p>$$\begin{aligned}&E[Y|T=1]-E[Y|T=0]\\\\=&E[Y|Y>0,T=1]P(Y>0|T=1)+E[Y|Y>0,T=0]P(Y>0|T=0)(删去E[Y|Y=0])\\\\=&(P(Y>0|T=1)-P(Y>0|T=0))E[Y|Y>0,T=1]\\\\+&(E[Y|Y>0,T=1]-E[Y|Y>0,T=0])P(Y>0|T=0)\end{aligned}$$<p>上式子中，前者代表“Participation Effect”，及治疗前后值从0到1的改变情情况，即一群的预期效益；后者则代表”COP”，即治疗前后增加的基因表达数量，即二群的预期效益<br>数学上完全正确，问题出在估计$E[Y|Y&gt;0|T&#x3D;1]-E[Y|Y&gt;0|T&#x3D;0]$过程中</p>$$\begin{aligned}&E[Y|Y>0,T=1]-E[Y|Y>0,T=0]\\\\=&E[Y_{1}|Y_{1}>0]-E[Y_{0}|Y_{0}>0]\\\\=&E[Y_{1}-Y_{0}|Y_{1}>0] + (E[Y_{0}|Y_{1}>0]-E[Y_{0}|Y_{0}>0]) \end{aligned}$$<p>这就是我们常见的bias公式，我们可以看到，前面的那个估计正确，但是后面可能会出现bias，也就是说$E[Y_{0}|Y_{1}&gt;0]&lt;E[Y_{0}|Y_{0}&gt;0]$, 因为会有部分$Y_{0}&#x3D;0$的情况被排除。<br><img src="/2025/05/06/Beyond-Confounders/casual_5.png" alt="casual_5" title="casual_5"><br><strong>注意：上式子我们需要求得的是$E[Y_{1}-Y_{0}|Y_{1}&gt;0]$，其中$E[Y|T&#x3D;1]-E[Y|T&#x3D;0]$，是我们观察到的数据，主要问题就是我们在计算过程中可能会把$E[Y_{0}|Y_{1}&gt;0]-E[Y_{0}|Y_{0}&gt;0]$所忽视</strong><br><em>这里的思路类似于[[mathematic&#x2F;Casual inference&#x2F;Introduction]]中的思路，就是计算ATT，但是我们加了个前提就是要大于0，大于0就让无法ATT的转化无法正常进行，因为这使得引入了新的bias，很奇妙吧，虽然过程不同，但是最后归于公式的时候却是相同的</em><br>相当有趣的是这里我们依旧可以用Selection Bias解释，这是因为治疗与否影响了基因表达是否大于0，同时outcome也对基因表达是否大于0有影响，构成了一个Collider，一旦控制，就会带来Selection Bias.</p><hr><p>Thanks for watching! and this my learning note of the blog of <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>.<br>感谢观看，这是我学习<a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>博客的笔记。<br>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 因果推断 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 因果推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循证医学7-8周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="二项分布与poisson分布及其应用"><a href="#二项分布与poisson分布及其应用" class="headerlink" title="二项分布与poisson分布及其应用"></a>二项分布与poisson分布及其应用</h1><h2 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h2>$$P(X) = C^x_{n} \pi^x (1-\pi)^{n-x}$$$$\mu = n\pi, \sigma^2={ n\pi(1-\pi) }$$<p>样本率的方差计算同正态分布时的均值的方差计算：<br>$$S_{p}&#x3D;\sqrt{ \frac{p(1-p)}{n} }$$<br>总体率置信区间计算：</p><ol><li>查表方法</li><li>正态近似法(样本容量&gt;100, $\pi \approx 0.5$)</li></ol>$$\begin{aligned}u &= \frac{{p-\pi_{0}}}{\sigma_{p}} \\\sigma_{p} &= \sqrt{ \frac{\pi_{0}(1-\pi_{0})}{n} }\end{aligned}$$*既往死亡率为40%，实验中120名病人死亡30名，统计推断：H_0: 均值不等H_1: 均值相等确定alpha值为0.05，双尾检验*$$\begin{aligned}\sigma_{p}&=\sqrt{ \frac{\pi_{0}(1-\pi_{0})}{n} }\\&=\sqrt{ \frac{0.4(1-0.4)}{120} }\\&\approx 0.045\\u&=\frac{{p-\pi_{0}}}{\sigma_{p}}\\&=\frac{{\frac{30}{120} - 0.4}}{0.045}\\&=-3.333\end{aligned}$$<p><em>显著：拒绝H_0，因为超过了3个标准差</em></p><h2 id="Poisson分布"><a href="#Poisson分布" class="headerlink" title="Poisson分布"></a>Poisson分布</h2><p>$$P(X)&#x3D; \frac{\lambda^x}{x!}e^{-\lambda}, X&#x3D;0,1,2,\dots$$<br>$$\mu&#x3D;\lambda, \sigma^2&#x3D;\lambda$$<br>总体率置信区间计算：</p><ol><li>查表方法</li><li>正态近似法($\mu \approx 0.5$)<br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_6.png" alt="分布间关系" title="分布间关系"></li></ol><h1 id="RR值和OR值的估计"><a href="#RR值和OR值的估计" class="headerlink" title="RR值和OR值的估计"></a>RR值和OR值的估计</h1><p>RR值适用于：队列研究(risk ratio)<br>OR值适用于：病例对照研究(odds ratio)</p><table><thead><tr><th>指标</th><th>全称</th><th>定义</th><th>适用研究</th></tr></thead><tbody><tr><td><strong>RR</strong></td><td>相对危险度（Relative Risk）</td><td>暴露组患病概率 &#x2F; 非暴露组患病概率</td><td><strong>队列研究</strong>（可以“跟踪”发病）</td></tr><tr><td><strong>OR</strong></td><td>比值比（Odds Ratio）</td><td>病例组的暴露几率 &#x2F; 对照组的暴露几率</td><td><strong>病例对照研究</strong>（不能计算发病率）</td></tr></tbody></table><h3 id="为何适用于不同研究类型？"><a href="#为何适用于不同研究类型？" class="headerlink" title="为何适用于不同研究类型？"></a>为何适用于不同研究类型？</h3><h4 id="队列研究-→-RR"><a href="#队列研究-→-RR" class="headerlink" title="队列研究 → RR"></a>队列研究 → <strong>RR</strong></h4><ul><li>从“暴露”开始观察，<strong>可以</strong>得到真正的“发病概率”。</li><li>所以可以直接算：<br>  $$RR &#x3D; \frac{P(\text{发病}|\text{暴露})}{P(\text{发病}|\text{非暴露})}$$​</li></ul><h4 id="病例对照研究-→-OR"><a href="#病例对照研究-→-OR" class="headerlink" title="病例对照研究 → OR"></a>病例对照研究 → <strong>OR</strong></h4><ul><li>从“疾病状态”出发选人（先有病例和对照），<strong>无法</strong>算发病率。</li><li>只能算暴露与非暴露的“比值”：<br>  $$OR &#x3D; \frac{\text{病例组中暴露&#x2F;非暴露}}{\text{对照组中暴露&#x2F;非暴露}}$$</li></ul><h4 id="生存分析-→-HR-harzard-ratio"><a href="#生存分析-→-HR-harzard-ratio" class="headerlink" title="生存分析 → HR(harzard ratio)"></a>生存分析 → <strong>HR(harzard ratio)</strong></h4><ul><li><p><strong>定义</strong>：HR 衡量暴露组相对于非暴露组在 <strong>随时间变化的事件发生速率</strong>（例如生存分析中的死亡率、疾病发生率等）的比率。它通常用于 <strong>生存分析</strong>，尤其是 <strong>Cox比例风险模型</strong> 中。</p></li><li><p><strong>计算方法</strong>：HR 基于时间的事件发生风险计算，可以理解为暴露组和非暴露组在单位时间内发生事件的风险比：<br>  $$HR &#x3D; \frac{\text{暴露组事件发生率}}{\text{非暴露组事件发生率}}$$</p><p>  它考虑了随时间推移的风险，而不仅仅是单纯的事件发生与否。</p></li></ul><h4 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h4><table><thead><tr><th></th><th>发病</th><th>未发病</th><th>总计</th></tr></thead><tbody><tr><td>暴露组</td><td>30</td><td>70</td><td>100</td></tr><tr><td>非暴露组</td><td>10</td><td>90</td><td>100</td></tr><tr><td>总计</td><td>40</td><td>160</td><td>200</td></tr></tbody></table>$$\begin{aligned}RR &= \frac{\frac{30}{100}}{\frac{10}{100}}=3 \\OR &= \frac{\frac{30}{10}}{\frac{70}{90}}=3.86\end{aligned}$$<p>口诀： <strong>“RR 看未来，OR 看过去”</strong></p><ul><li>RR 是“先暴露后观察结果” → 队列研究</li><li>OR 是“先有病例找原因” → 病例对照</li></ul><h1 id="卡方检验"><a href="#卡方检验" class="headerlink" title="卡方检验"></a>卡方检验</h1><p>理论频数的计算：</p><table><thead><tr><th></th><th>有效</th><th>无效</th><th>总数</th><th>概率</th></tr></thead><tbody><tr><td>A组</td><td>68(74*87.59%)</td><td>6</td><td>74</td><td>91.89%</td></tr><tr><td>B组</td><td>52</td><td>11</td><td>63</td><td>82.54%</td></tr><tr><td>总计</td><td>120</td><td>17</td><td>137</td><td>87.59%</td></tr></tbody></table><p>普通卡方：$n\geq40, E\geq5$<br>连续性校正卡方：$n\geq40, 1\leq E\leq5$<br>Fisher确切检验：$n\leq40$ 或 $E\leq {1}$</p><p><em>例题：15只4只发生癌变，对照组10只0只癌变</em></p><table><thead><tr><th></th><th>癌变</th><th>未癌变</th></tr></thead><tbody><tr><td>暴露组</td><td>4</td><td>11</td></tr><tr><td>非暴露组</td><td>0</td><td>10</td></tr></tbody></table><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_7.png" alt="卡方检验实例" title="卡方检验实例"></p><h2 id="配对卡方检验"><a href="#配对卡方检验" class="headerlink" title="配对卡方检验"></a>配对卡方检验</h2><h2 id="行列表卡方检验"><a href="#行列表卡方检验" class="headerlink" title="行列表卡方检验"></a>行列表卡方检验</h2><ol><li>多个率的比较</li><li>率的多重比较</li><li>多个构成比的比较</li><li>两种属性关联性检验</li></ol><h1 id="多种R-times-C表资料统计分析方法"><a href="#多种R-times-C表资料统计分析方法" class="headerlink" title="多种R $\times$ C表资料统计分析方法"></a>多种R $\times$ C表资料统计分析方法</h1><h2 id="卡方检验-1"><a href="#卡方检验-1" class="headerlink" title="卡方检验"></a>卡方检验</h2><ol><li>双向无序</li><li>单向有序：组别有序、结果无序</li></ol><h2 id="秩和检验"><a href="#秩和检验" class="headerlink" title="秩和检验"></a>秩和检验</h2><ol><li>单向有序：组别无序、结果有序</li></ol><h1 id="拟合优度的卡方检验"><a href="#拟合优度的卡方检验" class="headerlink" title="拟合优度的卡方检验"></a>拟合优度的卡方检验</h1><ol><li>单变量</li><li>二项分布</li><li>Poisson分布</li></ol><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C.png" alt="卡方检验" title="卡方检验"></p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循证医学5-6周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="ANOVA"><a href="#ANOVA" class="headerlink" title="ANOVA"></a>ANOVA</h1><p>多组样本均数比较</p><h1 id="多重比较"><a href="#多重比较" class="headerlink" title="多重比较"></a>多重比较</h1><p>SNK-Q, Dunnet-t, LSD-t检验，其中SNK-q最难显著，LSD-t最容易显著<br>SNK-q: 任意两组进行均数的比较<br>Dunnet-t: k-1个实验组与一个对照组的比较<br>LSD-t: 特定几组的比较</p><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>正态分布<br>方差齐性<br>Bartlett检验： 服从正态分布<br>Levene检验：服从任意分布</p><h1 id="双向方差分析"><a href="#双向方差分析" class="headerlink" title="双向方差分析"></a>双向方差分析</h1><p><em>方差分析不等于分析方差，方差分析分析均数</em><br>类似于ANOVA,仅可以做到比较多组是否全部相同。</p><h1 id="析因设计的方差分析"><a href="#析因设计的方差分析" class="headerlink" title="析因设计的方差分析"></a>析因设计的方差分析</h1><p>先确定有无交互效应<br>若无交互效应则进行主效应分析<br>若有交互效应则进行单独效应分析</p><p><em>F&amp;Q: 老师上课所使用的单变量回归该如何理解？单变量回归的作用是不是就是将不同正态分布的总体拉到同一基线上？</em><br>对于析因设计的方差检验，由于数据内部存在多组正态分布，导致数据总体不满足正态分布，所以需要分析其拟合后残差是否满足正态性与方差齐性<br>$$<br>\begin{aligned}<br>Y &#x3D; \beta_{0} + \beta_{1} X_{1} + \beta_{2}X_{2}<br>\end{aligned}$$<br>如果$X_{1}$: 肝脏&#x3D;0，心脏&#x3D;1；$X_{2}$: 15min&#x3D;0，60min&#x3D;1；$Y$: 药物浓度<br>如果我们研究不同时间的药物浓度是否相同:<br>$$<br>\begin{aligned}<br>Y &#x3D; \beta_{0} + \beta_{2}X_{2}\<br>Y - \beta_{1} &#x3D; \beta_{0}+\beta_{2}X_{2}<br>\end{aligned}$$<br>上面第一个式子是肝脏的药物浓度、第二个式子是心脏的药物浓度，但是我们给心脏的药物浓度做了个”修正”, 这个时候两数据的均值其实就”对齐”了</p><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/%E5%8F%82%E6%95%B0%E6%A3%80%E9%AA%8C.png" alt="参数检验" title="参数检验"></p><h1 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h1><blockquote><p>如果我们的数据不满足正态分布，而是满足二项分布，那我们该如何进行分析？</p></blockquote><h1 id="广义线性模型"><a href="#广义线性模型" class="headerlink" title="广义线性模型"></a>广义线性模型</h1><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_5.png" alt="logistic regression" title="logistic regression"></p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循证医学3-4周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A63-4%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A63-4%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h1><ol><li>检验的对象：抽样样本的均值，均值分布满足正态分布、抽样所得样本不一定满足正态分布</li><li>从正态分布——u分布——t分布(方差未知时用，<em><strong>大部分时候</strong></em>)</li><li>可信区间的计算(CI)：依赖于标准正态分布$\mathcal{N}(0,1)$ ,双边检验和单边检验的区分<br>变换方法：<br>$$\begin{aligned}<br>X \sim \mathcal{N}(\mu, \sigma^2)\\<br>X-\mu \sim \mathcal{N}(0, \sigma^2)\\<br>\frac{X-\mu}{\sigma} \sim \mathcal{N}(0, 1)<br>\end{aligned}<br>$$</li></ol><h1 id="两组均数比较的参数检验"><a href="#两组均数比较的参数检验" class="headerlink" title="两组均数比较的参数检验"></a>两组均数比较的参数检验</h1><h2 id="单样本t检验"><a href="#单样本t检验" class="headerlink" title="单样本t检验"></a>单样本t检验</h2><p>和已知的均值比较。<br>假设我检测的样本均值为$\bar{X} \sim \mathcal{N}(\mu_{1}, \frac{\sigma_{1}^2}{n})$，总体均值为常数$\mu_{2}$，然后我们对这两个作差得到:<br>$$\bar{X}-\mu_{2}\sim \mathcal{N}(\mu_{1}-\mu_{2}, \frac{\sigma_{1}^2}{n})$$<br>我希望的是：证明作差得到的分布是一个均值为0的分布，这样就可以证明两个样本均值和总体均值是没有差别的。<br>所以，假设以上均值为0，然后计算出现以上事件的概率。</p><h2 id="配对设计"><a href="#配对设计" class="headerlink" title="配对设计"></a>配对设计</h2><p>这里是配对样本的差值作为上面单样本检验的样本数据</p><h2 id="两总体均数比较"><a href="#两总体均数比较" class="headerlink" title="两总体均数比较"></a>两总体均数比较</h2><p>两样本均数满足$$\begin{aligned}<br>\bar{X_{1}} \sim \mathcal{N}\left( \mu_{1}, \frac{\sigma_{1}^2}{n_{1}} \right)\\<br>\bar{X_{2}} \sim \mathcal{N}\left( \mu_{2}, \frac{\sigma_{2}^2}{n_{2}} \right)<br>\end{aligned}<br>$$<br>作差得到, 随机变量计算公式：<br>$$\bar{X_{1}}-\bar{X_{2}} \sim \mathcal{N}\left( \mu_{1} - \mu_{2}, \frac{\sigma_{1}^2}{n_{1}} + \frac{\sigma_{2}^2}{n_{2}}\right)$$<br>假设上面公式均值为0，计算概率<br>因为总体方差未知，所以用S代替$\sigma$</p><h2 id="方差齐性"><a href="#方差齐性" class="headerlink" title="方差齐性"></a><em><strong>方差齐性</strong></em></h2><p>我们所做的工作都是针对均值，所以不妨假设方差相同，因为不相同，那显然不是两个相同总体<br>但是在使用该前提的时候需要证明方差相同。<br>使用的证明方法就是F检验，F分布就是两个正态分布的比值<br>$$F&#x3D;\frac{\frac{\sum_{i&#x3D;1}^{n_{1}}X_{i}^2}{n_{1}}}{\frac{\sum_{i&#x3D;1}^{n_{2}}Y_{i}^2}{n_{2}}}$$<br>其中，$X_{i}$和$Y_{i}$均为来自标准正态分布的样本，则称统计量F满足F分布<br>$$F \sim F(n_{1},n_{2})$$<br>方差之比遵从F分布，计算方差之比在假设两方差相同的情况下出现的概率。<br><strong>有趣的是，后面我们计算多组均数的方差分析中，也是使用的F分布，那个时候我们做出的假设是——组内方差&#x3D;组间方差</strong></p><h1 id="LASSO"><a href="#LASSO" class="headerlink" title="LASSO"></a>LASSO</h1><p><em>文献例子: Development and validation of a model to predict cognitive impairment in traumatic brain injury patients: a prospective observational study</em><br>“Variable selection was conducted via the least absolute shrinkage and selection operator (LASSO) method. Independent variables with nonzero coefficients in the LASSO regression model were selected and subsequently analyzed via multivariate logistic regression (P &lt; 0.05) to identify potential predictive factors.”</p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第一篇文章</title>
      <link href="/2025/05/06/2025-5-6/"/>
      <url>/2025/05/06/2025-5-6/</url>
      
        <content type="html"><![CDATA[<h2 id="这是我的第一篇文章"><a href="#这是我的第一篇文章" class="headerlink" title="这是我的第一篇文章"></a>这是我的第一篇文章</h2><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">alert</span>(<span class="string">&#x27;Hello World!&#x27;</span>);</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>循证医学1-2周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<p>第一周的主要内容其实就是意识到概率论和数理统计之间的关系</p><h1 id="统计学中的基本概念"><a href="#统计学中的基本概念" class="headerlink" title="统计学中的基本概念"></a>统计学中的基本概念</h1><h2 id="PPT-1"><a href="#PPT-1" class="headerlink" title="PPT-1"></a>PPT-1</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>总体——参数——$\mu, \sigma$<br>样本——统计量——$\bar{X}, \bar{Y}$<br>同质性与异质性<br><strong>抽样误差(sampling error)</strong></p><p>计量资料——有序<br>计数资料——有序<br>等级资料——无序</p><h3 id="因果与联系："><a href="#因果与联系：" class="headerlink" title="因果与联系："></a>因果与联系：</h3><p>金字塔顶端RCT研究，RCT是揭示事物因果关系最重要的方法，但是由于价格原因，大部分时间只能使用他的替代方案。</p><h3 id="抽样误差的有趣知识SE"><a href="#抽样误差的有趣知识SE" class="headerlink" title="抽样误差的有趣知识SE"></a>抽样误差的有趣知识<strong>SE</strong></h3><p>为什么要有SE？<br>如下图所示，美国为了研究班级人数的多少和班级平均分的关系，他们发现分数高的是那些班级人数较少的班级，但事实上，只是因为班级人数过少导致SE增大带来的错误因果！<br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_4.png" alt="SE的解释" title="SE的解释"></p><h2 id="PPT-2"><a href="#PPT-2" class="headerlink" title="PPT-2"></a>PPT-2</h2><p>不同均数的适应情况，及为什么适应：</p><h3 id="算术均数"><a href="#算术均数" class="headerlink" title="算术均数"></a>算术均数</h3><p>算术均数适用于正态分布，因为算术均数其实是正态分布的通过<strong>极大似然估计</strong>得到的均值<br>$$P(x)&#x3D;\frac{1}{\sqrt{ 2\pi }\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$<br>$$\begin{aligned}<br>l(x_{1},x_{2},\dots,x_{n})&amp;&#x3D;\sum_{i&#x3D;1}^n \ln P(x_{i})\\<br>&amp;&#x3D;\sum_{i&#x3D;1}^n (\ln \frac{1}{\sqrt{ 2\pi }\sigma} + \ln e^{-\frac{(x_{i}-\mu)^2}{2\sigma^2}})\\<br>&amp;&#x3D;\sum_{i&#x3D;1}^n (\ln \frac{1}{\sqrt{ 2\pi }\sigma} -\frac{(x_{i}-\mu)^2}{2\sigma^2})<br>\end{aligned}$$<br>求使上式子最大的$\mu$<br>$$\frac{dl}{d\mu}&#x3D;\sum_{i&#x3D;1}^n \frac{x_{i}-\mu}{\sigma^2}&#x3D;0$$<br>so<br>$$\mu&#x3D;\frac{1}{n}\sum_{i&#x3D;1}^n x_{i}$$</p><h3 id="几何均数"><a href="#几何均数" class="headerlink" title="几何均数"></a>几何均数</h3><p>几何均数适用于<strong>对数转换后呈正态分布的资料</strong>，即右偏态<br><em><strong>存在部分数值特别大的</strong></em><br>为什么使用几何均数？<br>为什么能用累乘解释：<br><em>比如，某机械厂生产机器，设有毛坯、粗加工、精加工和装配4个连续作业的车间。某批产品其毛坯车间制品合格率为97%，接下来3个车间的合格率分别为93%、91%和87%，求产品的平均合格率。<br>产品的平均合格率受制于4个车间的坏品或损耗情况，由于是连续作业的车间，所以是在前者基础上变成了百分之多少的感觉，符合几何平均数的应用。<br>直接使用几何平均数的公式，计算得出：</em><br>$$G&#x3D;(0.97 \times 0.93 \times 0.91 \times 0.87)^{1&#x2F;4}&#x3D;0.9193$$</p><h3 id="中位数"><a href="#中位数" class="headerlink" title="中位数"></a>中位数</h3><p>$$M&#x3D;L_{M}+\frac{i_{M}}{f_{M}}\left( \frac{n}{2} -\sum f_{L}\right)$$<br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_2.png" alt="中位数" title="中位数"></p><h3 id="标准差"><a href="#标准差" class="headerlink" title="标准差"></a>标准差</h3><p>为什么会有一个$\sigma$和$S$<br>而且$S$下面的分母为$n-1$<br>这是因为在计算均数时已经消耗掉一个自由度，所以需要减去一个自由度。通俗的讲，均数其实是偏向于我们采样的数据，所以在计算方差时需要让除数小一点，这样让方差更大，更加接近真实方差。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>正态分布: 能使用<strong>算术均数</strong>和<strong>标准差</strong>描述<br>右偏态数据使用: <strong>几何均数</strong><br>所有分布都可以使用的: <strong>众数</strong>、<strong>四分位数间距</strong><br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_3.png" alt="总结" title="总结"></p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
