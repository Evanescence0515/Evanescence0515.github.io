<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>循证医学9-12周回顾</title>
      <link href="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="非参数检验"><a href="#非参数检验" class="headerlink" title="非参数检验"></a>非参数检验</h1><h2 id="非参数检验的适应条件"><a href="#非参数检验的适应条件" class="headerlink" title="非参数检验的适应条件"></a>非参数检验的适应条件</h2><ol><li>等级顺序资料</li><li>偏态资料</li><li>未知分布资料</li><li>各组资料的变异度大，方差不齐，变换也不能达到齐性</li><li>数据一端或两端有不确定值的资料</li><li>初步分析<br><em>可以举几个例子：1. 不满足参数检验的要求；2. 血糖水平高于最高值会显示high</em></li></ol><h2 id="非参数检验的缺点"><a href="#非参数检验的缺点" class="headerlink" title="非参数检验的缺点"></a>非参数检验的缺点</h2><p>容易出现第II类错误，即假阴性概率增大，本应显示出显著性差异的结果但是却并没有出现显著性差异。</p><h2 id="两组配对设计资料的比较"><a href="#两组配对设计资料的比较" class="headerlink" title="两组配对设计资料的比较"></a>两组配对设计资料的比较</h2><p>Wilcoxon符号秩和检验</p><ol><li>符号检验</li><li>配对设计差值的符号秩检验：其实就是对差值进行符号检验</li></ol><h2 id="单样本资料的符号秩和检验"><a href="#单样本资料的符号秩和检验" class="headerlink" title="单样本资料的符号秩和检验"></a>单样本资料的符号秩和检验</h2><p>Wilcoxon符号秩和检验。对标单样本正态检验</p><h2 id="成组设计两样本比较的秩和检验"><a href="#成组设计两样本比较的秩和检验" class="headerlink" title="成组设计两样本比较的秩和检验"></a>成组设计两样本比较的秩和检验</h2><p>Wilcoxon秩和检验</p><h2 id="成组设计多个样本比较的秩和检验"><a href="#成组设计多个样本比较的秩和检验" class="headerlink" title="成组设计多个样本比较的秩和检验"></a>成组设计多个样本比较的秩和检验</h2><p>Kruskal Wallis H检验</p><h3 id="原始数据的多个样本比较"><a href="#原始数据的多个样本比较" class="headerlink" title="原始数据的多个样本比较"></a>原始数据的多个样本比较</h3><p>对标参数检验中的ANOVA，用于揭示多组数据的中位数是否完全相同</p><h3 id="多个样本两两比较的秩和检验"><a href="#多个样本两两比较的秩和检验" class="headerlink" title="多个样本两两比较的秩和检验"></a>多个样本两两比较的秩和检验</h3><p>对标参数检验中的SNK-Q, LSD-T检验</p><h1 id="回归与相关"><a href="#回归与相关" class="headerlink" title="回归与相关"></a>回归与相关</h1><p>回归与相关并不相同，从概念上讲，相关其实是一种双重映射，而回归是单射。从直觉上讲，相关其实是一个相对模糊的概念，并不具有因果性，而回归其实是显示出一种简单的因果性：是自变量的改变会导致因变量改变程度的一种反映。</p><h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2><h3 id="回归方程"><a href="#回归方程" class="headerlink" title="回归方程"></a>回归方程</h3><p>$$Y &#x3D; \alpha +\beta X + \epsilon$$<br>$\alpha$：回归直线的截距<br>$\beta$：回归直线的斜率，又称为回归系数<br>$\epsilon$：误差项，在线性回归中我们认为其满足均值为0，方差为1的假设，所以在完成线性回归后我们将会对其进行残差检验，以研究其是否满足我们的前提。</p><h3 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h3><h4 id="F检验"><a href="#F检验" class="headerlink" title="F检验"></a>F检验</h4>$$\begin{aligned}\sum(Y-\bar{Y})^2 &= \sum((\hat{Y}- \bar{Y}) + (Y - \hat{Y}))^2 \\&=\sum(\hat{Y} - \hat{Y})^2 + \sum(Y - \hat{Y})^2\end{aligned}$$<p>$Y$：真实值<br>$\hat{Y}$：预测值<br>$\bar{Y}$：均值</p>$$F = \frac{MS_{回归}}{MS_{误差}}=\frac{\frac{SS_{回归}}{\nu_{回归}}}{\frac{SS_{误差}}{\nu_{误差}}}$$<p>其中$\nu_{总}&#x3D;n-1, \nu_{回归} &#x3D; 1, \nu_{误差} &#x3D; n-2$</p><h4 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h4><p>回归系数的区间估计</p>$$b \pm t_{\frac{\alpha}{2},n-2}S_{b}, S_{b}=\sqrt{ \frac{MS_{误差}}{l_{XX}} }$$<p>均值的区间估计</p>$$\hat{Y}\pm t_{\frac{\alpha}{2},n-2}S_{\hat{Y}}, S_{\hat{Y}}=S_{YX}\sqrt{ \frac{1}{n} + \frac{(X_{0}-\hat{X})^2}{\sum(X-\bar{X})^2}}$$<p>其中$l_{XX}=\sum(X-\bar{X})^2, S_{YX}=\sqrt{ \frac{\sum(Y-\hat{Y})^2}{n-2} }=\sqrt{ \frac{SS_{剩}}{n-2} }$<br>个体Y值的容许区间</p>$$\hat{Y}\pm t_{\frac{\alpha}{2},n-2}S_{Y}, S_{Y}=S_{YX}\sqrt{ 1 + \frac{1}{n} + \frac{(X_{0}-\hat{X})^2}{\sum(X-\bar{X})^2}}$$<h3 id="残差分析"><a href="#残差分析" class="headerlink" title="残差分析"></a>残差分析</h3><p>线性回归模型满足以下四个前提要求：线性、独立、正态性、等方差。<br>这里线性的条件很容易理解；对于独立的条件，其实就是为了避免样本之间的相关性，例如我们要研究药物浓度与时间的关系，但是样本中存在相同人的不同时间的样本，那可能会出现该人的某个时间段的检查数值与之前某个时间的检查数值相关。那么我们在进行回归的时候会发现，如果前一个时间段浓度高，该时间段浓度也会高。也就意味着，有一部分的误差并不能通过对于时间的回归来解释，这里我们需要使用<strong>时间序列分析</strong>以最大化对于不同时间段相同人的数据的利用率。<br>正态性与等方差性则是进行线性回归的前提，如果不满足则优化的方法其实是有问题的。<br>为了验证以上4个前提，我们常使用残差分析。<br>残差分析我们可以认为是<strong>线性回归的粪便检查</strong>，线性回归完成后我们需要研究<strong>回归后还剩下什么</strong>，残差就是回归后的边角料，如果边角料中存在很明显的趋势，那我们就不能丢弃这一部分的数据，我们仍然需要进一步挖掘。而这一趋势其实就是数据不满足以上线性回归四前提的实际体现。所以也可以认为，线性回归的能力(消化能力)其实并不强，一但数据复杂度增高(消化难度增加)，就难以继续使用线性回归挖掘数据(消化并吸收营养)，所以需要进行残差回归以确定线性回归可以充分利用该数据。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>线性回归不能外推、要有实际意义、<strong>要先绘图</strong>(非常重要，这是线性回归乃至后面的时间序列分析、断点回归、样条插值的必需前提)、要假设检验(应该不会有人忘记，因为软件自动进行)</p><h2 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h2>$$r = \frac{\sum(X-\bar{X})(Y-\bar{Y})}{\sqrt{ \sum(X - \bar{X})^2\sum(Y-\bar{Y})^2 }}=\frac{l_{XY}}{\sqrt{ l_{XX}l_{YY} }}$$<p>大部分类似于回归</p><h2 id="秩相关"><a href="#秩相关" class="headerlink" title="秩相关"></a>秩相关</h2><p>适用于：不满足双变量正态分布、总体分布未知、等级表示的原始数据</p><h2 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h2><p>类似于线性回归</p><h2 id="筛选自变量"><a href="#筛选自变量" class="headerlink" title="筛选自变量"></a>筛选自变量</h2><p>后退法、前进法、逐步法<br>这里筛选自变量其实还有一个很重要的原因，就是可能原来不显著的结果在筛选变量后变得显著。</p><h1 id="重复测量资料的方差分析"><a href="#重复测量资料的方差分析" class="headerlink" title="重复测量资料的方差分析"></a>重复测量资料的方差分析</h1><p>重复测量实验能不能进行普通的成组检验(参数或非参数)？答案是否定的，因为不管是参数与非参数检验均需要保证样本之间的独立性和随机性，但是重复测量的数据一定有相关性。<br>为了避免时间因素，所以需要同时考虑分组与重复测量的时间点.</p><h2 id="随机区组设计方差分析法"><a href="#随机区组设计方差分析法" class="headerlink" title="随机区组设计方差分析法"></a>随机区组设计方差分析法</h2><p>前提：满足“球对称”假设</p><h3 id="重复测量数据的两因素两水平分析"><a href="#重复测量数据的两因素两水平分析" class="headerlink" title="重复测量数据的两因素两水平分析"></a>重复测量数据的两因素两水平分析</h3><p>当前后差值不满足方差齐性时。进行重复测量设计方差分析，分析表的阅读方式与之前的随机区组设计类似。</p><h3 id="两因素多水平重复测定资料的方差分析"><a href="#两因素多水平重复测定资料的方差分析" class="headerlink" title="两因素多水平重复测定资料的方差分析"></a>两因素多水平重复测定资料的方差分析</h3><p>进行重复测量设计方差分析，分析表的阅读方式与之前的随机区组设计类似。</p><h1 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h1><h2 id="交叉设计"><a href="#交叉设计" class="headerlink" title="交叉设计"></a>交叉设计</h2><p>分组同时需要分为2阶段，不同阶段进行不同处理。<br>前提：需要满足无延后效应</p><h2 id="拉丁方设计"><a href="#拉丁方设计" class="headerlink" title="拉丁方设计"></a>拉丁方设计</h2><p>通过拉丁字母组成方阵，在同一行或同一列内没有重复的字母。<br>这样你就会发现，在每个时间段每种处理方式都有1个样本。</p><h2 id="正交设计"><a href="#正交设计" class="headerlink" title="正交设计"></a>正交设计</h2><h3 id="表头设计"><a href="#表头设计" class="headerlink" title="表头设计"></a>表头设计</h3><p><img src="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_8.png" alt="picForEvibased_8" title="picForEvibased_8"><br>设计流程如下：</p><ol><li>如果我们希望研究的是每个因子的2阶交互因子。</li><li>将A，B放在1，2列内。</li><li>对于$A \times B$我们查看A,B因子所处的列1，2列，查交互作用表中1行2列，得到3。所以将$A \times B$放于第3列，</li><li>将C放在第4列，研究$A \times C$，我们查看1行4列得到第5列，将其放置在第5列。</li></ol><h1 id="生存时间资料分析"><a href="#生存时间资料分析" class="headerlink" title="生存时间资料分析"></a>生存时间资料分析</h1><h2 id="生存资料的特点"><a href="#生存资料的特点" class="headerlink" title="生存资料的特点"></a>生存资料的特点</h2><ol><li>存在删失值(如何处理？)</li><li>效应变量有2种</li><li>分布类型复杂</li></ol><h3 id="小样本生存率的K-M估计"><a href="#小样本生存率的K-M估计" class="headerlink" title="小样本生存率的K-M估计"></a>小样本生存率的K-M估计</h3><p>删失值不纳入死亡率的计算。</p><h3 id="大样本生存率的寿命表法估计"><a href="#大样本生存率的寿命表法估计" class="headerlink" title="大样本生存率的寿命表法估计"></a>大样本生存率的寿命表法估计</h3><p>删失人员只作为半个人。</p><h3 id="log-rank检验"><a href="#log-rank检验" class="headerlink" title="log-rank检验"></a>log-rank检验</h3><p>用于检验2组人群生存率是否存在差异性</p><h3 id="Cox风险比例模型"><a href="#Cox风险比例模型" class="headerlink" title="Cox风险比例模型"></a>Cox风险比例模型</h3><p>可以研究不同协变量对于生存率的影响</p><p>非参数检验的流程<br><img src="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/%E9%9D%9E%E5%8F%82%E6%95%B0%E6%A3%80%E9%AA%8C.drawio.png" alt="非参数检验" title="非参数检验"><br>生存分析的流程<br><img src="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/%E7%94%9F%E5%AD%98%E5%88%86%E6%9E%90.drawio.png" alt="生存分析" title="生存分析"></p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>CLIP</title>
      <link href="/2025/05/08/CLIP/"/>
      <url>/2025/05/08/CLIP/</url>
      
        <content type="html"><![CDATA[<p>CLIP将计算机视觉与自然语言处理相结合，获得更加优秀的迁移性能与zero-shot效果。同时打破了固定标签的定式。</p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>针对目前已有的计算机视觉系统，大部分都是使用固定的标签集合，这限制了它的泛化性能和可用性。<br>于是作者选择通过图片的语言文本来进行图像识别。作者爬取了4亿张图片以进行模型的预训练。在预训练完成后，作者在30多个任务上进行了测试。<br>在ImageNet数据集内，CLIP模型在zero-shot的情况下便已经与训练完成的Resnet50打成平手。</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>GPT作为一个”Text-in-text-out”的经典案例，反映了弱监督工作的可行性，于是作者决定提出使用图片与文字结合，进行CLIP模型的研究。<br>已有相关研究VirTex, ICMLM和ConVIRT方法虽然接近，但是数据集规模较少，而有些弱监督模型的准确率较高，其依赖的是极度大量数据集，所以作者考虑到是否能够同时满足以上条件，进而研究出新的方法。在预实验结果中，使用已有模型(ConVIRT)与新的数据，其模型在zero-shot上成功体现出极好的效果。同时<strong>模型效果与模型大小呈现正相关</strong>。</p><h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>作者发现目前已有数据集不能满足训练需求，所以选择自己开发数据集。</p><h2 id="Pre-Training-Method"><a href="#Pre-Training-Method" class="headerlink" title="Pre-Training Method"></a>Pre-Training Method</h2><p>作者针对该数据的标签，决定使用“图像-文本配对”的方法来进行训练，这是因为如果采用标签生成或者词袋模型，训练过程较慢。<br>同时作者也采用对比学习的方法进行训练。<br>作者在训练过程中其实是发现了两个重要的事情。</p><h3 id="非线性映射"><a href="#非线性映射" class="headerlink" title="非线性映射"></a>非线性映射</h3><p>CLIP（Contrastive Language–Image Pre-training）在其两个编码器（图像编码器与文本编码器）末端各插入了一个 <strong>线性映射</strong>（linear projection）层，将各自的表示向量映射到同一多模态嵌入空间，以便计算余弦相似度并进行对比损失优化。在早期的对比或自监督学习框架（如 SimCLR、MoCo 等）中，人们常使用 <strong>非线性映射头</strong>（two-layer MLP + ReLU + BN）来获得更好的特征表示；而 CLIP 的作者发现，去掉这层非线性映射，仅保留简单的线性映射，训练效率与效果几乎无差异，因此选择了更为简洁的设计。</p><h3 id="未出现过拟合"><a href="#未出现过拟合" class="headerlink" title="未出现过拟合"></a>未出现过拟合</h3><p>作者在训练过程中未出现过拟合。<em>其实挺好理解的，这么大的数据集能过拟合也是神人了</em><br>作者对于数据的处理也仅仅只有裁剪，而并未采用更多的高级方法。作者对于温度系数 $t$ 也仅仅只是进行</p><h2 id="Choosing-and-Scaling-the-Model"><a href="#Choosing-and-Scaling-the-Model" class="headerlink" title="Choosing and Scaling the Model"></a>Choosing and Scaling the Model</h2><h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">image_encoder: Resnet or Vision Transformer</span><br><span class="line">text_encoder: CBOW or Text Transformer</span><br><span class="line">I: n * h * w * c, minibatch of aligned images</span><br><span class="line">T: n * l, minibatch of aligned texts</span><br><span class="line">t: learned temperature parameter</span><br><span class="line"></span><br><span class="line"># extract feature representations of each modality</span><br><span class="line">I_f = image_encoder(I) #[n, d_i]</span><br><span class="line">T_f = text_encoder(T) #[n, d_t]</span><br><span class="line"></span><br><span class="line"># joint multimodal embedding [n, d_e]</span><br><span class="line"># linear projectin</span><br><span class="line"># 这里是多模态常见的合成方法</span><br><span class="line">I_e = l2_normalize(np.dot(I_f, W_i), axis = 1)</span><br><span class="line">T_e = l2_normalize(np.dot(T_f, W_t), axis = 1)</span><br><span class="line"></span><br><span class="line"># scaled pairwise cosine similarities</span><br><span class="line">logits = np.dot(I_e, T_e.T) * np.exp(t)</span><br><span class="line"></span><br><span class="line"># symmetric loss function</span><br><span class="line"># 这里的正样本是对角线上的数据，也就是第一排第一个，第二排第二个。这里对比学习的思路。</span><br><span class="line">labels  = np.arrang(n)</span><br><span class="line">loss_i = cross_entropy_loss(logits, labels, aixs = 0)</span><br><span class="line">loss_t = cross_entropy_loss(logits, labels, aixs = 1)</span><br><span class="line">loss = (loss_i + loss_t)/2</span><br></pre></td></tr></table></figure><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>作者训练了5个ResNets和3个Vision Transformers<br>ResNet: ResNet-50, ResNet-101, EfficientNet-style model 4x, 16x and 64x the compute of a ResNet-50<br>Vision Transformer: ViT-B&#x2F;32 Vit-B&#x2F;16 ViT-L&#x2F;14<br>训练32个epoch，Adam优化器<br>作者对于ViT-L&#x2F;14在336像素的图片上又额外训练了一个epoch，并将其标注为ViT-L&#x2F;14@336px. 后面使用的模型均为ViT-L&#x2F;14@336px</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p><img src="/2025/05/08/CLIP/CLIP_inference.png" alt="CLIP_inference" title="CLIP_inference"></p><ol><li>通过Prompt Engineering构造选项(备选方案如plane, car, dog -&gt; A photo of plane, car, dog)经过Text Encoder计算为向量。</li><li>将图片经过Encoder转化为图像，计算图像与词向量的余弦相似度</li></ol><h3 id="Prompt-Engineering-and-Ensembling"><a href="#Prompt-Engineering-and-Ensembling" class="headerlink" title="Prompt Engineering and Ensembling"></a>Prompt Engineering and Ensembling</h3><p>作者在该段提出了：多义性(polysemy)和标签多为短句的问题。并对于这两种问题，其提出使用提示词模板来解决，例如模板”A photo of a {label}”. 该方法提升准确率1.3%<br>同时，对于特定数据集，可以将模型进一步扩充，如对于Oxford-IIIT Pets, 则可将模板改为”A photo of a {label}, a type of pets”.</p><h3 id="效果分析"><a href="#效果分析" class="headerlink" title="效果分析"></a>效果分析</h3><ol><li>CLIP(zero-shot) vs linear probe Resnet50: 对于有具体物体的模型CLIP表现更佳，而抽象概念的数据则相对较差(如数字、纹理)。</li><li>CLIP vs previous few-shot method: 远超既往小样本学习结果。CLIP在zero-shot的情况下，准确率已经和BiT-M的16-shot的效果相近。但是在部分few-shot上CLIP反而不如自己的zero-shot。</li><li>CLIP使用linear probe效果，全数据集训练效果依旧强劲。</li></ol><h1 id="Comparison-to-Human-Performance"><a href="#Comparison-to-Human-Performance" class="headerlink" title="Comparison to Human Performance"></a>Comparison to Human Performance</h1><p><img src="/2025/05/08/CLIP/Comparison_to_human.png" alt="Comparison_to_human" title="Comparison_to_human"></p><h1 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h1><ol><li>距离已有模型的SOTA有较大距离，只是优于ResNet50的Baseline.</li><li>CLIP对于部分数据的效果不佳，比如细分类的数据集、抽象概念的数据(数字、异常提取)。</li><li>对于数据分布偏差极大的数据集，效果依旧较差。例如MNIST数据集效果较差，作者分析是因为400M图片中均无MNIST类似的图片。</li><li>CLIP不是生成式模型，仍然需要提供一些选项。</li><li>CLIP模型对于数据的应用并不高效。</li><li>希望能够产生一种新的，针对Zero-shot的数据集。</li><li>数据并无清洗，可能存在偏见。</li><li>CLIP在few-shot的情况下并不如zero-shot优秀。</li></ol><hr><p>Cover image icon by <a href="https://www.flaticon.com/authors/becris" title="Becris">Becris</a> from <a href="https://www.flaticon.com/free-icons/deep-learning" title="deep learning icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Propensity Score</title>
      <link href="/2025/05/06/Propensity-Score/"/>
      <url>/2025/05/06/Propensity-Score/</url>
      
        <content type="html"><![CDATA[<p>The propensity score makes it so that you don’t have to condition on the entirety of X to achieve independence of the potential outcomes on the treatment. It is sufficient to condition on this single variable, which is the propensity score<br>$$(Y_{0},Y_{1}) \perp T|e(x)$$<br><em>The propensity score is the conditional probability of receiving the treatment, right? So we can think of it as some sort of function that converts X into the treatment T. The propensity score makes this middle ground between the variable X and the treatment T. If we show this in a causal graph, this is what it would look like.</em><br><img src="/2025/05/06/Propensity-Score/casual_7.png" alt="casual_7" title="casual_7"></p><h1 id="law-of-iterated-expectations"><a href="#law-of-iterated-expectations" class="headerlink" title="law of iterated expectations"></a><strong>law of iterated expectations</strong></h1><p>$$E[X]&#x3D;E[E[X|Y]]$$<br><em>Proof</em></p>$$\begin{aligned}E[E[Y|X]]&=\int_{-\infty}^\infty\int_{-\infty}^\infty yp_{Y|X}(y|x)p_{X}(x)dydx\\\\&=\int_{-\infty}^\infty\int_{-\infty}^\infty yp(x,y)dydx\\\\&=\int_{-\infty}^\infty y\int_{-\infty}^\infty p(x,y)dxdy\\\\&=\int_{-\infty}^\infty yp_{Y}(y)dy\\\\&=E[Y]\end{aligned}$$<p>具体内容参考<a href="https://www.zhihu.com/question/22996373/answer/3274277491">统计学基础</a><br> 其实我们可以看出，所谓$e(x)$就是$E[T|X]$也就是情形X下收到treatment的概率<br> $$E[T|e(x)]&#x3D;E[E[T|e(x),X]|e(x)]&#x3D;E[e(x)|e(x)]&#x3D;e(x)$$<br>其中$E[T|e(x),X]&#x3D;E[T|X]&#x3D;e(x)$</p><h1 id="Inverse-Probability-of-Treatment-Weighting-IPTW"><a href="#Inverse-Probability-of-Treatment-Weighting-IPTW" class="headerlink" title="Inverse Probability of Treatment Weighting (IPTW)"></a>Inverse Probability of Treatment Weighting (IPTW)</h1>$$E[Y|X,T=1]-E[Y|X,T=0]=E\left[ \frac{Y}{e(x)}|X,T=1 \right]P(T)-E\left[ \frac{Y}{1-e(x)}|X,T=0 \right](1-P(T))$$<p>直观上理解就是本来应该不被治疗的样本如果接受了治疗，那这个样本在分析的过程中会更加有价值<br>我们可以将其化简为$$E\left[ Y\frac{{T-e(x)}}{e(x)(1-e(x))} \right]$$<br><em>Proof</em></p>$$\begin{aligned}E[Y|X,T=1]-E[Y|X,T=0]&=E\left[ \frac{Y}{e(x)}|X,T=1 \right]P(T)-E\left[ \frac{Y}{1-e(x)}|X,T=0 \right](1-P(T))\\\\&=E\left[ \frac{{YT}}{e(x)}\bigg|X \right]-E\left[ \frac{Y(1-T)}{1-e(x)}\bigg|X \right]\\\\&=E\left[ \frac{YT(1-e(x))}{e(x)(1-e(x))}-\frac{Y(1-T)e(x)}{e(x)(1-e(x))} \bigg| X\right]\\\\&=E\left[ Y\frac{{T-e(x)}}{e(x)(1-e(x))} \bigg | X\right ]\end{aligned}$$<p><strong>positivity assumption</strong> of causal inference: Notice that this estimator requires that $e(x)$ and $1−e(x)$ are larger than zero. In words, this means that everyone needs to have at least some chance of receiving the treatment and of not receiving it. Another way of stating this is that the treated and untreated distributions need to overlap.</p><h1 id="Propensity-Score-Estimation"><a href="#Propensity-Score-Estimation" class="headerlink" title="Propensity Score Estimation"></a>Propensity Score Estimation</h1><p>代码见<a href="https://matheusfacure.github.io/python-causality-handbook/11-Propensity-Score.html">11 - Propensity Score — Causal Inference for the Brave and True</a></p><h1 id="Standard-Error"><a href="#Standard-Error" class="headerlink" title="Standard Error"></a>Standard Error</h1><p>首先考虑加权平均的方差$$\sigma^2_{w}&#x3D;\frac{\sum_{i&#x3D;1}^nw_{i}(y_{i}-\hat{\mu})^2}{\sum_{i&#x3D;1}^nw_{i}}$$<br>However, we can only use this if we have the true propensity score. If we are using the estimated version of it, $\hat{P}(x)$, we need to account for the errors in this estimation process. The easiest way of doing this is by bootstrapping the whole procedure. This is achieved by sampling with replacement from the original data and computing the ATE like we did above. We then repeat this many times to get the distribution of the ATE estimate.</p><h1 id="Common-Issues-with-Propensity-Score"><a href="#Common-Issues-with-Propensity-Score" class="headerlink" title="Common Issues with Propensity Score"></a>Common Issues with Propensity Score</h1><p><strong>Propensity score doesn’t need to predict the treatment very well. It just needs to include all the confounding variables</strong>.<br><em>To see this, consider the following example (adapted from Hernán’s Book). You have 2 schools, one of them apply the growth mindset seminar to 99% of its students and the other to 1%. Suppose that the schools have no impact on the treatment effect (except through the treatment), so it’s not necessary to control for it. If you add the school variable to the propensity score model, it’s going to have a very high predictive power. However, by chance, we could end up with a sample where everyone in school A got the treatment, leading to a propensity score of 1 for that school, which would lead to an infinite variance. This is an extreme example, but let’s see how it would work with simulated data.</em><br>其实就是当treatment和non treatment组之间特征没有过多的重叠时，对于接近0.5的概率附近样本较少，这会让方差增大<strong>This lack of balancing can generate some bias, because we will have to extrapolate the treatment effect to unknown regions.As a general rule of thumb, you are in trouble if any weight is higher than 20 (which happens with an untreated with propensity score of 0.95 or a treated with a propensity score of 0.05).</strong><br><strong>if the distributions don’t overlap, your data is probably not enough to make a causal conclusion anyway. To gain some further intuition about this, we can look at a technique that combines propensity score and matching</strong><br><img src="/2025/05/06/Propensity-Score/casual_8.png" alt="casual_8" title="casual_8"></p><h1 id="Propensity-Score-Matching"><a href="#Propensity-Score-Matching" class="headerlink" title="Propensity Score Matching"></a>Propensity Score Matching</h1><p>就是针对Propensity Score进行一次matching，从这个角度看，Propensity Score其实就是一种维度压缩，而我们就是再计算经过维度压缩后的特征的matching<br>值得注意的是，倾向性评分匹配并不适合bootstrap以估计SE[ON THE FAILURE OF THE BOOTSTRAP FOR MATCHING ESTIMATORS](<a href="https://economics.mit.edu/sites/default/files/publications/ON%20THE%20FAILURE%20OF%20THE%20BOOTSTRAP%20FOR.pdf">On the Failure of the Bootstrap for Matching Estimators</a>)</p><hr><p>Thanks for watching! and this my learning note of the blog of <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>.<br>感谢观看，这是我学习<a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>博客的笔记。<br>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 因果推断 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 因果推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Stats Review</title>
      <link href="/2025/05/06/Stats-Review/"/>
      <url>/2025/05/06/Stats-Review/</url>
      
        <content type="html"><![CDATA[<blockquote><p><em>“Some equations are dangerous if you know them, and others are dangerous if you do not. The first category may pose danger because the secrets within its bounds open doors behind which lies terrible peril. The obvious winner in this is Einstein’s iconic equation $E&#x3D;mc^2$, for it provides a measure of the enormous energy hidden within ordinary matter. […] Instead I am interested in equations that unleash their danger not when we know about them, but rather when we do not. Kept close at hand, these equations allow us to understand things clearly, but their absence leaves us dangerously ignorant.”</em></p></blockquote><p align="right">——Howard Wainer</p># Moivre’s equation$$SE=\frac{\sigma}{\sqrt{ n }}$$SE: standard error; $\sigma$: standard deviation; n: sample sizeeg: fewer students $\neq$ better eduacation, sometimes just **Greater SE**<p><img src="/2025/05/06/Stats-Review/casual_1.png" alt="casual_1" title="casual_1"></p><p>As Taleb puts it in his book, Fooled by Randomness:</p><blockquote><p>Probability is not a mere computation of odds on the dice or more complicated variants; it is the acceptance of the lack of certainty in our knowledge and the development of methods for dealing with our ignorance.</p></blockquote><h1 id="Standard-Error-of-Our-Estimates"><a href="#Standard-Error-of-Our-Estimates" class="headerlink" title="Standard Error of Our Estimates"></a>Standard Error of Our Estimates</h1><p>first calculate standard deviation:<br>$$\hat{\sigma}&#x3D;\sqrt{ \frac{1}{N-1}\sum^N_{i&#x3D;1}(x_{i}-\bar{x})^2 }$$<br>$$SE&#x3D;\frac{\sigma}{\sqrt{ n }}$$</p><h1 id="Confidence-Intervals"><a href="#Confidence-Intervals" class="headerlink" title="Confidence Intervals"></a>Confidence Intervals</h1><p>To calculate the confidence interval, we use the <strong>central limit theorem</strong>. This theorem states that <strong>means of experiments are normally distributed</strong>. From statistical theory, we know that 95% of the mass of a normal distribution is between 2 standard deviations above and below the mean. Technically, 1.96, but 2 is close enough.<br>The Standard Error of the mean serves as our estimate of the distribution of the experiment means. So, if we multiply it by 2 and add and subtract it from the mean of one of our experiments, we will construct a 95% confidence interval for the true mean.<br>你提到的这个观点其实非常重要，关于信赖区间（Confidence Interval，简称CI）的解释确实有一些常见误解。在频率统计学中，信赖区间并不是直接描述“某个特定区间包含真实均值的概率”，而是描述了通过重复实验或样本抽取，使用相同的统计方法计算出的区间包含真实参数的频率。<br>具体来说，95%置信区间的解释是：如果你在同样的条件下进行很多次独立的实验，每次计算置信区间，那么有95%的置信区间会包含真实的总体参数（例如，均值）。但这并不意味着某一个特定的区间有95%的概率包含真实值，因为真实值要么在这个区间内，要么不在。<br>为了更清晰地理解，可以举个例子：<br>假设我们进行100次相同的实验，每次都计算一个95%的置信区间。假如有95次的区间包含了真实的总体均值，而5次不包含，那么我们可以说：我们的统计方法是可靠的，95%的信赖区间会包含真实的均值。但对于单个实验的结果，我们不能说“这个区间有95%的概率包含真实均值”。<br>简而言之，CI是描述统计方法的长期表现，而不是对某个具体实验结果的概率评估。</p><h1 id="Hypothesis-Testing"><a href="#Hypothesis-Testing" class="headerlink" title="Hypothesis Testing"></a>Hypothesis Testing</h1><p>$$\mathcal{N}(\mu_{1}, \sigma_{1}^2)+\mathcal N(\mu_{2}, \sigma_{2}^2)&#x3D;\mathcal{N}(\mu_{1}+\mu_{2}, \sigma^2_{1}+\sigma_{2}^2)$$<br>$$\mathcal{N}(\mu_{1}, \sigma_{1}^2)-\mathcal N(\mu_{2}, \sigma_{2}^2)&#x3D;\mathcal{N}(\mu_{1}-\mu_{2}, \sigma^2_{1}+\sigma_{2}^2)$$<br>And the same for SE<br>$$\begin{aligned}<br>&amp;\mu_{diff} &#x3D; \mu_{1} - \mu_{2}<br>\\<br>&amp;SE_{diff} &#x3D; \sqrt{ SE_{1}^2+ SE_{2}^2 }&#x3D;\sqrt{ \frac{\sigma_{1}^2}{N_{1}} + \frac{\sigma_{2}^2}{N_{2}} }<br>\end{aligned}$$</p><h2 id="z-statistic"><a href="#z-statistic" class="headerlink" title="z-statistic"></a>z-statistic</h2>$$\begin{aligned}z &=\frac{{\mu_{diff}-H_{0}}}{SE}\\\\&=\frac{{\mu_{1}-\mu_{2}-H_{0}}}{\sqrt{ \frac{\sigma_{1}^2}{N_{1}} + \frac{\sigma_{2}^2}{N_{2}} }}\end{aligned}$$<p>The z statistic is a measure of how extreme the observed difference is. We will use contradiction to test our hypothesis that the difference in the means is statistically different from zero. We will assume that the opposite is true; we will assume that the difference is zero. This is called a <strong>null hypothesis</strong>, or $H_{0}$ .<br>Under $H_{0}$, the z statistic follows a standard normal distribution. So, if the difference is indeed zero, we would see the z statistic within 2 standard deviations of the mean 95% of the time. The direct consequence is that if z falls above or below 2 standard deviations, we can reject the null hypothesis with 95% confidence.<br><strong>To specify, $H_{0}$ stands for $\mu_{1}-\mu_{2}$, which is always 0</strong><br><strong>z-statistic</strong>（z统计量）在假设检验中通常用于检验两个样本均值之间的差异，尤其是在满足某些条件下，比如样本量较大（通常n &gt; 30）或者总体标准差已知的情况下。z检验常见的应用有：</p><ol><li><strong>单样本z检验</strong>：用于检验一个样本的均值是否与已知的总体均值有显著差异。<ul><li>例如，假设你想检验某个工厂生产的产品的平均重量是否等于标称值。</li></ul></li><li><strong>两样本z检验</strong>：用于检验两个独立样本的均值是否有显著差异。<ul><li>例如，你想比较两个不同工厂生产的产品的平均重量是否相同。</li></ul></li><li><strong>z检验的条件</strong>：通常要求已知总体标准差，或者样本量足够大以使得样本标准差可以较好地估计总体标准差。这个条件也可以通过<strong>中心极限定理</strong>来理解，即大样本的分布趋近于正态分布。</li></ol><h1 id="P-value"><a href="#P-value" class="headerlink" title="P-value"></a>P-value</h1><p><strong>the p-value is the probability of obtaining test results at least as extreme as the results actually observed during the test, assuming that the null hypothesis is correct</strong><br>P值是假设零假设成立的前提下，获取至少与实验结果一样极端的数据的概率<br>It measures how unlikely it is that you are seeing a measurement if the null hypothesis is true. Naturally, this often gets confused with the probability of the null hypothesis being true. Note the difference here. The p-value is NOT $P(H_{0}|data)$, but rather $P(data|H_{0})$.<br>也就是说，P-value不是说给定数据的前提下，$H_{0}$成立的概率，而是假设$H_{0}$成立的前提下，获得该数据的概率<br><img src="/2025/05/06/Stats-Review/casual_2.png" alt="casual_2" title="casual_2"><br>以上为单边检验，此外还有双边检验，<strong>双边检验</strong>关注参数是否偏离某个值，无论偏离的方向是增大还是减小。双边检验相较于单边更加难以显著，这是因为双边同时需要考虑两边的偏差，而单边只需要考虑一边的偏差，也就意味着单边其实已经有了一个前提，也就是我们已知偏差会位于左侧(或者右侧)，正是这个已知的事实减少了样本空间的大小，让概率升高。</p><h2 id="双边检验的必要性"><a href="#双边检验的必要性" class="headerlink" title="双边检验的必要性"></a><strong>双边检验的必要性</strong></h2><h3 id="a-无法预知偏离的方向时"><a href="#a-无法预知偏离的方向时" class="headerlink" title="a. 无法预知偏离的方向时"></a><strong>a. 无法预知偏离的方向时</strong></h3><ul><li>如果没有足够的理论依据或先验知识来预测偏差的方向，双边检验是<strong>唯一合理的选择</strong>。在这种情况下，使用单边检验可能导致忽视另一个方向上的潜在效应。</li></ul><h3 id="b-安全性和准确性考虑"><a href="#b-安全性和准确性考虑" class="headerlink" title="b. 安全性和准确性考虑"></a><strong>b. 安全性和准确性考虑</strong></h3><ul><li>在医学、工程和其他关键领域，错误地选择单边检验可能会导致过度自信或误判。尤其在某些实验中，我们无法确保效应的方向，如果单边检验的假设方向错误，可能会导致严重的后果。例如，药物效果的测试，如果只假设药物会增强效果而忽视了副作用，可能会导致对副作用的忽视。</li></ul><h3 id="c-多假设检验中的一致性"><a href="#c-多假设检验中的一致性" class="headerlink" title="c. 多假设检验中的一致性"></a><strong>c. 多假设检验中的一致性</strong></h3><ul><li>在某些复杂的多假设检验场景中，使用双边检验可以保持检验的一致性。例如，分析基因表达时，如果我们事先不知道某个基因是否会上调或下调，双边检验可以确保我们对上调和下调的效应都进行充分检验。</li></ul><hr><p>Thanks for watching! and this my learning note of the blog of <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>.<br>感谢观看，这是我学习<a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>博客的笔记。<br>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 因果推断 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 因果推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Beyond Confounders</title>
      <link href="/2025/05/06/Beyond-Confounders/"/>
      <url>/2025/05/06/Beyond-Confounders/</url>
      
        <content type="html"><![CDATA[<h1 id="Good-Control"><a href="#Good-Control" class="headerlink" title="Good Control"></a>Good Control</h1><p>Sometimes treatment’s effect on the outcome is much smaller than other factors, in order to figure out the effect of treatment, we should control other factors because:<br><strong>If a variable is a good predictor of the outcome, it will explain away a lot of its variance.</strong><br>To demonstrate this, let’s resort to the partialling out way of breaking regression into 2 steps.<br>First, we will regress the treatment, email, and the outcome, payments, on the additional controls, credit limit and risk score.<br>Second, we will regress the residual of the treatment on the residuals of payments, both obtained in step 1. (This is purely pedagogical, in practice you won’t need to go through all the hassle).<br>To wrap it up, anytime we have a control that is a good predictor of the outcome, even if it is not a confounder, adding it to our model is a good idea. It helps lowering the variance of our treatment effect estimates. Here is a picture of what this situation looks like with causal graphs.<br><img src="/2025/05/06/Beyond-Confounders/casual_4.png" alt="casual_4" title="causal_4"></p><p>其实这里与我们之前将confounder针对treatment回归的有相似之处又有不同之处：<br>之前将confounder针对treatment的回归主要依赖于confounder同时对treatment和outcome有影响，所以我们需要打断confounder的路径，造成随机化的情况。<br>而这里的factor其实并非confounder，这里是由于多种因素同时存在造成的“大数吃小数”的情况，所以需要将factor对outcome回归后，在将残差对于treatment回归。</p><h1 id="Bad-Control"><a href="#Bad-Control" class="headerlink" title="Bad Control"></a>Bad Control</h1><p>we should <strong>NOT</strong> add controls that are just good predictors of the treatment, because they will increase the variance of our estimates.<br>控制与treatment强相关的因素将会导致treatment的分组不均匀，从而提高variance，进而导致结果的不显著。</p><h2 id="Selection-Bias"><a href="#Selection-Bias" class="headerlink" title="Selection Bias"></a>Selection Bias</h2><p><strong>selection bias is when we control for a common effect or a variable in between the path from cause to effect.</strong>(参考[[Graph Casual Model]]中的Selection Bias)<br>Here is some examples:</p><ol><li>Adding a dummy for paying the entire debt when trying to estimate the effect of a collections strategy on payments.</li><li>Controlling for white vs blue collar jobs when trying to estimate the effect of schooling on earnings</li><li>Controlling for conversion when estimating the impact of interest rates on loan duration</li><li>Controlling for marital happiness when estimating the impact of children on extramarital affairs</li><li>Breaking up payments modeling E[Payments] into one binary model that predict if payment will happen and another model that predict how much payment will happen given that some will: E[Payments|Payments&gt;0]*P(Payments&gt;0)</li></ol><h2 id="COP-A-special-case-of-Selection-Bias"><a href="#COP-A-special-case-of-Selection-Bias" class="headerlink" title="COP: A special case of Selection Bias"></a>COP: A special case of Selection Bias</h2><p>这个问题来自与一个常见的问题：如果遇到0，是否要将其舍去，其实这个问题就是针对舍去0的模型：<br>我们在针对一些相对稀疏的outcome进行推断时，常常倾向于删去0值，但是这样会导致我们舍去了一部分正常为0的数据，以基因表达为例；<br>如果我们对于某群体给予某种药物，则必然有一部分基因在大部分情况下均不表达，这时有人提出：为什么我们不只看那部分表达的个体在治疗前后的基因表达改变的情况。<br>但是，这个想法是错误的！<br>直观上讲，就是我们大可以将群体分为2群，一群是在药物治疗后基因表达增加，而这个群体本身就有基因表达；二群是在药物治疗后基因表达从0到1，这个群体本身无基因表达。如果我们简单去掉0数据，则可能带来：二群的治疗前的数据的丢失。最后在研究因果效应时会导致因果效应偏小。<br>理论上推导如下：</p>$$\begin{aligned}&E[Y|T=1]-E[Y|T=0]\\\\=&E[Y|Y>0,T=1]P(Y>0|T=1)+E[Y|Y>0,T=0]P(Y>0|T=0)(删去E[Y|Y=0])\\\\=&(P(Y>0|T=1)-P(Y>0|T=0))E[Y|Y>0,T=1]\\\\+&(E[Y|Y>0,T=1]-E[Y|Y>0,T=0])P(Y>0|T=0)\end{aligned}$$<p>上式子中，前者代表“Participation Effect”，及治疗前后值从0到1的改变情情况，即一群的预期效益；后者则代表”COP”，即治疗前后增加的基因表达数量，即二群的预期效益<br>数学上完全正确，问题出在估计$E[Y|Y&gt;0|T&#x3D;1]-E[Y|Y&gt;0|T&#x3D;0]$过程中</p>$$\begin{aligned}&E[Y|Y>0,T=1]-E[Y|Y>0,T=0]\\\\=&E[Y_{1}|Y_{1}>0]-E[Y_{0}|Y_{0}>0]\\\\=&E[Y_{1}-Y_{0}|Y_{1}>0] + (E[Y_{0}|Y_{1}>0]-E[Y_{0}|Y_{0}>0]) \end{aligned}$$<p>这就是我们常见的bias公式，我们可以看到，前面的那个估计正确，但是后面可能会出现bias，也就是说$E[Y_{0}|Y_{1}&gt;0]&lt;E[Y_{0}|Y_{0}&gt;0]$, 因为会有部分$Y_{0}&#x3D;0$的情况被排除。<br><img src="/2025/05/06/Beyond-Confounders/casual_5.png" alt="casual_5" title="casual_5"><br><strong>注意：上式子我们需要求得的是$E[Y_{1}-Y_{0}|Y_{1}&gt;0]$，其中$E[Y|T&#x3D;1]-E[Y|T&#x3D;0]$，是我们观察到的数据，主要问题就是我们在计算过程中可能会把$E[Y_{0}|Y_{1}&gt;0]-E[Y_{0}|Y_{0}&gt;0]$所忽视</strong><br><em>这里的思路类似于[[mathematic&#x2F;Casual inference&#x2F;Introduction]]中的思路，就是计算ATT，但是我们加了个前提就是要大于0，大于0就让无法ATT的转化无法正常进行，因为这使得引入了新的bias，很奇妙吧，虽然过程不同，但是最后归于公式的时候却是相同的</em><br>相当有趣的是这里我们依旧可以用Selection Bias解释，这是因为治疗与否影响了基因表达是否大于0，同时outcome也对基因表达是否大于0有影响，构成了一个Collider，一旦控制，就会带来Selection Bias.</p><hr><p>Thanks for watching! and this my learning note of the blog of <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>.<br>感谢观看，这是我学习<a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>博客的笔记。<br>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 因果推断 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 因果推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循证医学7-8周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="二项分布与poisson分布及其应用"><a href="#二项分布与poisson分布及其应用" class="headerlink" title="二项分布与poisson分布及其应用"></a>二项分布与poisson分布及其应用</h1><h2 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h2>$$P(X) = C^x_{n} \pi^x (1-\pi)^{n-x}$$$$\mu = n\pi, \sigma^2={ n\pi(1-\pi) }$$<p>样本率的方差计算同正态分布时的均值的方差计算：<br>$$S_{p}&#x3D;\sqrt{ \frac{p(1-p)}{n} }$$<br>总体率置信区间计算：</p><ol><li>查表方法</li><li>正态近似法(样本容量&gt;100, $\pi \approx 0.5$)</li></ol>$$\begin{aligned}u &= \frac{{p-\pi_{0}}}{\sigma_{p}} \\\sigma_{p} &= \sqrt{ \frac{\pi_{0}(1-\pi_{0})}{n} }\end{aligned}$$*既往死亡率为40%，实验中120名病人死亡30名，统计推断：H_0: 均值不等H_1: 均值相等确定alpha值为0.05，双尾检验*$$\begin{aligned}\sigma_{p}&=\sqrt{ \frac{\pi_{0}(1-\pi_{0})}{n} }\\&=\sqrt{ \frac{0.4(1-0.4)}{120} }\\&\approx 0.045\\u&=\frac{{p-\pi_{0}}}{\sigma_{p}}\\&=\frac{{\frac{30}{120} - 0.4}}{0.045}\\&=-3.333\end{aligned}$$<p><em>显著：拒绝H_0，因为超过了3个标准差</em></p><h2 id="Poisson分布"><a href="#Poisson分布" class="headerlink" title="Poisson分布"></a>Poisson分布</h2><p>$$P(X)&#x3D; \frac{\lambda^x}{x!}e^{-\lambda}, X&#x3D;0,1,2,\dots$$<br>$$\mu&#x3D;\lambda, \sigma^2&#x3D;\lambda$$<br>总体率置信区间计算：</p><ol><li>查表方法</li><li>正态近似法($\mu \approx 0.5$)<br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_6.png" alt="分布间关系" title="分布间关系"></li></ol><h1 id="RR值和OR值的估计"><a href="#RR值和OR值的估计" class="headerlink" title="RR值和OR值的估计"></a>RR值和OR值的估计</h1><p>RR值适用于：队列研究(risk ratio)<br>OR值适用于：病例对照研究(odds ratio)</p><table><thead><tr><th>指标</th><th>全称</th><th>定义</th><th>适用研究</th></tr></thead><tbody><tr><td><strong>RR</strong></td><td>相对危险度（Relative Risk）</td><td>暴露组患病概率 &#x2F; 非暴露组患病概率</td><td><strong>队列研究</strong>（可以“跟踪”发病）</td></tr><tr><td><strong>OR</strong></td><td>比值比（Odds Ratio）</td><td>病例组的暴露几率 &#x2F; 对照组的暴露几率</td><td><strong>病例对照研究</strong>（不能计算发病率）</td></tr></tbody></table><h3 id="为何适用于不同研究类型？"><a href="#为何适用于不同研究类型？" class="headerlink" title="为何适用于不同研究类型？"></a>为何适用于不同研究类型？</h3><h4 id="队列研究-→-RR"><a href="#队列研究-→-RR" class="headerlink" title="队列研究 → RR"></a>队列研究 → <strong>RR</strong></h4><ul><li>从“暴露”开始观察，<strong>可以</strong>得到真正的“发病概率”。</li><li>所以可以直接算：<br>  $$RR &#x3D; \frac{P(\text{发病}|\text{暴露})}{P(\text{发病}|\text{非暴露})}$$​</li></ul><h4 id="病例对照研究-→-OR"><a href="#病例对照研究-→-OR" class="headerlink" title="病例对照研究 → OR"></a>病例对照研究 → <strong>OR</strong></h4><ul><li>从“疾病状态”出发选人（先有病例和对照），<strong>无法</strong>算发病率。</li><li>只能算暴露与非暴露的“比值”：<br>  $$OR &#x3D; \frac{\text{病例组中暴露&#x2F;非暴露}}{\text{对照组中暴露&#x2F;非暴露}}$$</li></ul><h4 id="生存分析-→-HR-harzard-ratio"><a href="#生存分析-→-HR-harzard-ratio" class="headerlink" title="生存分析 → HR(harzard ratio)"></a>生存分析 → <strong>HR(harzard ratio)</strong></h4><ul><li><p><strong>定义</strong>：HR 衡量暴露组相对于非暴露组在 <strong>随时间变化的事件发生速率</strong>（例如生存分析中的死亡率、疾病发生率等）的比率。它通常用于 <strong>生存分析</strong>，尤其是 <strong>Cox比例风险模型</strong> 中。</p></li><li><p><strong>计算方法</strong>：HR 基于时间的事件发生风险计算，可以理解为暴露组和非暴露组在单位时间内发生事件的风险比：<br>  $$HR &#x3D; \frac{\text{暴露组事件发生率}}{\text{非暴露组事件发生率}}$$</p><p>  它考虑了随时间推移的风险，而不仅仅是单纯的事件发生与否。</p></li></ul><h4 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h4><table><thead><tr><th></th><th>发病</th><th>未发病</th><th>总计</th></tr></thead><tbody><tr><td>暴露组</td><td>30</td><td>70</td><td>100</td></tr><tr><td>非暴露组</td><td>10</td><td>90</td><td>100</td></tr><tr><td>总计</td><td>40</td><td>160</td><td>200</td></tr></tbody></table>$$\begin{aligned}RR &= \frac{\frac{30}{100}}{\frac{10}{100}}=3 \\OR &= \frac{\frac{30}{10}}{\frac{70}{90}}=3.86\end{aligned}$$<p>口诀： <strong>“RR 看未来，OR 看过去”</strong></p><ul><li>RR 是“先暴露后观察结果” → 队列研究</li><li>OR 是“先有病例找原因” → 病例对照</li></ul><h1 id="卡方检验"><a href="#卡方检验" class="headerlink" title="卡方检验"></a>卡方检验</h1><p>理论频数的计算：</p><table><thead><tr><th></th><th>有效</th><th>无效</th><th>总数</th><th>概率</th></tr></thead><tbody><tr><td>A组</td><td>68(74*87.59%)</td><td>6</td><td>74</td><td>91.89%</td></tr><tr><td>B组</td><td>52</td><td>11</td><td>63</td><td>82.54%</td></tr><tr><td>总计</td><td>120</td><td>17</td><td>137</td><td>87.59%</td></tr></tbody></table><p>普通卡方：$n\geq40, E\geq5$<br>连续性校正卡方：$n\geq40, 1\leq E\leq5$<br>Fisher确切检验：$n\leq40$ 或 $E\leq {1}$</p><p><em>例题：15只4只发生癌变，对照组10只0只癌变</em></p><table><thead><tr><th></th><th>癌变</th><th>未癌变</th></tr></thead><tbody><tr><td>暴露组</td><td>4</td><td>11</td></tr><tr><td>非暴露组</td><td>0</td><td>10</td></tr></tbody></table><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_7.png" alt="卡方检验实例" title="卡方检验实例"></p><h2 id="配对卡方检验"><a href="#配对卡方检验" class="headerlink" title="配对卡方检验"></a>配对卡方检验</h2><h2 id="行列表卡方检验"><a href="#行列表卡方检验" class="headerlink" title="行列表卡方检验"></a>行列表卡方检验</h2><ol><li>多个率的比较</li><li>率的多重比较</li><li>多个构成比的比较</li><li>两种属性关联性检验</li></ol><h1 id="多种R-times-C表资料统计分析方法"><a href="#多种R-times-C表资料统计分析方法" class="headerlink" title="多种R $\times$ C表资料统计分析方法"></a>多种R $\times$ C表资料统计分析方法</h1><h2 id="卡方检验-1"><a href="#卡方检验-1" class="headerlink" title="卡方检验"></a>卡方检验</h2><ol><li>双向无序</li><li>单向有序：组别有序、结果无序</li></ol><h2 id="秩和检验"><a href="#秩和检验" class="headerlink" title="秩和检验"></a>秩和检验</h2><ol><li>单向有序：组别无序、结果有序</li></ol><h1 id="拟合优度的卡方检验"><a href="#拟合优度的卡方检验" class="headerlink" title="拟合优度的卡方检验"></a>拟合优度的卡方检验</h1><ol><li>单变量</li><li>二项分布</li><li>Poisson分布</li></ol><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C.png" alt="卡方检验" title="卡方检验"></p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循证医学5-6周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="ANOVA"><a href="#ANOVA" class="headerlink" title="ANOVA"></a>ANOVA</h1><p>多组样本均数比较</p><h1 id="多重比较"><a href="#多重比较" class="headerlink" title="多重比较"></a>多重比较</h1><p>SNK-Q, Dunnet-t, LSD-t检验，其中SNK-q最难显著，LSD-t最容易显著<br>SNK-q: 任意两组进行均数的比较<br>Dunnet-t: k-1个实验组与一个对照组的比较<br>LSD-t: 特定几组的比较</p><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>正态分布<br>方差齐性<br>Bartlett检验： 服从正态分布<br>Levene检验：服从任意分布</p><h1 id="双向方差分析"><a href="#双向方差分析" class="headerlink" title="双向方差分析"></a>双向方差分析</h1><p><em>方差分析不等于分析方差，方差分析分析均数</em><br>类似于ANOVA,仅可以做到比较多组是否全部相同。</p><h1 id="析因设计的方差分析"><a href="#析因设计的方差分析" class="headerlink" title="析因设计的方差分析"></a>析因设计的方差分析</h1><p>先确定有无交互效应<br>若无交互效应则进行主效应分析<br>若有交互效应则进行单独效应分析</p><p><em>F&amp;Q: 老师上课所使用的单变量回归该如何理解？单变量回归的作用是不是就是将不同正态分布的总体拉到同一基线上？</em><br>对于析因设计的方差检验，由于数据内部存在多组正态分布，导致数据总体不满足正态分布，所以需要分析其拟合后残差是否满足正态性与方差齐性<br>$$<br>\begin{aligned}<br>Y &#x3D; \beta_{0} + \beta_{1} X_{1} + \beta_{2}X_{2}<br>\end{aligned}$$<br>如果$X_{1}$: 肝脏&#x3D;0，心脏&#x3D;1；$X_{2}$: 15min&#x3D;0，60min&#x3D;1；$Y$: 药物浓度<br>如果我们研究不同时间的药物浓度是否相同:<br>$$<br>\begin{aligned}<br>Y &#x3D; \beta_{0} + \beta_{2}X_{2}\<br>Y - \beta_{1} &#x3D; \beta_{0}+\beta_{2}X_{2}<br>\end{aligned}$$<br>上面第一个式子是肝脏的药物浓度、第二个式子是心脏的药物浓度，但是我们给心脏的药物浓度做了个”修正”, 这个时候两数据的均值其实就”对齐”了</p><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/%E5%8F%82%E6%95%B0%E6%A3%80%E9%AA%8C.png" alt="参数检验" title="参数检验"></p><h1 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h1><blockquote><p>如果我们的数据不满足正态分布，而是满足二项分布，那我们该如何进行分析？</p></blockquote><h1 id="广义线性模型"><a href="#广义线性模型" class="headerlink" title="广义线性模型"></a>广义线性模型</h1><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_5.png" alt="logistic regression" title="logistic regression"></p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循证医学3-4周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A63-4%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A63-4%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h1><ol><li>检验的对象：抽样样本的均值，均值分布满足正态分布、抽样所得样本不一定满足正态分布</li><li>从正态分布——u分布——t分布(方差未知时用，<em><strong>大部分时候</strong></em>)</li><li>可信区间的计算(CI)：依赖于标准正态分布$\mathcal{N}(0,1)$ ,双边检验和单边检验的区分<br>变换方法：<br>$$\begin{aligned}<br>X \sim \mathcal{N}(\mu, \sigma^2)\\<br>X-\mu \sim \mathcal{N}(0, \sigma^2)\\<br>\frac{X-\mu}{\sigma} \sim \mathcal{N}(0, 1)<br>\end{aligned}<br>$$</li></ol><h1 id="两组均数比较的参数检验"><a href="#两组均数比较的参数检验" class="headerlink" title="两组均数比较的参数检验"></a>两组均数比较的参数检验</h1><h2 id="单样本t检验"><a href="#单样本t检验" class="headerlink" title="单样本t检验"></a>单样本t检验</h2><p>和已知的均值比较。<br>假设我检测的样本均值为$\bar{X} \sim \mathcal{N}(\mu_{1}, \frac{\sigma_{1}^2}{n})$，总体均值为常数$\mu_{2}$，然后我们对这两个作差得到:<br>$$\bar{X}-\mu_{2}\sim \mathcal{N}(\mu_{1}-\mu_{2}, \frac{\sigma_{1}^2}{n})$$<br>我希望的是：证明作差得到的分布是一个均值为0的分布，这样就可以证明两个样本均值和总体均值是没有差别的。<br>所以，假设以上均值为0，然后计算出现以上事件的概率。</p><h2 id="配对设计"><a href="#配对设计" class="headerlink" title="配对设计"></a>配对设计</h2><p>这里是配对样本的差值作为上面单样本检验的样本数据</p><h2 id="两总体均数比较"><a href="#两总体均数比较" class="headerlink" title="两总体均数比较"></a>两总体均数比较</h2><p>两样本均数满足$$\begin{aligned}<br>\bar{X_{1}} \sim \mathcal{N}\left( \mu_{1}, \frac{\sigma_{1}^2}{n_{1}} \right)\\<br>\bar{X_{2}} \sim \mathcal{N}\left( \mu_{2}, \frac{\sigma_{2}^2}{n_{2}} \right)<br>\end{aligned}<br>$$<br>作差得到, 随机变量计算公式：<br>$$\bar{X_{1}}-\bar{X_{2}} \sim \mathcal{N}\left( \mu_{1} - \mu_{2}, \frac{\sigma_{1}^2}{n_{1}} + \frac{\sigma_{2}^2}{n_{2}}\right)$$<br>假设上面公式均值为0，计算概率<br>因为总体方差未知，所以用S代替$\sigma$</p><h2 id="方差齐性"><a href="#方差齐性" class="headerlink" title="方差齐性"></a><em><strong>方差齐性</strong></em></h2><p>我们所做的工作都是针对均值，所以不妨假设方差相同，因为不相同，那显然不是两个相同总体<br>但是在使用该前提的时候需要证明方差相同。<br>使用的证明方法就是F检验，F分布就是两个正态分布的比值<br>$$F&#x3D;\frac{\frac{\sum_{i&#x3D;1}^{n_{1}}X_{i}^2}{n_{1}}}{\frac{\sum_{i&#x3D;1}^{n_{2}}Y_{i}^2}{n_{2}}}$$<br>其中，$X_{i}$和$Y_{i}$均为来自标准正态分布的样本，则称统计量F满足F分布<br>$$F \sim F(n_{1},n_{2})$$<br>方差之比遵从F分布，计算方差之比在假设两方差相同的情况下出现的概率。<br><strong>有趣的是，后面我们计算多组均数的方差分析中，也是使用的F分布，那个时候我们做出的假设是——组内方差&#x3D;组间方差</strong></p><h1 id="LASSO"><a href="#LASSO" class="headerlink" title="LASSO"></a>LASSO</h1><p><em>文献例子: Development and validation of a model to predict cognitive impairment in traumatic brain injury patients: a prospective observational study</em><br>“Variable selection was conducted via the least absolute shrinkage and selection operator (LASSO) method. Independent variables with nonzero coefficients in the LASSO regression model were selected and subsequently analyzed via multivariate logistic regression (P &lt; 0.05) to identify potential predictive factors.”</p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第一篇文章</title>
      <link href="/2025/05/06/2025-5-6/"/>
      <url>/2025/05/06/2025-5-6/</url>
      
        <content type="html"><![CDATA[<h2 id="这是我的第一篇文章"><a href="#这是我的第一篇文章" class="headerlink" title="这是我的第一篇文章"></a>这是我的第一篇文章</h2><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">alert</span>(<span class="string">&#x27;Hello World!&#x27;</span>);</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>循证医学1-2周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<p>第一周的主要内容其实就是意识到概率论和数理统计之间的关系</p><h1 id="统计学中的基本概念"><a href="#统计学中的基本概念" class="headerlink" title="统计学中的基本概念"></a>统计学中的基本概念</h1><h2 id="PPT-1"><a href="#PPT-1" class="headerlink" title="PPT-1"></a>PPT-1</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>总体——参数——$\mu, \sigma$<br>样本——统计量——$\bar{X}, \bar{Y}$<br>同质性与异质性<br><strong>抽样误差(sampling error)</strong></p><p>计量资料——有序<br>计数资料——有序<br>等级资料——无序</p><h3 id="因果与联系："><a href="#因果与联系：" class="headerlink" title="因果与联系："></a>因果与联系：</h3><p>金字塔顶端RCT研究，RCT是揭示事物因果关系最重要的方法，但是由于价格原因，大部分时间只能使用他的替代方案。</p><h3 id="抽样误差的有趣知识SE"><a href="#抽样误差的有趣知识SE" class="headerlink" title="抽样误差的有趣知识SE"></a>抽样误差的有趣知识<strong>SE</strong></h3><p>为什么要有SE？<br>如下图所示，美国为了研究班级人数的多少和班级平均分的关系，他们发现分数高的是那些班级人数较少的班级，但事实上，只是因为班级人数过少导致SE增大带来的错误因果！<br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_4.png" alt="SE的解释" title="SE的解释"></p><h2 id="PPT-2"><a href="#PPT-2" class="headerlink" title="PPT-2"></a>PPT-2</h2><p>不同均数的适应情况，及为什么适应：</p><h3 id="算术均数"><a href="#算术均数" class="headerlink" title="算术均数"></a>算术均数</h3><p>算术均数适用于正态分布，因为算术均数其实是正态分布的通过<strong>极大似然估计</strong>得到的均值<br>$$P(x)&#x3D;\frac{1}{\sqrt{ 2\pi }\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$<br>$$\begin{aligned}<br>l(x_{1},x_{2},\dots,x_{n})&amp;&#x3D;\sum_{i&#x3D;1}^n \ln P(x_{i})\\<br>&amp;&#x3D;\sum_{i&#x3D;1}^n (\ln \frac{1}{\sqrt{ 2\pi }\sigma} + \ln e^{-\frac{(x_{i}-\mu)^2}{2\sigma^2}})\\<br>&amp;&#x3D;\sum_{i&#x3D;1}^n (\ln \frac{1}{\sqrt{ 2\pi }\sigma} -\frac{(x_{i}-\mu)^2}{2\sigma^2})<br>\end{aligned}$$<br>求使上式子最大的$\mu$<br>$$\frac{dl}{d\mu}&#x3D;\sum_{i&#x3D;1}^n \frac{x_{i}-\mu}{\sigma^2}&#x3D;0$$<br>so<br>$$\mu&#x3D;\frac{1}{n}\sum_{i&#x3D;1}^n x_{i}$$</p><h3 id="几何均数"><a href="#几何均数" class="headerlink" title="几何均数"></a>几何均数</h3><p>几何均数适用于<strong>对数转换后呈正态分布的资料</strong>，即右偏态<br><em><strong>存在部分数值特别大的</strong></em><br>为什么使用几何均数？<br>为什么能用累乘解释：<br><em>比如，某机械厂生产机器，设有毛坯、粗加工、精加工和装配4个连续作业的车间。某批产品其毛坯车间制品合格率为97%，接下来3个车间的合格率分别为93%、91%和87%，求产品的平均合格率。<br>产品的平均合格率受制于4个车间的坏品或损耗情况，由于是连续作业的车间，所以是在前者基础上变成了百分之多少的感觉，符合几何平均数的应用。<br>直接使用几何平均数的公式，计算得出：</em><br>$$G&#x3D;(0.97 \times 0.93 \times 0.91 \times 0.87)^{1&#x2F;4}&#x3D;0.9193$$</p><h3 id="中位数"><a href="#中位数" class="headerlink" title="中位数"></a>中位数</h3><p>$$M&#x3D;L_{M}+\frac{i_{M}}{f_{M}}\left( \frac{n}{2} -\sum f_{L}\right)$$<br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_2.png" alt="中位数" title="中位数"></p><h3 id="标准差"><a href="#标准差" class="headerlink" title="标准差"></a>标准差</h3><p>为什么会有一个$\sigma$和$S$<br>而且$S$下面的分母为$n-1$<br>这是因为在计算均数时已经消耗掉一个自由度，所以需要减去一个自由度。通俗的讲，均数其实是偏向于我们采样的数据，所以在计算方差时需要让除数小一点，这样让方差更大，更加接近真实方差。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>正态分布: 能使用<strong>算术均数</strong>和<strong>标准差</strong>描述<br>右偏态数据使用: <strong>几何均数</strong><br>所有分布都可以使用的: <strong>众数</strong>、<strong>四分位数间距</strong><br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_3.png" alt="总结" title="总结"></p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
