<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>VIME论文速读(2020, NeurIPS)</title>
      <link href="/2025/08/08/VIME/"/>
      <url>/2025/08/08/VIME/</url>
      
        <content type="html"><![CDATA[<p><a href="https://proceedings.neurips.cc/paper/2020/file/7d97667a3e056acab9aaf653807b4a03-Paper.pdf">VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain</a><br>在这篇文章中，作者提出了新的表格数据自监督与半监督学习框架。对于自监督学习，在特征向量预测器的基础上，作者提出了<strong>mask vector estimation+Feature vector estimation</strong>。为了解决前置任务，解码器函数学习从无标签的原始特征中构建富含信息的表示。对于半监督学习，作者引入了一种新的表格数据增广模式：使用训练的编码器，通过对于遮掩的数据进行插值来获取多个增广数据。</p><h1 id="要点速读"><a href="#要点速读" class="headerlink" title="要点速读"></a>要点速读</h1><p><strong>VIME</strong>模型主要是提出了在表格数据中使用无标签的数据进行预训练的策略：<br><strong>Mask Vector Estimation</strong>与<strong>Feature Vector Estimation</strong>：即在无标签的数据中进行污染，然后预测哪个数据遭受污染并预测污染数据的原数据。</p><h1 id="Proposed-Model-VIME"><a href="#Proposed-Model-VIME" class="headerlink" title="Proposed Model: VIME"></a>Proposed Model: VIME</h1><h2 id="自监督学习"><a href="#自监督学习" class="headerlink" title="自监督学习"></a>自监督学习</h2><p>相较于TabTransformer，VIME对于数据的污染是采用分类数据的分布，这样可以保证对于污染数据的识别有一定难度。<br>$$\tilde{\mathbf{x}}&#x3D;g_{m}(\mathbf{x},\mathbf{m})&#x3D;\mathbf{m}\odot \bar{\mathbf{x}}+(1-\mathbf{m})\odot \mathbf{x}$$<br>其中$\bar{\mathbf{x}}$取样于实际分布$\hat{p}_{X_{j}}&#x3D;\frac{1}{N_{u}}\sum_{i&#x3D;N_{l}+1}^{N_{l}+N_{u}}\delta(x_{j}&#x3D;x_{i,j})$<br>接下来，作者将预测原数据的过程分为两步：1. 预测哪个特征被遮掩；2. 预测被遮掩的特征。前者输入嵌入，输出$\hat{\mathbf{m}}$，即预测的遮掩向量；后者输入嵌入，输出$\hat{\mathbf{x}}$，即预测的原特征。最后计算$l_{m}(\mathbf{m},\hat{\mathbf{m}})$与$l_{r}(\mathbf{x},\hat{\mathbf{x}})$作为损失函数进行反向传播。</p><h2 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h2><p>监督学习部分与普通的监督学习相同：做出预测后计算与真实标签的loss并反向传播。<br>对于自监督学习，作者使用了<strong>一致性正则化</strong>：鼓励预测模型在输入被干扰的情况下，依旧返回相似的输出分布。如果使用相对严谨的数学语言，描述如下：<br>$$<br>\mathcal{L}_{u}&#x3D;\mathbb{E}_{\mathbf{x}\sim p_{X}, \mathbf{m}\sim p_{\mathbf{m}},\bar{\mathbf{x}}\sim g_{m}(\mathbf{x},\mathbf{m})}[(f_{e}(\tilde{\mathbf{x}})-f_{e}(\mathbf{x}))^2]<br>$$<br>其中$f_{e}&#x3D;f\circ e$，即预测函数；$\tilde{\mathbf{x}}$为被污染的数据；$\mathbf{x}$为原始数据。也就是说，自监督损失函数是需要保证污染后数据的预测结果和污染前数据的预测结果一致。</p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TabTransformer论文速读(2020)</title>
      <link href="/2025/08/07/TabTransformer/"/>
      <url>/2025/08/07/TabTransformer/</url>
      
        <content type="html"><![CDATA[<p><a href="https://arxiv.org/pdf/2012.06678">TabTransformer</a>是基于Transformer架构构建的表格学习深度模型。它主要将类别变量转化为上下文嵌入，同时发现这样产生的嵌入对于缺失数据具有良好的鲁棒性与可解释性。最后作者提出一种半监督预训练方法。这篇文章发表于2020年，当时的SOTA还是MLP，深度学习还远远比不上树模型，TabTransformer有隐隐赶上树模型的趋势。</p><h1 id="重点速递"><a href="#重点速递" class="headerlink" title="重点速递"></a>重点速递</h1><p><strong>TabTransformer</strong>主要在表格数据领域中使用了特殊的预训练流程。<br><strong>MLM</strong>：对于数据进行遮掩，然后预测遮掩部分数据来进行预训练。<br><strong>RTD</strong>：将部分数据赋予随机值，然后设计二分类分类器来识别随机数据进行预训练。</p><h1 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h1><p>TabTransformer包括有一个列嵌入层、N个Tranformer层和一个MLP层。<br>$(\boldsymbol{x},y)$表示一个特征-标签对，其中$\boldsymbol{x}&#x3D;{\boldsymbol{x}_{cat},\boldsymbol{x}_{cont}}$前者代表类别变量$\boldsymbol{x}_\text{cat}&#x3D;{x_{1},x_{2},\dots,x_{m}}$，后者代表数值变量（共c个）$\boldsymbol{x}_\text{cont}\in \mathbb{R}^{c}$。作者将所有的类别特征使用列嵌入嵌入到d维空间，$e_{\phi_{i}}(x_{i})\in \mathbb{R}^d$，对于所有特征，有$\boldsymbol{E}_{\phi}(\boldsymbol{x}_\text{cat})&#x3D;{e_{\phi_{1}}(x_{1}),\dots,e_{\phi_{m}}(x_{m})}$。然后$\boldsymbol{E}$将被输入到Transformer层内得到输出${\boldsymbol{h}_{1},\dots,\boldsymbol{h}_{m}}$其中每个$\boldsymbol{h}$均为d维。最终将Transformer的输出和连续变量堆叠起来，得到一个$d \times m +c$维的向量。然后将该向量输入到MLP内用于预测标签$y$并计算损失函数。</p><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>架构与传统的Transformer一样</p><h2 id="Column-embedding"><a href="#Column-embedding" class="headerlink" title="Column embedding"></a>Column embedding</h2><p>对于类别特征$i$。有一个嵌入查询表$\boldsymbol{e}_{\phi_{i}}(\cdot)$，对于第$i$个特征，有$d_{i}$个类别，那么查询表就有$(d_{i}+1)$个嵌入，多出的一个嵌入代表缺失值。对于嵌入类别$x_{i}&#x3D;j\in[0,1,2,\dots,d_{i}]$，嵌入向量为$\boldsymbol{e}_{\phi_{i}}(j)&#x3D;[\boldsymbol{c}_{\phi_{i}},\boldsymbol{w}_{\phi_{ij}}]$，其中$\boldsymbol{c}_{\phi_{i}}\in \mathbb{R}^l, \boldsymbol{w}_{\phi_{ij}}\in \mathbb{R}^{d-l}$。$\boldsymbol{c}_{\phi_{i}}$属于是列专属，$\boldsymbol{w}_{\phi_{ij}}$是单元格专属，用于区分同列的不同单元格。作者当然也使用了无列专属嵌入的方法和列专属与单元格专属直接相加的嵌入的方法，但是效果最好的还是直接堆叠（平均最好）</p><h2 id="Pretraining-the-Embeddings"><a href="#Pretraining-the-Embeddings" class="headerlink" title="Pretraining the Embeddings"></a>Pretraining the Embeddings</h2><p>作者同时引入了无标签的样本进行预训练。<br>作者使用两种不同的预训练流程：<strong>MLM(masked language modeling)</strong> 与 <strong>RTD(replaced token detection)</strong> 。给出一个输入$\boldsymbol{x}_\text{cat}&#x3D;{x_{1},x_{2},\dots,x_{m}}$，<strong>MLM</strong>随机选择$k%$的特征遮掩，Transformer训练来降低预测原特征的交叉熵。<strong>RTD</strong>随机将特征使用一个该特征的随机值替代，这里是预测某个特征是否为替代特征，并计算损失函数。RTD在原始论文中是用一个子集来代替，但这是因为NLP中如果直接使用随机值，因为token有成千上万，一个替代的正态分布的特征太容易被发现了。而本文中，特征数量有限制且每列都有一个二分类器，所以直接用该特征的随机一个token。</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><p>作者在这篇文章的实验环节有许多有趣的创新点：</p><h2 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h2><p>已有数据集均有标签，所以为了构造无监督的数据，作者选择了数据中部分数据赋予标签，剩余数据作为无监督的数据进行测试。<br><strong>实验证明：直接使用Transformer效果优于MLP，使用预训练的TabTransformer效果更优于MLP</strong></p><h2 id="嵌入表示的效果测试"><a href="#嵌入表示的效果测试" class="headerlink" title="嵌入表示的效果测试"></a>嵌入表示的效果测试</h2><p>作者为了研究不同层中的上下文嵌入的效果，使用t-SNE对于每个样本进行降维，发现使用TabTransformer时<strong>语义学上相似的类会更加接近</strong>，而在MLP中并没有出现这种聚集现象。随后作者直接对每层的输出的嵌入使用线性回归测试预测效果，这个测试的目的就是：使用最简单的分类方法查看嵌入的质量。</p><h2 id="鲁棒性测试"><a href="#鲁棒性测试" class="headerlink" title="鲁棒性测试"></a>鲁棒性测试</h2><p>作者污染、删除数据，然后查看不同模型对于污染数据的预测效果。</p><h2 id="不同学习方法的比较"><a href="#不同学习方法的比较" class="headerlink" title="不同学习方法的比较"></a>不同学习方法的比较</h2><p>对于有监督学习，比较对象有：<strong>MLP, GBDT, Sparse MLP, Logistic Regression, TabNet, VIB</strong><br>对于无监督学习，比较对象有：<strong>ER MLP(Entropy Regularization combined with MLP), PL MLP\TabTransformer\GBDT(Pseudo Labeling), MLP(DAE)</strong></p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Tabular-Review-2</title>
      <link href="/2025/08/07/Tabular-Review-2/"/>
      <url>/2025/08/07/Tabular-Review-2/</url>
      
        <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/2402.01204">A Survey on Self-Supervised Learning for Non-Sequential Tabular Data</a><br>自监督学习(Self-Supervised Learn: SSL)：SSL在深度学习领域内主要用于基于无标签的数据集来学习富有内涵与鲁棒性的表示。<br>前置任务(Pretext Task): 为了达到训练任务而设计的间接任务：例如使用AE(Auto-Encoder)对图像进行编码来获取图片的分布，再进行图片的分类。<br>近期SSL在表格数据中崭露头角，这篇文章主要用于总结近期SSL在非序列表格领域的进展和挑战(SSL4NS-TD)。这里的NS-TD（非序列型表格数据）指的是：数据间无关联，无时间或者其他顺序。作者按照一下顺序安排文章：1. NS-TD的定义，与其他研究的相关性；2. 将方法分为3类：预测学习、对比学习、复合学习。各个方法的出发点和在每个领域内的优势；3. SSL4NS-TD的应用；4. 各个方法的比较；5. SSL4NS-TD的挑战并提出可能的方向。</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>SSL的主要优点就是其能够减少对于大规模数据的标注。SSL不同于传统的使用标签来训练，其通过前置任务学习任务无偏(Task-agnostic)的数据表示，来创造显式（例如预测学习）的或者隐式的标签（对比学习）。模型被期望从无标注的表格数据中学会普适性的表示，并能适应性的应用于下游任务中。总的来说，现有的有关SSL的表格数据技术可分为序列型与非序列型。作者在这篇文章中主要集中于非序列型(SSL4NS-TD)。</p><h1 id="Problem-Definition-of-SSL4NS-TD"><a href="#Problem-Definition-of-SSL4NS-TD" class="headerlink" title="Problem Definition of SSL4NS-TD"></a>Problem Definition of SSL4NS-TD</h1><p>不同于序列表格数据，非序列表格数据没有一个确定的顺序，在对于NS-TD使用SSL时，首先需要构建一个编码器函数$e: X\to Z$。其中$Z$代表从自监督学习任务中学到的上下文表示(Contextualized representation)。值得注意的是，自监督学习任务中的标签来自于数据本身而不是手动的标注。编码器函数与下游任务的模型结合可以更好的预测结果。</p><h1 id="Taxonomy"><a href="#Taxonomy" class="headerlink" title="Taxonomy"></a>Taxonomy</h1><ol><li>SSL4NS-TD的预测学习：最常用的类别，由于特征的异质性，在预测最终结果之前设计预测任务让模型可以学习到原始数据中的背景知识。但是难点在于设计有效的预测前置任务，这些任务需要考虑上游与下游数据集和任务之间的关系。虽然并没有设计预测性前置任务的共识，但是有许多范式被提出：1. 从掩码特征中学习；2. 在潜在空间中进行扰动；3. 利用预训练语言模型的固有能力，</li><li>SSL4NS-TD的对比学习：旨在学习表格数据中样本的相似性与差异性。优点就是提供了一种任务无偏的学习策略，并且可以应用于广泛的下游任务与迁移学习而仅需要少数的标注样本。但是，挑战在于如何规定样本的“远”与”近”。规定方法简要列举如下：1.  基于实例的；2. 基于模型的；3. 基于列特征的；3. 基于潜空间的。</li><li>SSL4NS-TD的复合学习：将以上两种方法结合的学习方法。当前主要有两类方法：1. 扰动+对比学习；2. 掩码+对比学习。</li></ol><h1 id="预测学习"><a href="#预测学习" class="headerlink" title="预测学习"></a>预测学习</h1><p>这个方法来自于使用于拥有同质性特征的领域的SSL，例如将干扰、旋转、裁剪和引入噪声作为前置任务。表格数据的SSL也是基于以上方法来设计前置任务的。当模型可以通过被遮掩或者污染的数据获取原始数据，那么该模型在下游任务中也是有效的。这里我们可以给出一个概括性的公式：</p><p>$$<br>\begin{aligned}<br>L_{predictive} &amp;&#x3D; \psi(g(e(x_{i}^*)), y_{i}^*)\\<br>x_{i}^* , y_{i}^* &amp;&#x3D; \delta(x_{i})<br>\end{aligned}<br>$$</p><p>$\psi$： 损失函数，用于优化转换后的$x_{i}^*$和自监督标签$y_{i}^*$，这两样东西是由$\delta$转化而来。$g$代表将编码器$e$产生的嵌入映射为自监督预测的映射。</p><h2 id="从遮掩的特征中学习"><a href="#从遮掩的特征中学习" class="headerlink" title="从遮掩的特征中学习"></a>从遮掩的特征中学习</h2><p>遮掩部分特征让模型可以学习到样本的上下文信息，这与下游训练中预测样本对应的类别&#x2F;样本的值的任务相一致。这种一致为训练好的编码器提供了在下游任务中，从给定样本特征中推理的知识。受启发于MAE(Masked Autoencoder)使用的随机掩码，<strong>TabTransformer</strong>和<strong>VIME</strong>将从一个污染的或者遮掩过的数据中还原数据作为前置任务，同时还构建了一个框架来泛化到所有表格数据。其中<strong>TabTransformer</strong>引入了随机掩码和随机值取代作为转化函数。<strong>VIME</strong>通过掩码向量估计器来识别被遮掩的特征并同时使用特征向量估计器基于相关的未被遮掩的特征进行插值。举个掩码向量估计器的例子，如果某个特征与和他相关的向量非常不协调，这个特征很可能就是被遮掩的。VIME的二元掩码来自于伯努利分布。<br>为了鼓励编码器产生更加结构化且有代表性的嵌入，以进一步提高<strong>VIME</strong>，<strong>TabNet</strong>设计了一个注意力机制来迭代地选择遮掩特征，让深度学习模型具有可解释性。于可学习的掩码相反。<strong>SEFS</strong>提出了一种特征子集生成器作为变换函数，来提高遮掩高度相关的特征的概率。<strong>SwitchTab</strong>在<strong>VIME</strong>自监督任务的基础上使用了非对称的编码-解码器架构，并提出了一种转移机制来对两个样本进行解耦：每个样本包括有共同信息（每个样本都有的，可交换的）和显著信息（每个样本特有的）。因此，对比的目标就是从共有的信息和独有的信息中获取原始特征。除了这些进展，掩码的占比是难以决定且需要根据任务调整。</p><h2 id="潜空间的扰动"><a href="#潜空间的扰动" class="headerlink" title="潜空间的扰动"></a>潜空间的扰动</h2><p>为了从表格数据的异质性特征中学习概括性的上下文信息，<strong>STUNT</strong>从未标记的数据中，“元学习”自己生成的任务，这种想法起源于：列可能与下游的标签有相关性(例如：工作的特征可能与收入有关，并且可以作为收入的替代)。这样一个转化函数遮掩部分特征，然后使用k-means算法产生伪标签。基于元学习的框架，<strong>STUNT</strong>在小样本表格数据中是高效的。<strong>LFR</strong>探索了随机映射器在缺少前置知识来增广数据的情况下，学习未标注数据并担任通用框架以合并多模态数据。但是这种方法并没有在有充足前置知识的情况下优秀。</p><h2 id="预训练语言模型的固有能力"><a href="#预训练语言模型的固有能力" class="headerlink" title="预训练语言模型的固有能力"></a>预训练语言模型的固有能力</h2><p>从另一个角度来解决特征异质性的问题：使用大语言模型作为编码器让知识可以在不同数据集之间迁移。但是难点在于如何将表格数据转化为自然语言的格式，多种预训练的语言模型被应用于表格数据：多个工作直接将数值作为字符串输入，这种方法虽然很直接，但是也有效减轻的预处理的压力。为了让语言模型理解数值变量，<strong>TP-BERTa</strong>提出了使用相对量纲分词技术(relative magnitude tokenization)通过使用决策树将数值变量分箱来将标量转化为离散的tokens，接着将embedding与原数值相乘来避免大量的值聚集在一块。为了减少特征的顺序偏倚，<strong>GReaT</strong>将表格和文本使用一个文本编码模式连接并使用随机插入。例如将$\text{age}&#x3D;26;\text{income}&#x3D;70$转化为“age is 26, income is 70k”。然后再改变顺序为”income is 70k, age is 26”</p><h1 id="对比学习"><a href="#对比学习" class="headerlink" title="对比学习"></a>对比学习</h1><p>这些进展的另一个共同主题是，通过同一输入的不同视角或扰动来学习鲁棒的表示，这一目标通过最大化相似实例之间的相似性、并拉远不相似实例之间的距离来实现。对比学习在CV领域和NLP领域获得了极大的成果，在表格数据领域，对比学习被使用来学习高效且泛化性能强的任务无偏的表示。对比学习可以被如下定义：<br>$$<br>\begin{aligned}<br>&amp;L_{contrastive}&#x3D;\phi(h_{i}, h_{i}^+, h_{j}^-)\<br>&amp;h_{i}&#x3D;e(x_{i});h_{i}^+&#x3D;e(x_{i}^+);h_{j}^-&#x3D;e(x_{j}^-)<br>\end{aligned}<br>$$<br>其中$\phi$是相似性函数，其比较锚点(anchor: $h_{i}$)、正例(positive: $h_{i}^+$)、反例(negative: $h_{i}^-$)。正例是特定样本锚点通过增广方式产生，负样本是来自于其他样本。正样本对代表相似、负样本对代表不相似。总体上来说，相似函数可以选择余弦相似度、欧几里得距离或者点乘。注意正样本对和负样本对并不是都需要加在loss里面。如果任务需要自监督的标签，则设置在$e$输出后使用的映射头$g$.<br><strong>SCARF</strong>是一个基于MLP的框架，其具有2阶段学习策略：<strong>InfoNCE对比预训练</strong>和<strong>有监督的微调</strong>。它加强了多种表格领域的泛化能力。在与训练阶段，其输入会被随机破坏，具体做法是将某部分特征随即替换为对应特征的边缘分布中的随机视图，从而构建正样本对和负样本对。接着，使用<strong>InfoNCE</strong>相关函数让正样本对更加靠近，负样本对更加远：<br>$$\phi_{\text{InfoNCE}}(h_{i},h_{i}^+,h_{j}^-)&#x3D;\log\left( \frac{\exp\left( \frac{h_{i}h_{i}^+}{\tau} \right)}{\sum_{j&#x3D;1}^N\exp(\frac{h_{i}h_{j}^-}{\tau})} \right)$$<br>$\tau$为温度参数。<br>与<strong>SCARF</strong>相反，<strong>STab</strong>旨在引入一种不使用增广的自监督表示学习技术，这种技术不需要负样本对。<strong>STab</strong>将输入样本使用两个MLP编码器，其中一个有一个多出的映射头，两个MLP编码器有相同的权重但是有不同的随机正则化。这可以被看作是一种基于模型的对比学习。然后比较负余弦距离作为相似函数。这两个MLP得出的表示被认为是各自的干扰样本。为了学习可被用于迁移学习、增量学习、零样本推理的上下文信息（表格间的列名是不同的），<strong>TransTab</strong>将表格中的列和单元格上下文化（例如将gender设置为woman而不是1、2）,其使用了Transformer编码器，并在多个表格中使用垂直划分对比学习（Vertical-partition contrastive learning：一种基于列划分表格的对比学习方法）进行预训练。Ye等人提出了一种基于原型的表格数据学习框架，用于围绕全局数据原型学习可解缠的表示。该方法引入全局原型来对抗相似样本，同时在潜在空间中通过多样化约束保留原始的差异性信息。</p><h1 id="复合学习"><a href="#复合学习" class="headerlink" title="复合学习"></a>复合学习</h1><p>将预测学习和对比学习结合的一种策略。一般来说，使用复合学习模型的方法需要多种映射头来处理不同的前置任务，多个映射头可以被并行使用来保证模型的鲁棒性。复合学习的损失函数如下定义：<br>$$L_{hybrid}&#x3D;L_{predictive}+L_{contrastive}$$<br>多种方法被使用来优化$L_{hybrid}$，包括干扰+对比学习、掩码＋对比学习。</p><h2 id="干扰-对比学习"><a href="#干扰-对比学习" class="headerlink" title="干扰+对比学习"></a>干扰+对比学习</h2><p>干扰＋对比学习可以在没有前置知识的前提下，学习到鲁棒性的表示与列、行乃至于单元格之间的上下文关系。除了重建损失函数外，<strong>SubTab</strong>将表格数据分为多个子集，每个子集有潜在的重叠的列作为不同的视图来进行对比损失和距离损失（类似于图片中的剪切，两种都是让同一个样本的子集更加靠近）。为了不均衡地扰动特征以进行特征重建，<strong>SubTab</strong>在以下3样东西上通过伯努利掩码加入了高斯噪声：1. 随机列；2. 临近列的随即区域；3. 样本中的随机特征。为了避免相似的特征在重建的损失中权重过大，Chen将损失函数与正则化矩阵结合。在分类标签的辅助下，他们使用了不同的视图进行有监督对比学习来最大化相同类的相似度并使用半监督学习来预训练Transformer模型。<br>除了在表格数据中使用了Transformer架构，研究者也开始将NS-TD作为token框架化，这在NLP及CV领域非常常用。多种变体被使用来捕捉表格数据中的更细颗粒度的表示（例如单元格级、数值型、类别型特征）。主要的优点就是表示可以在不同的数据集之间共用，并且可以通过自监督机制来建模。<strong>SAINT</strong>通过一组序列来描述特征，这组序列由数值变量和类别变量对应的部分组合而成，并在开头加上一个[CLS]的特殊token（就像<strong>BERT</strong>一样）。为了从其他相似的样本中建模不变的细颗粒度特征表示，<strong>SAINT</strong>将类别变量和数值变量嵌入并通过跨样本注意力机制在不同行间编码，最后使用重建损失和InfoNCE对比损失使用嵌入空间内的增广来进行预训练。<br>相较于已有工作中使用预训练并在下游数据集中进行微调，另外一个重要的角度是在大量数据集上进行预训练，这提供在下游任务中作为基础模型的能力，就像NLP中的Chatgpt。<strong>XTab</strong>是一个广义的表格数据Transformer预训练模型，其在大量且多样化的交叉表数据中进行训练，并且足够灵活来使用已有的编码器主干和自监督策略。<strong>UniTabE</strong>是一个在大规模多领域数据上进行训练的Transformer架构。解码器使用了自由格式和特定任务的提示词和来自编码器的上下文表示，从而能够进行自适应地任务定制化的推理。也就是说，提示词可以被修改来适应特定的下游任务。<strong>UniTabE</strong>的预训练任务包括了多单元格遮掩来重构样本的部分单元格和对比学习。</p><h2 id="掩码-对比学习"><a href="#掩码-对比学习" class="headerlink" title="掩码+对比学习"></a>掩码+对比学习</h2><p>相较于干扰留了部分数据信息，掩码直接遮掩了目标特征。为了适应上下游任务中不同的特征，Levin使用了一种基于已有深度表格模型的伪特征方法来进行预训练，并利用了对比预训练策略（就类似于在2k个高质量交叉表数据集中使用遮掩表格来学习特征间的潜在关联和相同类别样本的聚类）。分析得出：预训练为模型提供了相较于树模型更强的迁移能力。与特征无偏的SSL方法相反，<strong>DoRA</strong>关注于在金融领域基于特定知识设计一个特定的前置任务。它通过在预训练阶段选择领域内特定的特征作为自监督学习的标签，引入了样本内前置任务（例如，预测目标城镇的地理位置）。样本间对比学习则是基于特定知识引入不相似的样本来进行对比学习（例如相同城镇的房子会更加接近）。</p><h1 id="SSL4NS-TD的应用"><a href="#SSL4NS-TD的应用" class="headerlink" title="SSL4NS-TD的应用"></a>SSL4NS-TD的应用</h1><h2 id="自动数据工程"><a href="#自动数据工程" class="headerlink" title="自动数据工程"></a>自动数据工程</h2><p>深度学习缓解了特征工程的压力，但是在各领域稳定的表现依旧是一个挑战，因为数据中存在不平衡、缺失值、噪声数据。Huang证明SSL4NS-TD有在不同领域内保持鲁棒的表现的潜力，这将减少手工标注的小号。Lee使用了门控向量估计来自监督相关特征的选择过程，这可以避免选择冗余的特征并让更有信息的特征被学习。</p><h2 id="交叉表迁移性"><a href="#交叉表迁移性" class="headerlink" title="交叉表迁移性"></a>交叉表迁移性</h2><p>直接从表格学习表示需要对于每个下游数据集的训练模型，同时在测试数据与训练数据中也有着严格的特征限制。因此如何跨表格学习亟待解决。近期有许多方法实现了迁移性，包括基于PLM来从语义学角度上下文化知识的<strong>LIFT, TP-BERTa, GReaT</strong>；或者从头开始的细颗粒度特征编码器<strong>TransTab, XTab, UniTabE</strong>。这些方法证明：使用 SSL4NS-TD 进行预训练在适应增量列（incremental columns）、低资源场景（low-resource scenarios）以及缺失值预测（missing value predictions）方面具有优势。</p><h2 id="领域知识融合"><a href="#领域知识融合" class="headerlink" title="领域知识融合"></a>领域知识融合</h2><p>表格数据的应用常常需要有专家知识来推测结果，Du发现，使用地理图相关的特征作为前置任务是房产价格预测的重要因素。Nam设计了具有伪标签的自生成任务，该标签与下游标签有显著相关性（例如：通过地理位置和财产多少来估计房产价格类似于通过地理位置和财产来估计租金）。</p><h1 id="NS-TD数据集与Benchmarks"><a href="#NS-TD数据集与Benchmarks" class="headerlink" title="NS-TD数据集与Benchmarks"></a>NS-TD数据集与Benchmarks</h1><p>TabPFN表现最佳(这里的TabPFN是2023年的v1，2025年的v2准确率更高)，其次为SAINT，TabNet，VIME，TransTab.</p><h1 id="未来方向"><a href="#未来方向" class="headerlink" title="未来方向"></a>未来方向</h1><h2 id="SSL4NS-TD的秘籍"><a href="#SSL4NS-TD的秘籍" class="headerlink" title="SSL4NS-TD的秘籍"></a>SSL4NS-TD的秘籍</h2><p>除了已有的对于前置任务的探索：预测学习、对比学习、复合学习。SSL技术主要是来自于NLP与CV领域。目前仍然不清楚哪种SSL技术最佳、如何调超参。目前有一个很有前景的方向：就是如何设计与下游任务相关的前置任务。</p><h2 id="基础表格模型的进化"><a href="#基础表格模型的进化" class="headerlink" title="基础表格模型的进化"></a>基础表格模型的进化</h2><p>NLP的基础模型得到大大发展，但是基础模型依然未被完全探索。</p><h2 id="表格数据持续学习"><a href="#表格数据持续学习" class="headerlink" title="表格数据持续学习"></a>表格数据持续学习</h2><p>目前由于不同表格数据多样性与异质性，基础表格模型发展并不成熟。一种可能的方向就是统一表格数据格式，然后使用基础表格模型或者LLM处理。</p><h2 id="表格数据的隐私"><a href="#表格数据的隐私" class="headerlink" title="表格数据的隐私"></a>表格数据的隐私</h2><p>联邦学习是其中一种解决方法：多个设备和服务器同时训练模型且不共享本地数据，不上传数据，而是上传梯度或者权重。但是，由于上传的数据的质量和分布不一，所以联邦学习也存在问题。</p><h2 id="多模态多任务环境中的进展"><a href="#多模态多任务环境中的进展" class="headerlink" title="多模态多任务环境中的进展"></a>多模态多任务环境中的进展</h2><p>支持多任务学习能力（multi-task learning）可能有助于表格模型：<br>在不同任务之间<strong>共享知识</strong>；<br>同时以<strong>节省内存资源</strong>的方式来容纳这些任务。<br>进一步地，目前大多数的NS-TD方法依然仅关注于基于表格的数据，而忽视了多模态信息融合的潜力。然而，在 <strong>顺序表格数据领域（sequential tabular domain）</strong> 中，多模态融合（如将物品图片与其元数据结合，用于推荐系统）已经被证明是有效的。<br>此外，将表格格式的数据转换为文本格式（例如将数值“0”转化为“seen”，将“1”转化为“unseen”）能够利用大型语言模型（LLMs）中的通用知识来学习更丰富的上下文信息。<br>随着可用于训练的更大规模的表格数据集的增加；以及不同模态信息的融合技术的进步，我们认为：<strong>未来在这些方向上深入研究SSL在NS-TD中的应用（即SSL4NS-TD）</strong>，将有助于开发出<strong>更健壮、可部署性更强</strong>的学习方法。</p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>markdown中的数学公式</title>
      <link href="/2025/07/31/markdown%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/"/>
      <url>/2025/07/31/markdown%E4%B8%AD%E7%9A%84%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="MathJax解析与Hexo冲突转义"><a href="#MathJax解析与Hexo冲突转义" class="headerlink" title="MathJax解析与Hexo冲突转义"></a>MathJax解析与Hexo冲突转义</h1><p>Hexo 中如需使用公式，需在 Markdown 开头需附上mathjax:true（如NexT主题）或math:true（如Fuild主题）。</p><p>一行 MathJax 公式中出现多个_<br>{\rm a}_b{\rm a}_b: ${\rm a}<em>{b}{\rm a}</em>{b}$<br>{\rm a}\_b{\rm a}\<em>b: ${\rm a}_b{\rm a}_b$<br>欲显示</em><br>Pax_Romana: $Pax_Romana$<br>Pax\_Romana: $Pax\_Romana$<br>欲换行：<br>a\b\c：$a\b\c$<br>a\\b\\c：$a\\b\\c$</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://blog.enatsu.top/tex/MathSupport/">MathJax数学符号支持</a></p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 实用技巧 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AutoPNPNet论文阅读</title>
      <link href="/2025/07/31/AutoPNPNet%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
      <url>/2025/07/31/AutoPNPNet%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="模型速览"><a href="#模型速览" class="headerlink" title="模型速览"></a>模型速览</h1><p> <a href="https://www.mdpi.com/2079-9292/14/6/1165">PNPNet(Periodic-Non-Periodic Network)</a>和AutoPNPNet是作者提出的深度学习模型，用于挖掘数据内部的周期性来增强预测准确率。作者提出了FourierNet：一种基于Fourier的神经编码器来捕捉周期性特征；ChebyshevNet：使用Chebyshev神经编码器来建模非周期性特征。作者将这两种架构结合构成PNPNet和AutoPNPNet。模型效果优于SOTA（会有论文不是SOTA的吗？而且这里的SOTA是<a href="https://arxiv.org/abs/2106.11959">FT-Transformer</a>(2021, Yury Gorishniy)）。</p><hr><blockquote><p>PNPNet detects periodic and non-periodic features a priori, feeding them into separate branches, while AutoPNPNet automatically selects features through a learned mechanism.</p></blockquote><hr><p>Q1：PNPNet如何使用滤波器与傅里叶变换获取periodic and non-periodic特征并将其转化为什么样的先验？<br>Q2：如何传入不同分支？<br>Q3：这里的分支是什么？<br>Q4：AutoPNPNet如何自动选择特征？</p><h1 id="要点速递"><a href="#要点速递" class="headerlink" title="要点速递"></a>要点速递</h1><p>这篇文章创新性并不是那么强。而且在评价指标上有些”特别”。</p><ol><li><strong>ChebyshevNet</strong>：切比雪夫多项式，高阶切比雪夫多项式可以拟合非线性关系，近年提出的网络架构KAN也是对于Chebyshev多项式有所运用。</li><li><strong>FourierNet</strong>：类似于傅里叶变换的思路，主要是通过神经网络初始化多个频率，然后对于频率优化，其实并没有使用实际的傅里叶变换。</li><li><strong>Cross-head attention</strong>：交叉头注意力机制，这种机制会在每两个注意力头之间计算“交叉注意力”，然后归一化。可以有效提取不同注意力头之间的交互作用。</li><li><strong>评价指标</strong>：作者使用的评价指标是“相对于SOTA的<strong>提升率</strong>”，但是并没有给出具体的绝对数值和计算方法(80%提高10%是90%还是88%？)；在评价指标中，相同数据集的Precision和Accuracy居然显示的是不同模型。<br><img src="/2025/07/31/AutoPNPNet%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/Metric.png" alt="&quot;评价指标&quot;"></li></ol><h1 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h1><p><img src="/2025/07/31/AutoPNPNet%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/PNPNet.png" alt="&quot;PNPNet&quot;"></p><h2 id="FourierNet"><a href="#FourierNet" class="headerlink" title="FourierNet"></a>FourierNet</h2><p>FourierNet主要用于捕捉周期性的信息，基于Fourier变换的神经编码器将输入的特征转化为频域表示，让网络可以高效学习周期性的部分。<br>输入向量$X \in \mathbb{R}^d$，在进行傅里叶变换前将会进行多种处理，如果使用缩放，则所有的输入特征都将会进行一次可学习（$s\in \mathbb{R}^d为可学习参数$）的缩放（即对进行一次逐元素相乘）<br>$$\tilde{x}&#x3D;s\odot x$$<br>可选择进行一次1维的卷积操作，用于捕捉局部的特征信息<br>$$\tilde{x}&#x3D;\mathrm{Conv1D}(\tilde{x})$$<br>傅里叶编码器的核心在于：将输入特征使用正弦函数映射至一个高维度的空间，对于每个输入特征$x_{i}$，我们将其与m个频率组件相关联，构成一个频率矩阵$\mathbf{F}\in \mathbb{R}^{d\times m}$，频率$f_{ij}$可以通过多种方式初始化（uniform, normal, logarithmic initialization），如果使用RFF(random fourier features)，则将按照以下分布，其中$\sigma$代表带宽参数。<br>$$f_{ij} \sim \mathcal{N}\left( 0, \frac{1}{\sigma^2} \right)$$<br>编码器也有对于每个特征和频率可选择的可学习的参数振幅$\alpha_{ij}$和相移$\phi_{ij}$。输入向量将会哦那个过以下方式映射：<br>$$z_{ij}&#x3D;2\pi x_{i}f_{ij}+\phi_{ij}$$<br>编码器支持多种激活函数，其中sin_cos激活函数如下所示：<br>$$F_{ij}^{\sin}&#x3D;\alpha_{ij}\sin(z_{ij}), F_{ij}^{\cos}&#x3D;\alpha_{ij}\cos(z_{ij})$$<br>这些输出在特征维度上堆叠，在激活后，一个可选择的可学习缩放参数$\gamma_{ij}$被用于缩放特征<br>$$F_{ij}&#x3D;\gamma_{ij}F_{ij}$$<br>编码后的特征被展平来形成最终的编码向量$\mathbf{F}(x)$，该向量维度为$d\times m\times k$，其中k依赖于激活函数的类型，如果是”sin_cos”则k&#x3D;2。<br>$$\mathbf{F}(x)&#x3D;\mathrm{Flatten}(F_{ij})$$<br>完整的FourierNet结合了MLP，Fourier编码器将输入特征转化为一个高维度的表示$\mathbf{F}(x)$，通过正弦转化捕捉到了周期信息、振幅和相位，这些编码后的表示将通过L层的MLP：</p><p>$$<br>\begin{aligned}<br>\mathbf{h}_{0} &amp;&#x3D; \mathbf{F}(x) \\<br>\mathbf{h}_{l} &amp;&#x3D; \sigma(\mathbf{W}_{l}\mathbf{h}_{l-1}+\mathbf{b}_{l}), \quad \text{for } l&#x3D;1,2,\ldots,L \\<br>\hat{y} &amp;&#x3D; f_{\text{out}}(\mathbf{h}_{L})<br>\end{aligned}<br>$$<br>将所有的组件组合起来，对于输入特征 $x_{i}$ 和频率j的编码可以概括为以下式子：<br>$$<br>\begin{aligned}<br>F_{ij}&#x3D;\gamma_{ij}\alpha_{ij}\sin(2\pi x_{i}f_{ij}+\phi_{ij})\\<br>F_{ij}&#x3D;\gamma_{ij}\alpha_{ij}\cos(2\pi x_{i}f_{ij}+\phi_{ij})<br>\end{aligned}<br>$$</p><h2 id="ChebyshevNet"><a href="#ChebyshevNet" class="headerlink" title="ChebyshevNet"></a>ChebyshevNet</h2><p>ChebyshevNet用于捕捉复杂的、非周期、非线性的关系。ChebyshevNet使用了第一类切比雪夫多项式，对于每个输入特征$x_{i}$，切比雪夫多项式$T_{n}(x_{i})$通过如下方式递归定义：<br>$$\begin{aligned}<br>&amp;T_{0}(x_{i})&#x3D;1,\\<br>&amp;T_{1}(x_{i})&#x3D;x_{i},\\<br>&amp;T_{n}(x_{i})&#x3D;2x_{i}T_{n-1}(x_{i})-T_{n-2}(x_{i}), \text{for } n\geq 2 .<br>\end{aligned}<br>$$<br>这里我附上一个first kind chebyshev的绘图代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">chebyshev</span>(<span class="params">x, n = <span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">0</span>: </span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> n == <span class="number">1</span>: </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span> * x * chebyshev(x, n - <span class="number">1</span>) - chebyshev(x, n - <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.arange(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">0.01</span>)</span><br><span class="line">y = chebyshev(x, n=<span class="number">6</span>)</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>一个对于训练趋势的初步分析显示：loss有显著的波动，而这阻碍了训练的过程，尤其是对于高阶的多项式。为了解决这个问题，我们探索了特征限制（feature clamping）来增强训练稳定性。输入特征被限制到区间[-1,1].<br>$$x_{i} \leftarrow \mathrm{clip}(x_{i},-1,1).$$<br>这样的限制让高阶的多项式训练过程更加稳定。<br>Chebyshev编码器$\mathbf{C}(x)$通过计算对每个输入特征的N(及$\leq N$)阶多项式，产生特征编码张量，编码张量形状为[d, N+1]，d为输入的特征数量:</p><p>$$\mathbf{C}(x)&#x3D;[T_{0}(x_{i}), T_{1}(x_{i}),\dots,T_{N}(x_{i})]_{i&#x3D;1}^d$$</p><p>一个多头编码机制被用于增强编码器的表示能力。设共有H个头，每个头独立处理输入特征，包括学习参数$\mathbf{s}^{(h)}\in \mathbb{R}^d,\mathbf{W}^{(h)}\in \mathbb{R}^{d\times(N+1)}, \mathbf{K}^{(h)}\in \mathbb{R}^{d\times(N+1)\times k}$。其中s为可选的缩放参数、$\mathbf{K}$为交互核，k为核大小。对头h，输入特征如下处理：</p><p>$$\tilde{x}_i^{(h)} &#x3D; s_{i}^{(h)}x_{i}$$</p><p>计算特征编码矩阵：</p><p>$$P_{i,n}^{(h)}&#x3D;W_{i,n}^{(h)}T_{n}(\hat{x}_{i}^{(h)})$$</p><p>多项式的交互依赖于交互核：</p><p>$$S_{i,j}^{(h)}&#x3D;\sum_{n&#x3D;0}^NP_{i,n}^{(h)}K_{i,n,j}^{(h)},\text{ for }j&#x3D;1,2,\dots,k $$</p><p>使用激活函数：</p><p>$$S_{i,j}^{(h)}&#x3D;\sigma(S_{i,j}^{(h)})$$</p><p>如果使用残差连接：</p><p>$$S_{i,j}^{(h)}&#x3D;S_{i,j}^{(h)}+\tilde{x}_{i}^{(h)}$$</p><p>每个头输出张量$\mathbf{S}^{(h)}\in \mathbb{R}^{d\times k}$。然后会输入交叉头注意力模块中。cross-head attention中多头的权重通过指数加权求得:<br>$$s^{(h)}&#x3D;\mathrm{Flatten}(\mathbf{S}^{(h)}),\mathbf{s}^{(h)}\in \mathbb{R}^{dk}$$<br>$$\alpha^{(h,h’)}&#x3D;\frac{(q^{(h)})^Tk^{(h’)}}{\sqrt{ d_{a} }}$$<br>$$a^{(h,h’)}&#x3D;\frac{\exp(\alpha^{(h,h’)})}{\sum_{h’’&#x3D;1}^H\exp(\alpha^{(h,h’’)})}$$<br>$$\mathbf{o}^{(h)}&#x3D;\sum_{h’&#x3D;1}^Ha^{(h,h’)}\mathbf{v}^{(h’)}$$<br>$$\mathbf{C}(x)&#x3D;\mathrm{Concat}(\mathbf{o}^{(1)},\mathbf{o}^{(2)},\dots,\mathbf{o}^{(H)})$$<br>一个可选的归一化层在这里可以用于处理$\mathbf{C}(x)$来保证训练稳定性。最后$\mathbf{C}(x)$将被输入到MLP中</p><h2 id="PNPNet"><a href="#PNPNet" class="headerlink" title="PNPNet"></a>PNPNet</h2><p>PNPNet需要将输入的特征分为周期性变量$x_{p}\in \mathbb{R}^{d_{p}}$和非周期性变量$x_{np}\in \mathbb{R}^{d_{np}}$，其中$d_{p}+d_{np}&#x3D;d$。PNPNet分为两个并行的分支，分别处理周期变量和非周期变量，FourierNet产生的结果$\mathbf{F}(x_{p})$和ChebyshevNet产生的结果$\mathbf{C}(x_{np})$均经过MLP，最终将得到的特征堆叠：<br>$$<br>\mathbf{h}_{fusion}&#x3D;\begin{bmatrix} \mathbf{h}_{p,L_{p}}\<br>\mathbf{h}_{np,L_{np}}<br>\end{bmatrix}<br>$$</p><p>最终将融合的表征传入最终的MLP产生最终的结果：</p><p>$$<br>\begin{aligned}<br>\mathbf{h}_{\mathrm{fusion}}&amp;&#x3D;\sigma(\mathbf{W}_{f}\mathbf{h}_{\mathrm{fusion}}+\mathbf{b}_{f})\\<br>\hat{y}&amp;&#x3D;f_{out}(\mathbf{h}_{\mathrm{final}})<br>\end{aligned}<br>$$</p><h2 id="AutoPNPNet"><a href="#AutoPNPNet" class="headerlink" title="AutoPNPNet"></a>AutoPNPNet</h2><p>PNPNet处理数据前需要进行手动分类，为了避免手动分类的麻烦，我们直接将所有数据均传入两种编码器内部，得到同时具有周期与非周期数据处理后的结果$\mathbf{F}(x)\in \mathbb{R}^{d_{F}}$和$\mathbf{C}(x)\in \mathbb{R}^{d_{C}}$后经过MLP处理，一个注意力机制被使用来优化两个分支上的权重，注意力权重如下计算：</p><p>$$<br>\begin{aligned}<br>\alpha&amp;&#x3D;\mathrm{softmax}\left(\mathbf{W}_{att}\begin{bmatrix}<br>\mathbf{h}_{F,L_{F}}\<br>\mathbf{h}_{C,L_{C}}<br>\end{bmatrix}+\mathbf{b}_{att}\right)\\<br>\alpha&amp;&#x3D;\begin{bmatrix}<br>\alpha_{F}\ \alpha_{C}<br>\end{bmatrix}<br>\end{aligned}<br>$$</p><p>其中$\mathbf{W}_{att}\in \mathbb{R}^{2\times(h_{F}+h_{C})}$，$\mathbf{b}_{att}\in \mathbb{R}^2$均为可学习的参数，$\alpha_{F}+\alpha_{C}&#x3D;1$。<br>随后通过权重计算合成的表征：</p><p>$$<br>\mathbf{h}_{\mathrm{fusion}}&#x3D;\alpha_{F}\mathbf{h}_{F,L_{F}}+\alpha_{C}\mathbf{h}_{C,L_{C}}<br>$$</p><p>最后输入到MLP中产生预测结果。当然也可以将权重替换为交叉注意力机制，然后使用线性层、激活函数、层归一化、池化操作。</p><h2 id="Training-Objective"><a href="#Training-Objective" class="headerlink" title="Training Objective"></a>Training Objective</h2><p>回归使用均方差(MSE)损失、分类使用交叉熵(CE)损失</p><h2 id="周期性检验"><a href="#周期性检验" class="headerlink" title="周期性检验"></a>周期性检验</h2><p>对于PNPNet，我们需要确定周期性，所以我们使用ACF和波峰检测算法检测周期性。作者在文中提到了一种周期性的检测算法Periodicity Detection using ACF Peaks:<br><img src="/2025/07/31/AutoPNPNet%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/PeriodicityDetect.png" alt="&quot;周期性检测&quot;"></p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TabICL论文阅读</title>
      <link href="/2025/07/27/TabICL%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
      <url>/2025/07/27/TabICL%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="模型速览"><a href="#模型速览" class="headerlink" title="模型速览"></a>模型速览</h1><p><strong><a href="https://arxiv.org/abs/2502.05564">TabICL: In-Context Learning for Tabular Data</a><strong>是对于TabPFN的一次拓展，其名字取自于In-Context Learning(ICL)，主要是使用ICL对于数据量大于10K的表格数据进行预测。其可以处理</strong>500K</strong>的数据量的同时，速度是TabPFNv2的<strong>十倍</strong>。<br>为了适配任意大小的表格数据，<strong>TabICL</strong> 将 <strong>单元格（cell）</strong> 作为基本处理单位：  每一列被看作是一组单元格值的集合，用于捕捉该特征的分布与语义；  每一行则由多个相互依赖的特征值构成。<strong>TabICL 采用两阶段架构</strong>，以实现高效的表格数据的 In-Context Learning（ICL，<strong>上下文学习</strong>）。</p><h3 id="第一阶段："><a href="#第一阶段：" class="headerlink" title="第一阶段："></a>第一阶段：</h3><p>将每一行（<strong>不包含目标标签</strong>）编码为稠密向量（dense vector embeddings），<br>每一个嵌入向量都被设计为能捕捉整个表格的信息。<br>该阶段的本质是<strong>压缩列维度</strong>，从而显著降低后续 ICL 的计算复杂度与内存开销。</p><h3 id="第二阶段："><a href="#第二阶段：" class="headerlink" title="第二阶段："></a>第二阶段：</h3><p>将这些紧凑但信息丰富的嵌入向量与其对应的标签结合，执行 ICL。<br>因此，<strong>TabICL 的核心</strong>在于<strong>第一阶段的嵌入策略</strong>，它需要将行数据转换为具有语义丰富性的向量表示。</p><h1 id="要点速递"><a href="#要点速递" class="headerlink" title="要点速递"></a>要点速递</h1><ol><li><strong>Distribution-aware Column-wise Embedding(具分布感知能力的逐列嵌入)</strong>：通过学习变量的数据分布作为列的嵌入，是一种数据特征挖掘的新思路。</li><li><strong>Hypernetwork(超网络)</strong>：通过一个网络优化另一个网络的参数。可以与学习数据特征的算法结合，用以优化网络参数。</li><li><strong>ISAB(Inducing self-attention block)</strong>：多头注意力机制的加速策略，可以有效降低注意力机制的时间复杂度（O(n^2) -&gt;O(nk)）</li><li><strong>RoPE(rotary positional embedding)</strong>：在transformer中引入位置特征的策略，作者在这里引入用于区分分布相似的不同列。此方法在Attention is All You Need中亦有提及。</li><li><strong>Tree-based generation</strong>：基于树模型的数据合成。创建一个XGBoost，将父节点作为输入，高斯噪音作为标签训练，这样可以构造一种非常复杂的非线性相关。用于创造非线性相关的数据。</li><li><strong>curriculum learning for large-scale pretraining(大规模预训练的课程学习)</strong>：LLMs中常用的一种预训练方法，仿照人类学习的过程，先学习简单的内容，再学习困难的内容，保证模型收敛。这里作者使用它作为预训练的策略。</li><li><strong>Hierarchical Class-extension Strategy</strong>：多类别分类的一种分类策略。通过创建一个树，然后在每个中间节点创造一个分类头（作者在文中使用的是2层MLP），这样就将一个大问题分解为多个小的分类问题。</li><li><strong>Permutation invariant的解决策略</strong>：列的先后对于结果无影响，也就是说列如果交换，预测结果不应该发生改变，但是该论文和TabPFN均不能在架构（均为有位置编码的Transformer架构）上实现这个目标，所以他们采用使用多种不同的排列循序训练并使用集成学习集成不同排序下的预测结果。</li></ol><h1 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h1><h2 id="Distribution-aware-Column-wise-Embedding-具分布感知能力的逐列嵌入"><a href="#Distribution-aware-Column-wise-Embedding-具分布感知能力的逐列嵌入" class="headerlink" title="Distribution-aware Column-wise Embedding(具分布感知能力的逐列嵌入)"></a>Distribution-aware Column-wise Embedding(具分布感知能力的逐列嵌入)</h2><p>对于标量单元格$c_{j} \in \mathbb{R}$，我们将其嵌入为d维的向量，不像以往的嵌入方式（对每列分配一个独特的嵌入方式），我们对所有列共享嵌入方式$\mathrm{TF_{col}}$:<br>$$<br>\begin{aligned}<br>W, B&amp;&#x3D;\mathrm{TF_{col}}(c_{j})&amp;\in \mathbb{R}^{n\times d}\\<br>e_{j}&amp;&#x3D;W\odot c_{j}+B &amp;\in \mathbb{R}^{n\times d}<br>\end{aligned}<br>$$<br>这是一种全新的思路，因为这里的bias和weight是通过transformer来计算的，作者将其称为一个类似”超网络”(Hypernetwork)的思路，就是可以生成其他网络参数的网络。而且，<strong>TF网络可以生成每个cell（也就是每个单元格）独特的权重</strong>，虽然所有列共享嵌入方式，但其实嵌入的权重是每个单元都不同。为了保证数据的先后对于结果无影响（作者将其描述为permutation-invariant），也就是我们这个TF只用于学习数据的分布，而不学习数据的顺序，$\mathrm{TF_{col}}$内部架构如下：<br>$$<br>\begin{aligned}<br>U &amp;&#x3D; \mathrm{Lin}(c) &amp;\in \mathbb{R}^{n\times d}\\<br>M &amp;&#x3D; \mathrm{MAB_{1}}(V_{I}, U_{train}, U_{train}) &amp;\in \mathbb{R}^{k\times d}\\<br>V &amp;&#x3D; \mathrm{MAB_{2}}(U, M, M) &amp;\in \mathbb{R}^{n\times d}\\<br>W,B &amp;&#x3D;\mathrm{Lin}(V) &amp;\in \mathbb{R}^{n\times d}<br>\end{aligned}<br>$$<br>MAB为多头注意力模块，Lin为全连接层，两个多头注意力模块构成的是ISAB（induced self-attention block）<br><em>ISAB是一种用于处理集合结构数据的模块，用于提升自注意力机制在大规模输入中的效率和建模能力，其中k远小于n，这样就可以减少运算量（可从O(n^2) -&gt;O(nk)），M称为诱导点（inducing points）</em><br>参数选择：d&#x3D;128, k&#x3D;128, 注意力头数&#x3D;4，ISAB&#x3D;3<br>作者为了进一步了解学习的嵌入方式，将最后一层ISAB的M的对第一个维度求和，得到每一个列的单个向量，然后使用PCA的方法降维，就会发现有相同峰度和偏度的数据会偏向于聚在一起，这意味着TF可能通过嵌入反应了数据的特征。<strong>该方法与通过语义嵌入、通过特征识别向量嵌入不同</strong></p><h2 id="Context-aware-Row-wise-Interaction-具内容感知能力的逐行融合"><a href="#Context-aware-Row-wise-Interaction-具内容感知能力的逐行融合" class="headerlink" title="Context-aware Row-wise Interaction(具内容感知能力的逐行融合)"></a>Context-aware Row-wise Interaction(具内容感知能力的逐行融合)</h2><p>在获取所有特征嵌入后$E &#x3D;[e_{1},\dots,e_{m}]\in \mathbb{R}^{n\times m\times d}$，一个三层8头的transformer$\mathrm{TF_{row}}$对E进行特征间交互。为了将嵌入合成为一个向量，四个可学习的[CLS]被添加到E的每行开头，[CLS]将会在最终输出的时候堆叠在一起，这样的4个[CLS]大小为$4 \times 128&#x3D;512$。[CLS]是对于特定样本的一种更加细节且富有信息量的表示。<br>这个模块主要是为了防止表示崩塌(Representation collapse)的发生，表示崩塌发生于所有的列内数据分布相同或相似，$\mathrm{TF_{col}}$失去了对列进行区分的作用。作者使用了一种RoPE（rotary positional embedding）的方式来打破相似分布的特征的对称性（TabPFNv2中使用的是随机的特征识别向量并按组来表示特征）。RoPE主要用于<strong>自然语言处理中通过旋转query和key向量来表示位置信息</strong>，旋转角度如下确定：p：在序列中的位置；i：维度索引；$\theta_{i}&#x3D;\frac{p}{\mathrm{base}^{2i&#x2F;d}}$；d：嵌入维度；base：频率缩放参数，transformer中使用的是10000，该文章使用的是100000，<strong>频率缩放参数越大代表容许的长度越长</strong>。<br>此外，为了保证列与列之间可交换顺序，TabICL和TabPFN使用了相同策略：对于列进行重新排列组合并进行预测后集成学习。</p><h2 id="Dataset-wise-In-Context-Learning-逐数据集的语境学习"><a href="#Dataset-wise-In-Context-Learning-逐数据集的语境学习" class="headerlink" title="Dataset-wise In-Context Learning(逐数据集的语境学习)"></a>Dataset-wise In-Context Learning(逐数据集的语境学习)</h2><p>在将所有样本转化为嵌入$H \in \mathbb{R}^{n\times 4d}$后，训练标签通过独热编码的方式被映射到与H相同的空间内。X与y相加得到最终的训练嵌入$H_{train}$。然后我们通过一个12层4头的Transformer$\mathrm{TF_{icl}}$处理$H_{train}$与$H_{test}$。其中$H_{train}$中的嵌入可以参考其他的，但是$H_{test}$中的只能参考$H_{train}$中以避免发生数据泄露。最后，一个两层的MLP将$H_{test}$的输出转化为类别概率。</p><h2 id="时间复杂度分析"><a href="#时间复杂度分析" class="headerlink" title="时间复杂度分析"></a>时间复杂度分析</h2><p>$\mathrm{TF_{col}}$复杂度为$\mathcal{O}(nkm)$（作者省去了d）<br>$\mathrm{TF_{row}}$复杂度为$\mathcal{O}(m^2n)$（也省略了d）<br>$\mathrm{TF_{icl}}$复杂度为$\mathcal{O}(n^2)$（也省略了d）<br>与TabPFN的时间复杂度$\mathcal{O}(m^2n+n^2m)$相比TabICL($\mathcal{O}(m^2n+n^2)$)对于大n和适中的m训练时间更加短。</p><h1 id="预训练与推理"><a href="#预训练与推理" class="headerlink" title="预训练与推理"></a>预训练与推理</h1><h2 id="利用合成数据的训练"><a href="#利用合成数据的训练" class="headerlink" title="利用合成数据的训练"></a>利用合成数据的训练</h2><p>合成数据的训练过程依旧类似于TabPFN，但是作者额外加入了<strong>基于树模型的SCMs（structural causal models）</strong> 和 <strong>构造过程中子代与父代间更多的函数</strong>$f$（在SCMs模型内部，变量被描述为节点，子节点由父节点计算而来$c &#x3D; f(Pa(c))+\epsilon$，$Pa(c)$是其父节点的值）</p><h3 id="Tree-based-generation"><a href="#Tree-based-generation" class="headerlink" title="Tree-based generation"></a>Tree-based generation</h3><p>$f$使用XGBoost回归模型定义。XGBoost输入父节点的值，用高斯噪声作为目标训练，获取的预测结果接下来作为子节点的值。作者使用了70%的SCMs和30%tree-based SCMs。</p><h3 id="Diversifying-activation-function"><a href="#Diversifying-activation-function" class="headerlink" title="Diversifying activation function"></a>Diversifying activation function</h3><p>作者在已有的4种激活函数的基础上加入了另外15种激活函数来增强数据中非线性相关的多样性。</p><h2 id="大规模预训练的课程学习-curriculum-learning-for-large-scale-pretraining"><a href="#大规模预训练的课程学习-curriculum-learning-for-large-scale-pretraining" class="headerlink" title="大规模预训练的课程学习(curriculum learning for large-scale pretraining)"></a>大规模预训练的课程学习(curriculum learning for large-scale pretraining)</h2><p>课程学习（Curriculum Learning, CL）最早由Bengio等人在2009年提出，它模仿人类学习的方式。训练过程中不是将所有训练数据随机喂给模型，而是按照某种 <strong>“难度”顺序</strong> ，从“容易”样本逐步过渡到“困难”样本。这种学习方法主要用于LLMs的预训练，作者在这里通过逐渐增加合成数据集的大小，同时调整用于梯度累积的微批量大小($N_{\mathcal{B}}$: micro batch size)来适应内存限制，训练可分为3个阶段：</p><ol><li>$N_{\mathcal{B}}$&#x3D;4，batch size &#x3D; 1024, 160k步训练</li><li>$N_{\mathcal{B}}$&#x3D;1，batch size $\sim$ log-uniform$[1\mathrm{K}, 40\mathrm{K}]$  , 2k步训练</li><li>$N_{\mathcal{B}}$&#x3D;1，batch size $\sim$ log-uniform$[40\mathrm{K}, 60\mathrm{K}]$  , 50步训练，只更新$\mathrm{TF}_{icl}$</li></ol><h2 id="Hierarchical-Class-extension-Strategy"><a href="#Hierarchical-Class-extension-Strategy" class="headerlink" title="Hierarchical Class-extension Strategy"></a>Hierarchical Class-extension Strategy</h2><p>一种多类别分类任务的解决方法。<br>当类别大于10种时，就会递归地构造一个多层分类树，每个中间节点可以区分10个类别（中间节点的分类是进行2层的MLP进行分类），所以当要完成k分类任务时，需要的树深度为r&#x3D;$\lceil \log_{10}k \rceil$。这样在推理过程中，只需要计算从树根到类别对应叶节点的概率的累乘，就可以得到预测的概率。<br>这样一个树的构建发生于dataset-wise ICL。<br>所有的子任务都是基于相同的行嵌入H和$\mathrm{TF_{icl}}$。这些共享的参数提高了TabICL的效率。</p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实用代码（随机更新）</title>
      <link href="/2025/07/16/%E5%AE%9E%E7%94%A8%E4%BB%A3%E7%A0%81%EF%BC%88%E9%9A%8F%E6%9C%BA%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
      <url>/2025/07/16/%E5%AE%9E%E7%94%A8%E4%BB%A3%E7%A0%81%EF%BC%88%E9%9A%8F%E6%9C%BA%E6%9B%B4%E6%96%B0%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="使用代理"><a href="#使用代理" class="headerlink" title="使用代理"></a>使用代理</h1><p>国内需要访问github或者使用pip安装新的包时，经常需要修改代理，这里主要覆盖一些常用的代理使用代码</p><h2 id="git的代理"><a href="#git的代理" class="headerlink" title="git的代理"></a>git的代理</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.proxy <span class="string">&quot;127.0.0.1:7890&quot;</span></span><br><span class="line">git config --global https.proxy <span class="string">&quot;127.0.0.1:7890&quot;</span></span><br></pre></td></tr></table></figure><h2 id="WSL使用代理"><a href="#WSL使用代理" class="headerlink" title="WSL使用代理"></a>WSL使用代理</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> http_proxy=http://127.0.0.1:7890</span><br><span class="line"><span class="built_in">export</span> https_proxy=http://127.0.0.1:7890</span><br></pre></td></tr></table></figure><h1 id="进程处理"><a href="#进程处理" class="headerlink" title="进程处理"></a>进程处理</h1><p>在我们进行后端开发时，可能会忘记中止后端，这时便需要使用这个代码来杀死特定进程，空出特定端口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">//查看端口进程PID</span><br><span class="line">netstat -ano | findstr :5173</span><br><span class="line">//杀灭特定PID进程</span><br><span class="line">taskkill /PID 12345 /F</span><br></pre></td></tr></table></figure><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 实用技巧 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>T2G代码阅读</title>
      <link href="/2025/07/11/T2G%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/"/>
      <url>/2025/07/11/T2G%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="Tokenizer"><a href="#Tokenizer" class="headerlink" title="Tokenizer"></a>Tokenizer</h1><p>输入数据(tensor: $\text{batch_size}\times \text{categories}(\text{d_numerical})$)后tokenizer获得$x \in \mathbb{R}^{ \text{batch_size}\times (1+ \text{d_numerical}+\text{categories})\times {d_{token}}}$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Tokenizer</span>(nn.Module):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">self,</span></span><br><span class="line"><span class="params">d_numerical: <span class="built_in">int</span></span></span><br><span class="line"><span class="params">categories: ty.<span class="type">Optional</span>[ty.<span class="type">List</span>[<span class="built_in">int</span>]],</span></span><br><span class="line"><span class="params">d_token: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">bias: <span class="built_in">bool</span>,</span></span><br><span class="line"><span class="params"></span>) -&gt; <span class="literal">None</span></span><br><span class="line"><span class="built_in">super</span>().__init__()</span><br><span class="line"><span class="keyword">if</span> categories <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">d_bias = d_numerical</span><br><span class="line"><span class="variable language_">self</span>.category_offsets = <span class="literal">None</span></span><br><span class="line"><span class="variable language_">self</span>.category_embeddings = <span class="literal">None</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">d_bias = d_numerical + <span class="built_in">len</span>(categories)</span><br><span class="line">category_offsets = torch.tensor([<span class="number">0</span>] + categories[:-<span class="number">1</span>]).cumsum(<span class="number">0</span>)</span><br><span class="line"><span class="variable language_">self</span>.register_buffer(<span class="string">&#x27;category_offsets&#x27;</span>, category_offsets)</span><br><span class="line"><span class="variable language_">self</span>.category_embeddings = nn.Embedding(<span class="built_in">sum</span>(categories), d_token)</span><br><span class="line">nn_init.kaiming_uniform_(<span class="variable language_">self</span>.category_embeddings.weight, a=math.sqrt(<span class="number">5</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;self.category_embeddings.weight.shape&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># take [Cross-level Readout Node] into account</span></span><br><span class="line"><span class="variable language_">self</span>.weight = nn.Parameter(Tensor(d_numerical + <span class="number">1</span>, d_token))</span><br><span class="line"><span class="variable language_">self</span>.bias = nn.Parameter(Tensor(d_bias, d_token)) <span class="keyword">if</span> bias <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line"><span class="comment"># The initialization is inspired by nn.Linear</span></span><br><span class="line">nn_init.kaiming_uniform_(<span class="variable language_">self</span>.weight, a=math.sqrt(<span class="number">5</span>))</span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">nn_init.kaiming_uniform_(<span class="variable language_">self</span>.bias, a=math.sqrt(<span class="number">5</span>))</span><br></pre></td></tr></table></figure><p>初始化方法<br>Args:<br>d_numerical(int)：数值特征的维度数量。<br>categories(Optional[List[int]])：分类特征的类别数量列表，若无则为None<br>d_token(int)：词向量的维度大小<br>bias(bool)：是否使用偏置项<br>Attributes:<br>d_bias：为偏置项的数目，对应categories特征和numerical特征的数目之和。<br>category_offsets(tensor)：不同特征的index，例如categories&#x3D;[2,4,6]，则category_offsets为[0,2,6]，这是因为对于category的处理是将不同的category堆叠为一个矩阵，所以我们需要知道不同的特征对应的index。然后将category_index注册为一个buffer，此时category_index将无法进行训练更新。<br>category_embeddings：创建从特征向特征嵌入的映射，其实就是一个$\mathbb{R}^{categories\times d_{token}}$的矩阵，然后通过矩阵乘法将维度$\mathbb{R}^{categories}$转为$\mathbb{R}^{d_{token}}$<br>self.weight：数值特征与Cross-level Readout的节点权重，$\mathbb{R}^{(d_numerical+1)\times d_token}$。<small>有亿些下划线渲染失败了，不高兴改了，大概就是 $\text{d_numerical} &#x3D; d_numerical$</small><br>self.bias：偏置矩阵，$\mathbb{R}^{d_bias\times d_token}$<br>Notes:<br>创建类别的映射矩阵并构建类别映射的index，使用kaiming初始化对映射矩阵初始化。kaiming初始化如下$$W_{ij} \sim \mathcal{U}(-\mathrm{bound},\mathrm{bound})$$$$\mathrm{bound}&#x3D;\sqrt{ \frac{6}{(1+a^2) \cdot\mathrm{fan_in}} }$$<br>其中a在这里定义为sqrt(5)，为负斜率(slope)，fan_in为输入的特征数量<br>所有初始化均采用kaiming初始化，与nn.Linear保持一致。<br>Returns:<br>None</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@property</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">n_tokens</span>(<span class="params">self</span>) -&gt; <span class="built_in">int</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.weight) + (</span><br><span class="line">        <span class="number">0</span> <span class="keyword">if</span> <span class="variable language_">self</span>.category_offsets <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.category_offsets)</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>获取特征的数目<br>Args：self<br>Attributes：None<br>returns：<br>获取特征的总数，如果有10个数值特征，5个类别特征，再加上一个Cross-level Readout，则返回16<br>Notes：<br>将函数注册为一个不可修改的方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_num: Tensor, x_cat: ty.<span class="type">Optional</span>[Tensor]</span>) -&gt; Tensor:</span><br><span class="line">x_some = x_num <span class="keyword">if</span> x_cat <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> x_cat</span><br><span class="line"><span class="keyword">assert</span> x_some <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">x_num = torch.cat(</span><br><span class="line">[torch.ones(<span class="built_in">len</span>(x_some), <span class="number">1</span>, device=x_some.device)]  <span class="comment"># [CLS]</span></span><br><span class="line">+ ([] <span class="keyword">if</span> x_num <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">else</span> [x_num]),</span><br><span class="line">dim=<span class="number">1</span>,</span><br><span class="line">)</span><br><span class="line">x = <span class="variable language_">self</span>.weight[<span class="literal">None</span>] * x_num[:, :, <span class="literal">None</span>]</span><br><span class="line"><span class="keyword">if</span> x_cat <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">x = torch.cat(</span><br><span class="line">[x, <span class="variable language_">self</span>.category_embeddings(x_cat + <span class="variable language_">self</span>.category_offsets[<span class="literal">None</span>])],</span><br><span class="line">dim=<span class="number">1</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">bias = torch.cat(</span><br><span class="line">[</span><br><span class="line">torch.zeros(<span class="number">1</span>, <span class="variable language_">self</span>.bias.shape[<span class="number">1</span>], device=x.device),</span><br><span class="line"><span class="variable language_">self</span>.bias,</span><br><span class="line">]</span><br><span class="line">)</span><br><span class="line">x = x + bias[<span class="literal">None</span>]</span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>前向传播方法<br>Args：<br>x_num(tensor): 数值特征的矩阵，$\mathbb{R}^{batch_size\times d_numerical}$。<br>x_cat(ty.Optional[Tensor]): 类别特征的矩阵，可选，$\mathbb{R}^{batch_size\times categories}$。<br>Attributes：<br>x_num(tensor): 带有[CLS]的矩阵，$\mathbb{R}^{batch_size\times (1+d_numerical)}$<br>x(tensor): 通过自动广播计算，广播后逐元素相乘，$\mathbb{R}^{batch_size\times (1+d_numerical)\times {d_{token}}}$，如果有类别变量，则将类别变量与广播后的位置矩阵相加并x堆叠起来，得到$\mathbb{R}^{batch_size\times (1+d_numerical+categories)\times {d_{token}}}$，与bias相加后大小不变<br>bias(tensor): 先堆叠为$\mathbb{R}^{(1+d_bias)\times d_token}$，然后增加维度为$\mathbb{R}^{1\times(1+d_bias)\times d_token}$，与x相加得到x<br>Notes：<br>tensor索引中使用None索引是对tensor新加一个维度，例如self.weight就是$\mathbb{R}^{(d_numerical+1)\times d_token}\to \mathbb{R}^{1\times(d_numerical+1)\times d_token}$，x_num就是$\mathbb{R}^{batch_size\times (1+d_numerical)\times {1}}$。<br>这里使用的自动广播功能主要是对于batch进行重复操作。<br>Returns：<br>x(tensor): $\mathbb{R}^{batch_size\times (1+d_numerical+categories)\times {d_{token}}}$</p><h1 id="MultiheadGEAttention"><a href="#MultiheadGEAttention" class="headerlink" title="MultiheadGEAttention"></a>MultiheadGEAttention</h1><p>多头GE注意力模块：输入原数据，然后得到一个经过该图神经网络的数据和图神经网络的架构。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MultiheadGEAttention</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    FR-Graph integrated attention</span></span><br><span class="line"><span class="string">    ---</span></span><br><span class="line"><span class="string">    Learn relations among features and feature selection strategy in data-driven manner.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        <span class="comment"># Normal Attention Args</span></span></span><br><span class="line"><span class="params">        self, d: <span class="built_in">int</span>, n_heads: <span class="built_in">int</span>, dropout: <span class="built_in">float</span>, initialization: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        <span class="comment"># FR-Graph Args</span></span></span><br><span class="line"><span class="params">        n: <span class="built_in">int</span>, sym_weight: <span class="built_in">bool</span> = <span class="literal">True</span>, sym_topology: <span class="built_in">bool</span> = <span class="literal">False</span>, nsi: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">if</span> n_heads &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">assert</span> d % n_heads == <span class="number">0</span></span><br><span class="line">        <span class="keyword">assert</span> initialization <span class="keyword">in</span> [<span class="string">&#x27;xavier&#x27;</span>, <span class="string">&#x27;kaiming&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.W_v = nn.Linear(d, d)</span><br><span class="line">        <span class="variable language_">self</span>.W_out = nn.Linear(d, d) <span class="keyword">if</span> n_heads &gt; <span class="number">1</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        <span class="variable language_">self</span>.n_heads = n_heads</span><br><span class="line">        <span class="variable language_">self</span>.dropout = nn.Dropout(dropout) <span class="keyword">if</span> dropout <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">        </span><br><span class="line">        <span class="string">&quot;&quot;&quot;FR-Graph Params: Edge weights&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># head and tail transformation</span></span><br><span class="line">        <span class="variable language_">self</span>.W_head = nn.Linear(d, d)</span><br><span class="line">        <span class="keyword">if</span> sym_weight:</span><br><span class="line">            <span class="variable language_">self</span>.W_tail = <span class="variable language_">self</span>.W_head <span class="comment"># symmetric weights</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.W_tail = nn.Linear(d, d) <span class="comment"># ASYM</span></span><br><span class="line">        <span class="comment"># relation embedding: learnable diagonal matrix</span></span><br><span class="line">        <span class="variable language_">self</span>.rel_emb = nn.Parameter(torch.ones(n_heads, d // <span class="variable language_">self</span>.n_heads))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> [<span class="variable language_">self</span>.W_head, <span class="variable language_">self</span>.W_tail, <span class="variable language_">self</span>.W_v]:</span><br><span class="line">            <span class="keyword">if</span> initialization == <span class="string">&#x27;xavier&#x27;</span> <span class="keyword">and</span> (n_heads &gt; <span class="number">1</span> <span class="keyword">or</span> m <span class="keyword">is</span> <span class="keyword">not</span> <span class="variable language_">self</span>.W_v):</span><br><span class="line">                nn_init.xavier_uniform_(m.weight, gain=<span class="number">1</span> / math.sqrt(<span class="number">2</span>))</span><br><span class="line">            nn_init.zeros_(m.bias)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.W_out <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            nn_init.zeros_(<span class="variable language_">self</span>.W_out.bias)</span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot;FR-Graph Params: Graph topology (column = node = feature)&quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.n_cols = n + <span class="number">1</span> <span class="comment"># Num of Nodes: input feature nodes + [Cross-level Readout]</span></span><br><span class="line">        <span class="variable language_">self</span>.nsi = nsi <span class="comment"># no self-interaction</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># column embeddings: semantics for each column</span></span><br><span class="line">        d_col = math.ceil(<span class="number">2</span> * math.log2(<span class="variable language_">self</span>.n_cols)) <span class="comment"># dim for column header embedding -&gt; d_header += d</span></span><br><span class="line">        <span class="variable language_">self</span>.col_head = nn.Parameter(Tensor(<span class="variable language_">self</span>.n_heads, <span class="variable language_">self</span>.n_cols, d_col))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> sym_topology:</span><br><span class="line">            <span class="variable language_">self</span>.col_tail = nn.Parameter(Tensor(<span class="variable language_">self</span>.n_heads, <span class="variable language_">self</span>.n_cols, d_col))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.col_tail = <span class="variable language_">self</span>.col_head <span class="comment"># share the parameter</span></span><br><span class="line">        <span class="keyword">for</span> W <span class="keyword">in</span> [<span class="variable language_">self</span>.col_head, <span class="variable language_">self</span>.col_tail]:</span><br><span class="line">            <span class="keyword">if</span> W <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="comment"># correspond to Tokenizer initialization</span></span><br><span class="line">                nn_init.kaiming_uniform_(W, a=math.sqrt(<span class="number">5</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Learnable bias and fixed threshold for topology</span></span><br><span class="line">        <span class="variable language_">self</span>.bias = nn.Parameter(torch.zeros(<span class="number">1</span>))</span><br><span class="line">        <span class="variable language_">self</span>.threshold = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Frozen topology&quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># for some sensitive datasets set to `True`</span></span><br><span class="line">        <span class="comment"># after training several epoch, which helps</span></span><br><span class="line">        <span class="comment"># stability and better performance</span></span><br><span class="line">        <span class="variable language_">self</span>.frozen = <span class="literal">False</span></span><br></pre></td></tr></table></figure><p>初始化模块<br>Args:<br>d(int): 输入的特征维度<br>n_heads(int): 特征头的数量<br>dropout(float): dropout率<br>initialization(str: [xavier, kaiming]): 初始化方法<br>n(int): 输入的特征数<br>sym_weight(bool): 是否共享头尾转换的权重<br>sym_topology(bool): 是否共享拓扑嵌入的参数<br>nsi(bool): 是否禁用自交互(圈，在邻接矩阵中就是对角线)<br>Attributes:<br>边权重:<br>self.W_head(torch.nn.Linear): $d\to d$的全连接层<br>self.rel_emb(torch.tensor): 对角矩阵，可学习的，$\mathbb{R}^{n_heads\times (d&#x2F;n_heads)}$，但是在最初创建的时候，其使用torch.ones进行创建，创建的是一个全1矩阵。<br>图拓扑结构:<br>self.n_cols(int): n+1，为特征数+1(也就是多了一个跨层读取)<br>self.nsi(bool): nsi.<br>d_col(int): 列的嵌入维度，通过$\lceil 2\times \log_{2}(self.n_{cols}) \rceil$确定<br>self.col_head(torch.tensor): self.n_heads * self.n_cols * d_col.<br>self.bias(torch.tensor&#x3D;[1]): 可学习参数，是图拓扑结构的门控结构中的bias。<br>self.threshold(int&#x3D;0.5): 固定参数，是图拓扑结构的阈值<br>self.frozen(bool): 对于部分敏感的数据集，将会自动停止。<br>Notes:<br>边权重的初始化采用xavier，图拓扑结构的初始化采用kaiming初始化。<br>Returns:<br>None</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_reshape</span>(<span class="params">self, x: Tensor</span>) -&gt; Tensor:</span><br><span class="line">batch_size, n_tokens, d = x.shape</span><br><span class="line">d_head = d // <span class="variable language_">self</span>.n_heads</span><br><span class="line"><span class="keyword">return</span> (</span><br><span class="line">x.reshape(batch_size, n_tokens, <span class="variable language_">self</span>.n_heads, d_head)</span><br><span class="line">.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>用于注意力机制中的”分头”。将batch_size * n_tokens * d的矩阵转化为 batch_size * n_heads * n_tokens * d_heads，其中 d_heads &#x3D; d &#x2F;&#x2F; n_heads。<br>Args:<br>x(torch.tensor)<br>Returns:<br>x(torch.tensor)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_no_self_interaction</span>(<span class="params">self, x</span>):</span><br><span class="line"><span class="keyword">if</span> x.shape[-<span class="number">2</span>] == <span class="number">1</span>: <span class="comment"># only [Readout Node]</span></span><br><span class="line"><span class="keyword">return</span> x</span><br><span class="line"><span class="keyword">assert</span> x.shape[-<span class="number">1</span>] == x.shape[-<span class="number">2</span>] == <span class="variable language_">self</span>.n_cols</span><br><span class="line"><span class="comment"># mask diagonal interaction</span></span><br><span class="line">nsi_mask = <span class="number">1.0</span> - torch.diag_embed(torch.ones(<span class="variable language_">self</span>.n_cols, device=x.device))</span><br><span class="line"><span class="keyword">return</span> x * nsi_mask</span><br></pre></td></tr></table></figure><p>去除自我交互<br>Args:<br>x(torch.Tensor)<br>Notes:<br>1. 输入的第二个维度应该大于一，若等于则为仅存在一个Readout Node<br>2. 应该是方阵，且维度等于特征数+1(也就是图拓扑结构内的跨层读取)<br>3. 减去一个n_cols维的单位矩阵<br>4. 最后与输入逐元素相乘，得到一个对角线为0的adjacent matrix<br>Returns:<br>对角线为0的adjacent matrix</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_prune_to_readout</span>(<span class="params">self, x</span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;Prune edges from any features to [Readout Node]&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">assert</span> x.shape[-<span class="number">1</span>] == <span class="variable language_">self</span>.n_cols</span><br><span class="line">mask = torch.ones(<span class="variable language_">self</span>.n_cols, device=x.device)</span><br><span class="line">mask[<span class="number">0</span>] = <span class="number">0</span> <span class="comment"># zero out interactions from features to [Readout]</span></span><br><span class="line"><span class="keyword">return</span> x * mask</span><br></pre></td></tr></table></figure><p>修建Readout节点的入度<br>Args:<br>x(torch.Tensor)<br>Notes:<br>创建一个n_cols的全1向量，然后设置第一个数字为0后广播逐元素相乘<br>Returns:<br>x * mask(torch.Tensor): 第一列为0的邻接矩阵，代表没有特征指向Readout节点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_get_topology</span>(<span class="params">self, top_score, elewise_func=torch.sigmoid</span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Learning static knowledge topology (adjacency matrix)</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">top_score: N x N tensor, relation topology score</span></span><br><span class="line"><span class="string">adj: adjacency matrix A of FR-Graph</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">adj_probs = elewise_func(top_score + <span class="variable language_">self</span>.bias) <span class="comment"># choose `sigmoid` as element-wise activation (sigma1)</span></span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.nsi:</span><br><span class="line">adj_probs = <span class="variable language_">self</span>._no_self_interaction(adj_probs) <span class="comment"># apply `nsi` function</span></span><br><span class="line">adj_probs = <span class="variable language_">self</span>._prune_to_readout(adj_probs) <span class="comment"># cut edges from features to [Readout]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.frozen:</span><br><span class="line"><span class="comment"># using `Straight-through` tirck for non-differentiable operation</span></span><br><span class="line">adj = (adj_probs &gt; <span class="number">0.5</span>).<span class="built_in">float</span>() - adj_probs.detach() + adj_probs</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="comment"># frozen graph topology: no gradient</span></span><br><span class="line">adj = (adj_probs &gt; <span class="number">0.5</span>).<span class="built_in">float</span>()</span><br><span class="line"><span class="keyword">return</span> adj</span><br></pre></td></tr></table></figure><p>学习静态知识图谱的邻接矩阵<br>Args:<br>top_score(int): 相关性拓扑得分<br>elewise_func(func): 默认使用torch.sigmoid，是一种逐元素运算<br>Attributes:<br>adj_probs(torch.Tensor): 这是门控函数<br>Notes:<br>这里使用了straight-through的反向传播策略，这是一种当操作过程中设计不可导操作时进行的反向传播策略，基本原理就是构造一个导数用于反向传播。<br>adj_probs.detach()用于阻断当前梯度，其可以返回一个全新的，没有梯度的矩阵。<br>adj_probs &gt; 0.5 是前向传播的输出值，梯度值则由adj_probs的梯度得出，如此的策略可以用以下式子概括。如果没有梯度就不传入adj_probs的梯度。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">adj = hard - soft.detach() + soft</span><br></pre></td></tr></table></figure><p>Returns:<br>adj(torch.Tensor): 知识图谱的邻接矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"></span></span><br><span class="line"><span class="params">self,</span></span><br><span class="line"><span class="params">x_head: Tensor,</span></span><br><span class="line"><span class="params">x_tail: Tensor,</span></span><br><span class="line"><span class="params">key_compression: ty.<span class="type">Optional</span>[nn.Linear],</span></span><br><span class="line"><span class="params">value_compression: ty.<span class="type">Optional</span>[nn.Linear],</span></span><br><span class="line"><span class="params">elewise_func = torch.sigmoid,</span></span><br><span class="line"><span class="params">comp_func = torch.softmax,</span></span><br><span class="line"><span class="params"></span>) -&gt; Tensor:</span><br><span class="line">f_head, f_tail, f_v = <span class="variable language_">self</span>.W_head(x_head), <span class="variable language_">self</span>.W_tail(x_tail), <span class="variable language_">self</span>.W_v(x_tail)</span><br><span class="line"><span class="keyword">for</span> tensor <span class="keyword">in</span> [f_head, f_tail, f_v]:</span><br><span class="line"><span class="comment"># check multi-head</span></span><br><span class="line"><span class="keyword">assert</span> tensor.shape[-<span class="number">1</span>] % <span class="variable language_">self</span>.n_heads == <span class="number">0</span></span><br><span class="line"><span class="keyword">if</span> key_compression <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"><span class="keyword">assert</span> value_compression <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">f_tail = key_compression(f_tail.transpose(<span class="number">1</span>, <span class="number">2</span>)).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">f_v = value_compression(f_v.transpose(<span class="number">1</span>, <span class="number">2</span>)).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">assert</span> value_compression <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="built_in">len</span>(f_head)</span><br><span class="line">d_head_tail = f_tail.shape[-<span class="number">1</span>] // <span class="variable language_">self</span>.n_heads</span><br><span class="line">d_value = f_v.shape[-<span class="number">1</span>] // <span class="variable language_">self</span>.n_heads</span><br><span class="line">n_head_nodes = f_head.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># reshape to multi-head view</span></span><br><span class="line">f_head = <span class="variable language_">self</span>._reshape(f_head)</span><br><span class="line">f_tail = <span class="variable language_">self</span>._reshape(f_tail)</span><br><span class="line"></span><br><span class="line"><span class="comment"># edge weight scores (Gw)</span></span><br><span class="line">weight_score = f_head @ torch.diag_embed(<span class="variable language_">self</span>.rel_emb) @ f_tail.transpose(-<span class="number">1</span>, -<span class="number">2</span>) / math.sqrt(d_head_tail)</span><br><span class="line"></span><br><span class="line">col_emb_head = F.normalize(<span class="variable language_">self</span>.col_head, p=<span class="number">2</span>, dim=-<span class="number">1</span>) <span class="comment"># L2 normalized column embeddings</span></span><br><span class="line">col_emb_tail = F.normalize(<span class="variable language_">self</span>.col_tail, p=<span class="number">2</span>, dim=-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># topology score (Gt)</span></span><br><span class="line">top_score = col_emb_head @ col_emb_tail.transpose(-<span class="number">1</span>, -<span class="number">2</span>)</span><br><span class="line"><span class="comment"># graph topology (A)</span></span><br><span class="line">adj = <span class="variable language_">self</span>._get_topology(top_score, elewise_func)</span><br><span class="line"><span class="keyword">if</span> n_head_nodes == <span class="number">1</span>: <span class="comment"># only [Cross-level Readout]</span></span><br><span class="line">adj = adj[:, :<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># graph assembling: apply FR-Graph on interaction like attention mask</span></span><br><span class="line">adj_mask = (<span class="number">1.0</span> - adj) * -<span class="number">10000</span> <span class="comment"># analogous to attention mask</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># FR-Graph of this layer</span></span><br><span class="line"><span class="comment"># Can be used for visualization on Feature Relation and Readout Collection</span></span><br><span class="line">fr_graph = comp_func(weight_score + adj_mask, dim=-<span class="number">1</span>) <span class="comment"># choose `softmax` as competitive function</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">fr_graph = <span class="variable language_">self</span>.dropout(fr_graph)</span><br><span class="line">x = fr_graph @ <span class="variable language_">self</span>._reshape(f_v)</span><br><span class="line">x = (</span><br><span class="line">x.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">.reshape(batch_size, n_head_nodes, <span class="variable language_">self</span>.n_heads * d_value)</span><br><span class="line">)</span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.W_out <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">x = <span class="variable language_">self</span>.W_out(x)</span><br><span class="line"><span class="keyword">return</span> x, fr_graph.detach()</span><br></pre></td></tr></table></figure><p>nn.module特有的前向传播函数<br>Args:<br>x_head(torch.Tensor):<br>x_tail(Tensor):<br>key_compression(type.Optional[nn.Linear]):<br>value_compression(type.Optional[nn.Linear]):<br>elewise_func(function: torch.sigmoid):<br>comp_func(function: torch.softmax):<br>Attributes:<br>f_head, f_tail, f_v: x_head, x_tail以及x_v经过变换后得到的图嵌入<br>weight_score: 边的权重矩阵，由f_head @ rel_emb @ f_tail^T&#x2F;sqrt(d) 得到<br>top_score: 拓扑邻接矩阵，由col_emb_head @ col_emb_tail^T 得到<br>adj_mask: 遮掩矩阵，对于没有连接的两个节点的交点，设置为-10000，其余为1<br>fr_graph: 最终的图邻接矩阵，comp_func(weight_score + adj_mask)得到，其中comp_func为softmax函数。这样就可以得到一个邻接矩阵，相连的权重为正，不相连的则接近-10000<br>self.W_out: 输入到下一层最后的线性变换，是一个全连接层。<br>x: 是输出向下一层的值，由W_v($\mathbb{R}^{d\times d}$)与x_tail相乘得到。<br>Returns:<br>x: 输出向下一层的值，矩阵大小不变，依旧是batch_size * n_head_nodes(节点总数) * d(特征嵌入的维度)，最后还需经过一个$d\to d$的全连接层<br>fr_graph: 图邻接矩阵，无梯度</p><h1 id="T2GFormer"><a href="#T2GFormer" class="headerlink" title="T2GFormer"></a>T2GFormer</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">T2GFormer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;T2G-Former</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    References:</span></span><br><span class="line"><span class="string">    - FT-Transformer: https://github.com/Yura52/tabular-dl-revisiting-models/blob/main/bin/ft_transformer.py#L151</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        *,</span></span><br><span class="line"><span class="params">        <span class="comment"># tokenizer</span></span></span><br><span class="line"><span class="params">        d_numerical: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        categories: ty.<span class="type">Optional</span>[ty.<span class="type">List</span>[<span class="built_in">int</span>]],</span></span><br><span class="line"><span class="params">        token_bias: <span class="built_in">bool</span>,</span></span><br><span class="line"><span class="params">        <span class="comment"># transformer</span></span></span><br><span class="line"><span class="params">        n_layers: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        d_token: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        n_heads: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">        d_ffn_factor: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">        attention_dropout: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">        ffn_dropout: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">        residual_dropout: <span class="built_in">float</span>,</span></span><br><span class="line"><span class="params">        activation: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        prenormalization: <span class="built_in">bool</span>,</span></span><br><span class="line"><span class="params">        initialization: <span class="built_in">str</span>,</span></span><br><span class="line"><span class="params">        <span class="comment"># linformer</span></span></span><br><span class="line"><span class="params">        kv_compression: ty.<span class="type">Optional</span>[<span class="built_in">float</span>],</span></span><br><span class="line"><span class="params">        kv_compression_sharing: ty.<span class="type">Optional</span>[<span class="built_in">str</span>],</span></span><br><span class="line"><span class="params">        <span class="comment"># graph estimator</span></span></span><br><span class="line"><span class="params">        sym_weight: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        sym_topology: <span class="built_in">bool</span> = <span class="literal">False</span>,</span></span><br><span class="line"><span class="params">        nsi: <span class="built_in">bool</span> = <span class="literal">True</span>,</span></span><br><span class="line"><span class="params">        <span class="comment">#</span></span></span><br><span class="line"><span class="params">        d_out: <span class="built_in">int</span>,</span></span><br><span class="line"><span class="params">    </span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">assert</span> (kv_compression <span class="keyword">is</span> <span class="literal">None</span>) ^ (kv_compression_sharing <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.tokenizer = Tokenizer(d_numerical, categories, d_token, token_bias)</span><br><span class="line">        n_tokens = <span class="variable language_">self</span>.tokenizer.n_tokens</span><br></pre></td></tr></table></figure><p>初始化T2GFormer<br>Args:<br>tokenizer:<br>d_numerical(int): 特征的维度<br>categories(type.List[int]): 类别特征的类别数，例如性别为男女，则类别数为2，如果有4种职业，那类别数为4<br>token_bias(bool): 是否使用tokenizer的偏置项<br>transformer:<br>n_layer(int): 堆叠几个GE+transformer的架构<br>d_token(int): 每个特征在嵌入时会转化为几维的向量，例如将数值转化为8维的向量<br>n_heads(int): attention模块有几个头<br>d_ffn_factor(float): 全连接层的隐藏层神经元占d_token的比例，具体就是d_ffn_factor * d_token等于隐藏层的神经元个数<br>attention_dropout(float): attention层中出现dropout的概率<br>ffn_dropout(float): 全连接层出现dropout的概率<br>residual_dropout(float): 同上<br>activation(str): 激活函数的名字。<br>prenormalization(bool): 预归一化，是在残差层前归一化还是在残差层后归一化，体现在代码如下。<br>initialization(str): 初始化方法<br>linformer:<br>kv_compression(type.Optional[float]): 压缩k,v矩阵的token数<br>kv_compression_sharing(type.Optional[str] &#x3D; layerwise): 代表专门创建一个压缩层，所有层均共用这个层 。<br>graph estimator:<br>sym_weight(bool): 是否保证头尾的权重矩阵相同（是否对称）<br>sym_topology(bool): 是否保证头尾的拓扑结构图相同（是否对称）<br>d_out(int): 输出维度</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># prenormalization</span></span><br><span class="line">x = x + attention(norm0(x))</span><br><span class="line">x = x + linear(norm1(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># postnormalization</span></span><br><span class="line">x = norm0(x + attention(x))</span><br><span class="line">x = norm1(x + linear(x))</span><br></pre></td></tr></table></figure><p>Attributes:<br>self.tokenizer: 分词器，输入的数值特征嵌入为d_numerical维的向量，categories为类别的数量，为List[int]，d_token分词器处理后产生的维度，token_bias：是否启用bias.<br>n_tokens(int): 是所有特征加起来的数量+1，<em>这段代码写得并不好，因为n_tokens被反复赋值，后续直接等于所有特征的数量</em>。<br>self.shared_kv_compression(nn.Linear): 当使用kv压缩且kv_compression_sharing &#x3D; layerwise则赋值为make_kv_compression，反之则赋值为None<br>d_hidden(int): d_token * d_ffn_factor<br>self.activation(function): 激活函数。<br>self.last_activation(function): 激活函数，但是glu版本换成正常版本，避免最后一层进行glu激活。<br>self.last_normalization(type.Option[make_normalization]): 最后一层层归一化操作，如果有预归一化则为None.<br>self.head(nn.Linear): 分类头, d_token-&gt;d_out.<br>self.layers(nn.ModuleList[nn.ModuleDict]):<br>存放网络的层信息，每层由以下组分构成：<br>attention(MultiheadGEAttention): d_token维度，n_heads个头，n_tokens个特征(这里的n_tokens没有”+1”，其实是在MultiheadGEAttention里面+1获得self.n_cols)<br>linear0(nn.Linear): 1-&gt;2层神经网络，d_token -&gt; d_hidden<br>linear1(nn.Linear): 2-&gt;3层神经网络，d_hidden -&gt; d_token<br>norm1(nn.LayerNorm &#x3D; make_normalization): 层归一化<br>norm0(type.Option[nn.LayerNorm] &#x3D; make_normalization): 如果不进行prenormalization或者layer_idx !&#x3D; 0，就存在norm0，反之则不存在。也就是只有第一行有区别，只有在进行前归一化时，第一行可以不加norm0.<br>key_compression(nn.Linear &#x3D; make_kv_compression): 只有当kv_compression存在且不为False, shared_kv_compression不存在，设置为make_kv_compression<br>value_compression(nn.Linear &#x3D; make_kv_compression): 当kv_compression当kv_compression存在且不为False, shared_kv_compression不存在，且kv_compression_sharing &#x3D;&#x3D; headwise时设置为make_kv_compression。<br><em>这里逻辑上就是：如果需要使用kv_compression，但是不共享，那么就给每层都创造一个对于key与value的compression，如果我们要区分key与value的压缩(也就是headwise)，那么就再独立创建一个value_compression，反之则key与value共用压缩(也就是key-value)</em></p><p>function:<br>make_kv_compression(nn.Linear): 构建kv压缩层，n_tokens -&gt; n_tokens * kv_compression<br>make_normalization(nn.LayerNorm): 层归一化，这里n_tokens依旧是”+1”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_get_kv_compressions</span>(<span class="params">self, layer</span>):</span><br><span class="line"><span class="keyword">return</span> (</span><br><span class="line">(<span class="variable language_">self</span>.shared_kv_compression, <span class="variable language_">self</span>.shared_kv_compression)</span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.shared_kv_compression <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">else</span> (layer[<span class="string">&#x27;key_compression&#x27;</span>], layer[<span class="string">&#x27;value_compression&#x27;</span>])</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;key_compression&#x27;</span> <span class="keyword">in</span> layer <span class="keyword">and</span> <span class="string">&#x27;value_compression&#x27;</span> <span class="keyword">in</span> layer</span><br><span class="line"><span class="keyword">else</span> (layer[<span class="string">&#x27;key_compression&#x27;</span>], layer[<span class="string">&#x27;key_compression&#x27;</span>])</span><br><span class="line"><span class="keyword">if</span> <span class="string">&#x27;key_compression&#x27;</span> <span class="keyword">in</span> layer</span><br><span class="line"><span class="keyword">else</span> (<span class="literal">None</span>, <span class="literal">None</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>获取当前层使用的 Key 和 Value 压缩模块。<br>    根据 KV 压缩共享策略，该函数返回对应的压缩模块：<br>    - 如果设置了全局共享的压缩器（self.shared_kv_compression），则 Key 和 Value 都使用该共享模块；<br>    - 如果当前层包含独立的 ‘key_compression’ 和 ‘value_compression’，则分别返回；<br>    - 如果当前层只包含 ‘key_compression’，则认为 Key 和 Value 共用一个压缩模块；<br>    - 如果都没有设置，返回 (None, None)，表示不使用压缩。<br>Attributes：<br>layer (nn.ModuleDict): 当前 Transformer 层，可能包含 Key&#x2F;Value 压缩模块。<br>Returns：<br>Tuple[Optional[nn.Module], Optional[nn.Module]]:<br>一个元组，分别表示 Key 和 Value 的压缩模块。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_start_residual</span>(<span class="params">self, x, layer, norm_idx</span>):</span><br><span class="line">x_residual = x</span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.prenormalization:</span><br><span class="line">norm_key = <span class="string">f&#x27;norm<span class="subst">&#123;norm_idx&#125;</span>&#x27;</span></span><br><span class="line"><span class="keyword">if</span> norm_key <span class="keyword">in</span> layer:</span><br><span class="line">x_residual = layer[norm_key](x_residual)</span><br><span class="line"><span class="keyword">return</span> x_residual</span><br></pre></td></tr></table></figure><p>处理残差连接起始部分（如果使用前置归一化）<br>Attributes：<br>x (Tensor): 当前输入张量<br>layer (nn.ModuleDict): 当前 Transformer 层，可能包含 norm 层<br>norm_idx (int): 使用的归一化层索引（如 norm0, norm1）<br>Returns：<br>Tensor: 用于残差分支的输入（可能已归一化）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_end_residual</span>(<span class="params">self, x, x_residual, layer, norm_idx</span>):</span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.residual_dropout:</span><br><span class="line">x_residual = F.dropout(x_residual, <span class="variable language_">self</span>.residual_dropout, <span class="variable language_">self</span>.training)</span><br><span class="line">x = x + x_residual</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.prenormalization:</span><br><span class="line">x = layer[<span class="string">f&#x27;norm<span class="subst">&#123;norm_idx&#125;</span>&#x27;</span>](x)</span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>处理残差连接结束部分：加上残差、dropout、后归一化（如果不使用前置归一化）<br>参数：<br>x (Tensor): 当前主干输出<br>x_residual (Tensor): 残差分支输入（来自 _start_residual）<br>layer (nn.ModuleDict): 当前 Transformer 层<br>norm_idx (int): 使用的归一化层索引<br>返回：<br>Tensor: 应用残差和归一化后的输出张量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_num: Tensor, x_cat: ty.<span class="type">Optional</span>[Tensor], return_fr: <span class="built_in">bool</span> = <span class="literal">False</span></span>) -&gt; Tensor:</span><br><span class="line">fr_graphs = [] <span class="comment"># FR-Graph of each layer</span></span><br><span class="line">x = <span class="variable language_">self</span>.tokenizer(x_num, x_cat)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer_idx, layer <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.layers):</span><br><span class="line">is_last_layer = layer_idx + <span class="number">1</span> == <span class="built_in">len</span>(<span class="variable language_">self</span>.layers)</span><br><span class="line">layer = ty.cast(ty.<span class="type">Dict</span>[<span class="built_in">str</span>, nn.Module], layer)</span><br><span class="line"></span><br><span class="line">x_residual = <span class="variable language_">self</span>._start_residual(x, layer, <span class="number">0</span>)</span><br><span class="line">x_residual, fr_graph = layer[<span class="string">&#x27;attention&#x27;</span>](</span><br><span class="line"><span class="comment"># for the last attention, it is enough to process only [CLS]</span></span><br><span class="line">(x_residual[:, :<span class="number">1</span>] <span class="keyword">if</span> is_last_layer <span class="keyword">else</span> x_residual),</span><br><span class="line">x_residual,</span><br><span class="line">*<span class="variable language_">self</span>._get_kv_compressions(layer),</span><br><span class="line">)</span><br><span class="line">fr_graphs.append(fr_graph)</span><br><span class="line"><span class="keyword">if</span> is_last_layer:</span><br><span class="line">x = x[:, : x_residual.shape[<span class="number">1</span>]]</span><br><span class="line">x = <span class="variable language_">self</span>._end_residual(x, x_residual, layer, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">x_residual = <span class="variable language_">self</span>._start_residual(x, layer, <span class="number">1</span>)</span><br><span class="line">x_residual = layer[<span class="string">&#x27;linear0&#x27;</span>](x_residual)</span><br><span class="line">x_residual = <span class="variable language_">self</span>.activation(x_residual)</span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.ffn_dropout:</span><br><span class="line">x_residual = F.dropout(x_residual, <span class="variable language_">self</span>.ffn_dropout, <span class="variable language_">self</span>.training)</span><br><span class="line">x_residual = layer[<span class="string">&#x27;linear1&#x27;</span>](x_residual)</span><br><span class="line">x = <span class="variable language_">self</span>._end_residual(x, x_residual, layer, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> x.shape[<span class="number">1</span>] == <span class="number">1</span></span><br><span class="line">x = x[:, <span class="number">0</span>]</span><br><span class="line"><span class="keyword">if</span> <span class="variable language_">self</span>.last_normalization <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">x = <span class="variable language_">self</span>.last_normalization(x)</span><br><span class="line">x = <span class="variable language_">self</span>.last_activation(x)</span><br><span class="line">x = <span class="variable language_">self</span>.head(x)</span><br><span class="line">x = x.squeeze(-<span class="number">1</span>)</span><br><span class="line"><span class="keyword">return</span> x <span class="keyword">if</span> <span class="keyword">not</span> return_fr <span class="keyword">else</span> (x, fr_graphs)</span><br></pre></td></tr></table></figure><p>前向传播<br>Args:<br>x_num(Tensor): 数值特征的矩阵<br>x_cat(type.Option[Tensor]): 类别特征的矩阵<br>return_fr(bool &#x3D; False): 是否返回图结构<br>Attributes:<br>x: 特征，流程：<br>1. self.tokenizer(x_num, x_cat): 进行“分词“<br>2. self._start_residual(x, layer, 0): 计算norm0的残差(分为预归一化和后归一化)<br>3. layer[‘attention’]: 计算图拓扑结构并返回下一层的输入<br>4. (如果是最后一层)取出每个样本的第一行([CLS])进行最后的分类<br>5. self._end_residual: 同_start_resudual<br>6. self._start_residual(x, layer, 1): 计算norm1的残差<br>7. lay[‘linear0’]: 线性层<br>8. self.activation: 激活函数<br>9. dropout: 如果需要ffn_drop，进行dropout<br>10. lay[‘linear1’]: 线性层<br>11. end_residual: 同上<br>12. self.last_normalization: 最终的激活函数<br>13. self.head: 分类头<br>Notes:<br>这里用到了一个有趣的代码</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">layer = ty.cast(ty.<span class="type">Dict</span>[<span class="built_in">str</span>, nn.Module], layer)</span><br></pre></td></tr></table></figure><p>它可以让layer从nn.ModuleDict伪装成dict，避免类型检查时出错<br>Returns:<br>Tensor or Tuple[Tensor, SomeType]:<br>如果 <code>return_fr</code> 为 False，则返回张量 <code>x</code>，表示模型的输出；<br>如果 <code>return_fr</code> 为 True，则返回一个元组 <code>(x, fr_graphs)</code>，<br>其中 <code>fr_graphs</code> 是边权重图的数据结构（具体类型视实现而定）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">froze_topology</span>(<span class="params">self</span>):</span><br><span class="line"><span class="string">&quot;&quot;&quot;API to froze FR-Graph topology in training&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> <span class="variable language_">self</span>.layers:</span><br><span class="line">layer = ty.cast(ty.<span class="type">Dict</span>[<span class="built_in">str</span>, nn.Module], layer)</span><br><span class="line">layer[<span class="string">&#x27;attention&#x27;</span>].frozen = <span class="literal">True</span></span><br></pre></td></tr></table></figure><p>在训练过程中冻结 FR-Graph 拓扑结构。通过将每个层的 attention 模块的 <code>frozen</code> 属性设置为 True，禁止 FR-Graph 拓扑的更新，从而保持当前拓扑结构不变。<br>适用于需要固定图结构、不希望训练时修改拓扑的场景。<br>Args:<br>无<br>Returns:<br>None</p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 代码阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>T2GFormer</title>
      <link href="/2025/07/09/T2GFormer/"/>
      <url>/2025/07/09/T2GFormer/</url>
      
        <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>作者在这篇文章中提出了一种新的特征交互方式。这种方式基于一种新型的图估计器，这种估计器可以自动估计特征之间的关系并通过连接相关特征来构造图像。一种特别的 <strong>跨层读取(Cross-level Readout)</strong> 收集了通过T2Gformer预测的不同层的突出特征并获取全局信息并作出预测。T2Gformer优于深度神经网络并与非深GBDT能力相近。<br>T2Gformer的优势在于特征交互项的提取，所以作者在引入中便提及：已有的特征选择方法可以被分为“软”与”硬”版本。”软”版本本质上运用特征间的全连接交互项，例如乘法交互项、特征交叉与基于注意力的交互。但是表格特征本质上就带有异质性，所以全连接交互是一个次优的选项因为其盲目地将所有特征融合在一起。<em>DANets</em>使用了”硬”版本，其将相关的特征分组并将交互限制在被分组的特征内，虽然DANets取得了非常有潜力的成果，他的特征选取操作依旧不能解决组内交互的问题，因此同一组的特征被无差别的融合，使得模型表达能力下降。<br>作者设计了Graph Estimator(GE)来组织表格特征为一个特征关联图(FR-Graph)，更进一步的，作者通过堆叠GE融合块用于特征交互，并辅助以一个transformer架构的神经网络，这种新的架构被称为t2g-transformer。<br>GE通过以下几点构建特征交互图：</p><ol><li>一个静态的可以描述任务的潜在知识的图拓扑结构。</li><li>适应数据的边权重。<br>在作者提出的T2G-Former中，每层使用了FR-Graph来将输入特征转化为图特征，异质性特征交互是遵循图中边的指定结构来有序的进行。同时，一个特殊的跨层读取收集了每个分级的突出特征并获取全局表格语义以作出最终决策。<br>作者这项工作的主要贡献如下：<br> 首次使用了特征图来处理特征异质性的问题，并提出了一个GE模块来进行特征相关性组织<br> 在Transformer架构中使用了FR-Graph并构建了特定的T2G-Former模型进行表格数据的分类与回归。<br> T2G-Former的表现在许多数据库上优于SOTA tabular DNNs，并且可与GBDTs相抗衡。</li></ol><h1 id="Graph-Estimator"><a href="#Graph-Estimator" class="headerlink" title="Graph Estimator"></a>Graph Estimator</h1><p>GE将表格数据特征作为图节点、特征相关性作为边。其设计理念来自于<em>知识图谱补全knowledge graph completion</em>，也就是使用了两个实体的语义学相关性来估计关系的可信度。一个基础的式子被用于描述这样的语义学相关性:<br>$$f_{r}(h,t)&#x3D;h^TM_{r}t$$<br>其中$h,t\in \mathbb{R}^n$是头实体节点的编码和尾实体节点的编码，$M_{r} \in \mathbb{R}^{n\times n}$是一个可学习矩阵，用于在知识图谱(KG, Knowledge Graph)中表示关系r。许多相关方法均来自于该公式，唯一不同的就是关系编码和评分函数。<br>不同于KGC模型只计算静态的关系可信度，GE借助可适应的边权重，借助静态的潜在图拓扑结构来估计特征的关系。我将每个特征作为一个节点，首先使用语义学上的匹配来估计每对特征关系的软可信度(这被作者称为<strong>数据适应的边权重</strong>)；其次，一个<strong>静态知识拓扑结构</strong>基于数据列语义被学习并构建，其被用于保留重要特征对的交互项。最后，边权重与知识拓扑结构集成以形成FR-Graph.</p><h2 id="FR-Graph-Structure-Components"><a href="#FR-Graph-Structure-Components" class="headerlink" title="FR-Graph Structure Components"></a>FR-Graph Structure Components</h2><p>为了挖掘表格数据的特征关联，我们通过将表格特征作为图节点的候选项并预测节点间的边来构建FR-Graph。边是来自于两个角度：自适应的边权重表示了特定数据的信息；静态的边拓扑结构展示了潜在的信息。其中，有部分节点与FR-Graph相独立，这是因为没有节点与之相连。</p><h3 id="Adaptive-Edge-Weight"><a href="#Adaptive-Edge-Weight" class="headerlink" title="Adaptive Edge Weight"></a>Adaptive Edge Weight</h3><p>考虑两个表格数据特征嵌入向量$x_{i},x_{j}\in \mathbb{R}^n(i,j\in{1,2,\dots,N})$其中$N$为输入特征的数量，我们通过如下方式估计交互可信度：<br>$$G_{\omega}[i,j]&#x3D;g_{\omega}(f_{i}^h, f_{j}^t)&#x3D;{f_{i}^h}^T \mathrm{diag}(r)f_{j}^t$$</p><p>$$<br>f_i^h &#x3D; W^h x_i,\quad f_i^t &#x3D; W^t x_i,\quad<br>$$</p>$$\left \{\begin{array}{ll}W^h = W^t & \text{if symmetric} \\W^h \ne W^t & \text{if asymmetric}\end{array}\right.$$<p>其中，可学习的两个参数$W^h, W^t \in \mathbb{R}^{m\times n}$记为对于头特征和尾特征的转化，$\mathrm{diag}(r)\in \mathbb{R}^{m\times m}$(原文写的是$\mathbb{R}^{n\times n}$)是一个对角矩阵，该对角矩阵是由可学习的关系向量$r \in \mathbb{R}^n$参数化而来，其语义上表示了特征的关系。$W^h$与$W^t$如果是对称的(无向的)，则共享参数，在非对称的例子中则不相等。出于书写的方便，所有偏置项都被省去。最终，自适应权重评分$g_{\omega}$构成了一个全连接的加权图，这样的一张图将会在diag(r)为单位阵时退化成一个注意力评分，因此，它也能计算加权特征相似性。</p><h3 id="Static-Knowledge-Topology"><a href="#Static-Knowledge-Topology" class="headerlink" title="Static Knowledge Topology"></a>Static Knowledge Topology</h3><p>静态相关拓扑评分可以如下计算：</p>$$G_{t}[i,j]=g_{t}(e_{i}^h, e_{j}^t)=\frac{{e_{i}^h}^Te_{j}^t}{||e_{i}^h||_{2}||e_{j}^t||_{2}}$$<p>$$e_{i}^h&#x3D;E^h[:,i], e_{i}^t&#x3D;E^t[:,i],$$<br>其中$E\in{ E^h, E^t}$时一个可学习的列嵌入，其被分为头嵌入与尾嵌入。$E&#x3D;{ e_{1}, e_{2},\dots,e_{N}}\in \mathbb{R}^{d\times N}$，d是嵌入的维度。相似的，相关拓扑评分有对称与非对称两个版本，与加权特征相似性计算一样，对称时相同而非对称时不同。作者使用二范数来保证同量纲与训练稳定性(这不就是余弦相似度).<br>我们通过一下式子获得静态关联拓扑结构：<br>$$A&#x3D;f_{top}(G_{t})&#x3D;\mathbb{1}[\sigma_{1}(G_{t}+b)&gt;T]$$<br>其中$\sigma_{1}$是逐元素的激活函数，其具有一个可学习的参数b，$G_{t}$是一个邻接矩阵评分，由关联拓扑评分构成，T是一个常数阈值，$\mathbb{1}$记为指示函数，通过这种方法，我们获得了一种全局图拓扑结构来限制特征的交互，并且这样的拓扑结构可以被认为是整个任务上的静态知识。<br><em>这里原文讲得不是很清晰，后面对照代码来理解这一部分</em></p><h2 id="Relation-Graph-Assembling"><a href="#Relation-Graph-Assembling" class="headerlink" title="Relation Graph Assembling"></a>Relation Graph Assembling</h2><p>当我们从数据角度获得了软自适应边权重，从知识角度获得了硬静态关系拓扑图结构，我们将他们组合起来产生一个FR-Graph：<br>$$G&#x3D;\sigma_{2}(f_{nsi}(A)\odot G_{\omega})$$<br>其中$\sigma_{2}$是一个竞争激活函数(例如$L_{p}$正则化、softmax、sparsemax)来限制每个节点的入度，$\odot$是Hadamard积(就是逐元素相乘)。最终的关系图G是一个同时基于适应性特征匹配与静态知识拓扑结构的加权图。为了让FR-Graph主要关注学习有意义的交互项，一个“非自我交互函数”$f_{nsi}$被使用用于精确排除G中的圈(self-loop)。我们使用FR-Graph来指导接下来的特征交互。同时，因为边权重与拓扑结构均有2种版本(非对称与对称)，所以在实验中，我们也会讨论不同版本对于结果的影响。</p><h1 id="T2G-Former"><a href="#T2G-Former" class="headerlink" title="T2G-Former"></a>T2G-Former</h1><p>我们将GE结合到类注意力的模块，并且通过将多个块堆叠来构建T2G-Former。T2G-Former使用估计的FR-Graphs进行特征交互并获取高级特征，跨层读取按顺序被映射到每层的特征空间并选择性的收集特征性的特征以进行最终的预测。一条捷径被加入来从前一层中保留信息(残差)，最终形成一个在不同特征级别间的有门控融合。</p><h2 id="Basic-Block"><a href="#Basic-Block" class="headerlink" title="Basic Block"></a>Basic Block</h2><p>每个块都配有GE用于特征交互，输入特征$X^l\in \mathbb{R}^{n\times N}$，$l$代表第$l$-层，我们使用如下式子获取下一层输入$X^{l+1}$<br>$$G^l&#x3D;GE(X^l), V^l&#x3D;W_{v}X^l$$<br>$$H^l&#x3D;G^lV^l+g(X^l), X^{l+1}&#x3D;FFN(H^l)+g(H^l)$$<br>$W_{v}\in \mathbb{R}^{m\times n}$是一个可学习的参数，用于特征映射，$V^l$时映射后的特征输入，FFN为前馈神经网络。环已在$G^l$中排除，g为捷径，在实验中就是一个dropout层。值得注意的是，我们产生并使用FR-Graph用于特征交互，但是它并不影响那些通过残差连接进行的特征内部更新。在第一层中，我们将输入的表格数据通过一个简单的tokenizer编码为$X_{0}$，以下我给出一个简单的tokenizer帮助理解在表格数据中，如何进行”分词”</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FeatureTokenizer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, cat_dims, num_dim, embed_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.cat_embeds = nn.ModuleList([</span><br><span class="line">            nn.Embedding(num_cat, embed_dim) <span class="keyword">for</span> num_cat <span class="keyword">in</span> cat_dims</span><br><span class="line">        ])</span><br><span class="line">        <span class="variable language_">self</span>.num_proj = nn.Linear(num_dim, embed_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_cat, x_num</span>):</span><br><span class="line">        cat_vecs = [emb(x_cat[:, i]) <span class="keyword">for</span> i, emb <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.cat_embeds)]</span><br><span class="line">        num_vecs = <span class="variable language_">self</span>.num_proj(x_num)</span><br><span class="line">        <span class="keyword">return</span> torch.stack(cat_vecs + [num_vecs], dim=<span class="number">1</span>)  <span class="comment"># Shape: [B, #features, d]</span></span><br></pre></td></tr></table></figure><p>通过这种方式，高级别的特征可以通过FR-Graph迭代的产生并选择性地交互。在使用过程中，层归一化的作用是保证稳定的训练。</p><h2 id="Cross-level-Readout"><a href="#Cross-level-Readout" class="headerlink" title="Cross-level Readout"></a>Cross-level Readout</h2><p>我们设计了一个全局读取节点来选择性的收集每层中重要的特征并获取全面的语义学信息以进行最终的预测。特别的一点是，我们使用注意力机制融合当前层选择的特征，同时将他们与前一层的特征的捷径结合，当前读出层的状态为$z^l\in \mathbb{R}^n$收集过程可以被描述为：<br>$$\alpha_{i}^l&#x3D;g_{\omega}(h^l,f_{i}^t) \cdot f_{top}(g_{t}(e^l,e_{i}^t)),h^l&#x3D;W^hz^l $$<br>$$r^l&#x3D;\mathrm{softmax}(\alpha^l)^TV^l+z^l$$<br>$$z^{l+1}&#x3D;\mathrm{FFN}(r^l)+r^l$$<br>$\alpha_{i}^l$记为第i个特征的权重，$\alpha^l\in \mathbb{R}^N$是由$\alpha_{i}^l$构成，$e^l\in \mathbb{R}^d$是一个可学习的向量，其表示读出层的节点在第l层的语义学信息，$f_{i}^t$是每层编码的特征，$e_{i}^t$是一个逐层的列嵌入，$V^l$是映射后的输入特征(似乎这里公式书写有些问题，后续看代码修正)，这里，我们将$z^l$输入到相同的FFN中将当前的读出映射到第l+1层的特征空间。捷径直接被加入，没有任何信息丢失，收集过程从输入特征到最高级的特征一直被重复，这样的操作可以鼓励跨层的特征交互。</p><h2 id="The-Overall-Architecture-and-Training"><a href="#The-Overall-Architecture-and-Training" class="headerlink" title="The Overall Architecture and Training"></a>The Overall Architecture and Training</h2><p>我们在每个块中默认使用8头GE，预测基于最后一层处理完成后的读出层状态<br>$$\hat{y}&#x3D;\mathrm{FC}(\mathrm{\mathrm{Re}LU(LN)}(z^L))$$<br>其中LN和FC分别表示层归一化和一个全连接层。使用交叉熵和均方误差作为损失函数，在过去的DNN中，我们测试了多种任务并观测到持续最优化静态图拓扑结构会造成模型的不稳定，所以，在其收敛后，我们将其固定以进行进一步的训练。<br>我们引入了额外的超参数$d$与$T$，在实验中，我们适应性地设定$d&#x3D;2\lceil \log_{2}N \rceil$，这是可以表示$N^2$<br>个二元元素的最小邻接矩阵的信息量，并保持$T&#x3D;0.5$在所有数据集中相同，$\sigma_{1}$是sigmoid，$\sigma_{2}$是softmax，对于示性函数，我们使用straight-through trick来计算梯度</p><hr><p>Cover image icon by <a href="https://www.flaticon.com/authors/becris" title="Becris">Becris</a> from <a href="https://www.flaticon.com/free-icons/deep-learning" title="deep learning icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文阅读 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>表格数据学习方法综述阅读(上)</title>
      <link href="/2025/05/28/Tabular-Review-1/"/>
      <url>/2025/05/28/Tabular-Review-1/</url>
      
        <content type="html"><![CDATA[<p>表格数据(tabular data)是日常生活中最常见的数据格式，为了挖掘表格数据中的有效信息，提出了很多相关的算法。这篇综述概括了表格数据的机器学习与深度学习方法，原文来自于南京大学LAMDA实验室中的<a href="https://github.com/LAMDA-Tabular">LAMDA-tabular课题组</a>，<a href="https://arxiv.org/abs/2504.16109">文章地址</a>。</p><h1 id="1-3"><a href="#1-3" class="headerlink" title="1-3"></a>1-3</h1><p>对于tabular data的一些简单介绍，略过</p><h1 id="4-特定方法的分类"><a href="#4-特定方法的分类" class="headerlink" title="4 特定方法的分类"></a>4 特定方法的分类</h1><p>作者将模型分为三类：特化方法(specialized methods), 迁移方法(transferable methods), 广义方法(general methods)。</p><h2 id="Specialized-method"><a href="#Specialized-method" class="headerlink" title="Specialized method"></a>Specialized method</h2><p>作者从3个角度入手讲述特化模型的方法：<br>Feature Aspect：特征角度来看，模型主要针对数据特征的关系进行建模。<br>Sample Aspect：从样本特征来看，模型通过最大化每个样本最邻近样本的作用来预测。<br>Objective Aspect：从客观角度，修改损失函数和整体目标(Overall objective)来引导模型特定的模式与偏好，注入inductive  bias(推断偏倚)。</p><h3 id="Feature-Aspect"><a href="#Feature-Aspect" class="headerlink" title="Feature Aspect"></a>Feature Aspect</h3><p>特征角度来看，模型主要针对数据特征的关系进行建模。<br>传统特征工程主要依赖于人手工设计特征，随着深度学习的进展，诸多特征相关的模型出现，例如特诊编码、选择、投影和交互。</p><h4 id="Feature-Encoding"><a href="#Feature-Encoding" class="headerlink" title="Feature Encoding"></a>Feature Encoding</h4><p>注意力机制让我们可以像自然语言处理中的词嵌入一样对于特征进行tokenization，将所有特征转变为嵌入。<br><strong>Categorical Encoding</strong><br>最主要使用的两种策略是序列编码(Ordinal Encoding)和独热编码(One-hot Encoding)。更加先进的编码方式还有Target Encoding，通过将该类的结局变量(target)的均值赋为该类的编码。该方法主要用于该变量与结局有很强的相关性。在留一法(Leave-one-out embedding)中，每个类都被赋予除了该变量的其他的结局均值。<br><strong>Numerical Encoding</strong><br><em>MLP-PLR</em>引入了2种数值编码方式：Piecewise Linear Encoding(PLE：分段线性编码) 和 Periodic Activation Function(周期性激活函数)。这两种方法可以与其他分类方法结合来提高表现。PLE基于特征分箱，为原始标量值生成了替代的初始表示。周期性激活函数考虑到：嵌入框架都是将所有特征独立处理，这让结合变量在嵌入过程中变得不可能。因此，周期激活函数会训练激活前的系数，而不仅仅是固定不变。<br><strong>Feature Tokenization</strong><br>它将特征转为embedding，因为特征表示是非常稀疏的，常用的方法就是将其转化为低维度表示(这里主要是将图片转为图特征向量)。<br>广义的特征tokenization可以被表示如下：<br>$$T_{i,j}&#x3D;b_{j}+\tau(x_{i,j};\Psi)\in \mathbb{R}^t$$<br>其中,$\tau(\cdot)$是特征分词器模块，将输入$x_{i} \in \mathbb{R}^d$转为嵌入$T_{i,j} \in \mathbb{R}^t$，$b_{j}$是第j个特征的偏倚，$\Psi$是可学习参数。<br><em>AutoInt</em>将分类变量和数值变量同时编码为低维度的变量。<em>TabTransformer</em>将每个分类变量手机用Column Embedding嵌入一个t维度的参数嵌入中。<em>SAINT</em>在传入 transformer编码器前，先将数值变量映射到一个t维的空间内。<em>FT-Transformer</em>使用了transformer架构。其中，数值变量使用了逐元素加法$T_{i}^{num}&#x3D;b_{i}^{num} + x_{i}^{num}W_{i}^{num}$；分类变量则使用了查表法$T_{i}^{cat} &#x3D; b_{i}^{cat} + e_{i}^TW_{i}^{cat}$，其中$e_{i}^T$是对应类的独热向量。</p><h4 id="Feature-Selection"><a href="#Feature-Selection" class="headerlink" title="Feature Selection"></a>Feature Selection</h4><p>高维度的数据常常会带来过拟合，模型过度关注无关的特征从而忽视了更加重要的特征，特征选择留下了最重要的特征避免过拟合。<br>传统树学习使用自动的特征选择来评估每个特征与结局之间的关联。决策树使用了基尼系数或者信息增益；随机森林使用了计算每个特征贡献度的方法；最近现代学习方法经常模拟树结构的方法来进行特征选取。<br><em>GrowNet</em>和<em>NODE</em>主要模仿了集成学习的方法，受GBDT启发，GrowNet设计了使用多个DNN构建多个弱学习器，每个学习器输入初始变量和前一层的输出；NODE使用可导遗忘决策树(Differentiable Oblivious Decision Tree)作为基学习器，在每层使用bagging和每个多层结构间使用stacking；为了让GAM(广义加性模型)可量化且高效，NODE-GAM将NODE改为GAM并允许GAM学习快速、非线性的跳跃以适应真实数据。<br><em>TabNET</em>和<em>GRANDE</em>更加关注树模型如何处理特征。TabNET不仅仅通过自监督学习保留了深度神经网络的表征学习能力，同时还融合了树模型的可解释性和稀疏特征选取能力；GRANDE认为树模型中的硬分裂(hard splits：某个特征的值满足条件就完全走一条路径)是深度模型的关键优势，并由此提出了一种利用梯度下降来学习硬、轴对称(axis-aligned：仅基于一个特征分裂，对立的是oblique split，需要结合多个特征进行分裂)的树集成模型，将轴对称分裂带来的有效归纳偏差与梯度下降优化带来的灵活性结合。</p><h4 id="Feature-Projection"><a href="#Feature-Projection" class="headerlink" title="Feature Projection"></a>Feature Projection</h4><p>特征映射旨在将特征转为中间形式，加强表达能力。特征映射可被分为两类：MLP变体和专门设计的架构。这些方法旨在加强模型对于复杂特征的表达能力：<br><strong>MLP Variant</strong>：<em>RTDL</em>研究了类似Resnet和基于transformer架构的模型，提出了简单但是有效的调整，尤其是MLP架构，其使用了多个包含线性层、ReLU激活函数和Dropout的块的堆叠，这将原始特征转为了固定维度的潜在表征，最终一个线性层作为分类头。这篇文章强调：如果有合理的超参数，简单的MLP和ResNet也能达到benchmarks。<br>另外一个同期的研究通过给MLP装备了一组正则化现代套件。通过多种正则方法的堆叠，形成了一种正则化鸡尾酒的方法。这个研究揭示了两种重要发现：1) 原版MLP(vanilla MLP: 有趣的是vanilla有”香草”的意思)通过正则化可以超过许多为面板数据设计的特化的、现代的神经网络架构；2) 这样的MLP甚至可以超过XGBoost。<em>RealMLP</em>探索了包括预处理、超参数调参、架构、正则化和初始化的多个角度。<br><strong>Special Designed Architectures</strong>：对于单元，受到归一化方法容易导致干扰，<em>SNN</em>提出了SELU(Scaled Exponential Linear Unit)；<em>NAMs</em>使用ExU(exp-centered hidden units)来提升对于跳跃函数(jumpy function)的学习能力；<em>BiSHop</em>使用双组分方法(dual-component approach：指的是一种将<strong>两个主要部分、机制或因素</strong>结合起来解决问题、建模、分析的策略。它体现的是“<strong>两个互补或协同的部分</strong>共同作用”。)使用两个有方向性、彼此连接的学习模块按顺序评估数据的行和列，他使用了现代Hopfield层</p><h4 id="Feature-Interaction"><a href="#Feature-Interaction" class="headerlink" title="Feature Interaction"></a>Feature Interaction</h4><p>广义形式可以表示为:<br>$$\hat{y_{i}} &#x3D; f(\mathcal{H}(x_{i}; \Theta))$$<br>其中$x_{i} \in \mathbb{R}^d$是输入向量，$\mathcal{H}(\cdot)$为特征交互模块，提取输入的特征依赖性并产生高维度的特征交互项；$f(\cdot)$是预测头。<br>特征交互可以被广泛的分为两类：自动交互模块的设计和潜在交互的挖掘。这些方法旨在加强模型学习复杂交互项和潜在特征结构的能力。<br><strong>Automatic Feature Interaction Modules</strong>：这些方法并不假设特定的特征类型，相仿，其关注提高模型中特征交互过程，让模型可以学到复杂且高维度的特征相关性。<em>DCNv2</em>通过Cross Network架构，它使用低秩方法(low-rank methods: 将高维度的参数矩阵$W \in \mathbb{R}^{d\times d}$化为两个低维度的矩阵$U,V \in \mathbb{R}^{d\times r}, W &#x3D; UV^\mathbf{T}$，以避免过拟合，非常有趣的方法，如果看过transformer的架构就会发现: <em>transformer在embedding的过程中input embedding和output embedding共用矩阵，这其实也是一种降低过拟合的方法</em>)在子空间中近似特征交叉(feature crosses:指的是将多个原始特征组合起来，比如将“性别 + 年龄”合成一个组合特征)，然后通过门控机制将这些子空间融合.<em>AutoInt</em>将原始稀疏的高维度特征向量(例如one-hot之后的类别)转为低维度空间并通过注意力机制将交互层堆叠(就是对于每个样本进行注意力操作)；不像AutoInt，<em>TabTransformer</em>只将类别变量嵌入内容嵌入，数值特征直接与交互后的上下文嵌入向量进行拼接。当只有数值变量时，其表现得像MLP，只有分类变量时，其表现得像AutoInt.<br><em>DANets</em>提出了表格数据中潜在特征组的存在，在每个特征组内的特征是相互之间相关的。它学习将特征分组并进行进一步的特征抽象；<em>SwitchTab</em>提出了一种思想：在表格特征中提取样本特异性的显著特征和样本共享的互信息(Mutual Information)；<em>ExcelFormer</em>认为DNN为每个特征赋予了一个权重，这会让模型纳入无关变量，为了解决这个问题，它引入了用于特征交互的“半透性注意力”(Semi-Permeable Attention)，这样可以让有较少信息的特征从有更多信息的模型中获取信息，同时避免高信息特征受到低信息特征的干扰。<em>AMFormer</em>提出了一种假说：算数特征交互项对于深度表格模型是重要的，基于Transformer架构，它提出了为了提取加性和乘性交互项的组件。</p><h3 id="Sample-Aspect"><a href="#Sample-Aspect" class="headerlink" title="Sample Aspect"></a>Sample Aspect</h3><p>从样本特征来看，模型通过最大化每个样本最邻近样本的作用来预测。<br>广义的模型公式可以表示如下：<br>$$<br>\hat{y_{i}}&#x3D;f(\mathcal{R}(x_{i}, \mathcal{D}; \Phi))<br>$$<br>其中，$\mathcal{D}$为所有样本的集合，$\mathcal{R}(\cdot)$是样本交互模块。$\Phi$是$\mathcal{R}$的可学习参数。$f(\cdot)$是预测头，用于将特征转为最终的输出。<br>样本角度可以被简单分为两个主要策略，第一个策略通过representation training(表征学习)学习样本特征之间的关系；第二个策略使用“基于检索的模型”(Retrieval-based model)通过如何检索并使用临近样本的作用。<br><strong>Sample Interaction</strong>：这个方法通过在表征学习过程中，使用样本间的相关性来训练得到一个更加鲁棒的表征。在训练过程中，因为没有交互，所有模型会变得更加敏感。<br><em>SAINT</em>引入样本间的attention而不仅仅是属性间的attention，提高了行分类的准确率；<em>NPT</em>将其扩展为非参数Transformer，而Hopular使用了Hopfield网络，这与SAINT其实是本质上相同的。Trompt认为特征的重要性在不同样本中是不同的，在特征提取过程中，它将样本之间的信息作为prompts。<em>PTaRL</em>识别了在表格数据中的两种情况：纠缠与局部化，并使用原型生成(prototype generation)和表示投影(representation project)来产生更加清晰且一致的决策。<br><strong>Neighbor Retrieval</strong>：这种方法构造了高质量的内容来帮助提取有价值的邻居，并找到高效的方法来利用他们之间的关系。训练样本被用于协助测试。<em>DNNR</em>向KNN中引入本地梯度估计和Taylor多项式逼近；<em>TabR</em>将所有候选样本编码并使用类注意力机制来检索样本。<em>ModernNCA</em>使用了传统NCA方法并引入了深度学习策略与架构。<br><em><strong>有趣的是，作者在这里留下了一段话：目前的基于近邻的方法类似于in-context learning(上下文学习)，尤其是最近的TabPFN；LoCalPFN也使用了本地回归来获取更有解释性的决策边界，这也正是使用了本地信息。</strong></em></p><h3 id="Objective-Aspect"><a href="#Objective-Aspect" class="headerlink" title="Objective Aspect"></a>Objective Aspect</h3><p>从客观角度，修改损失函数和整体目标(Overall objective)来引导模型特定的模式与偏好，注入inductive  bias(推断偏倚)。<br>就像L1-正则化(LASSO)、L2-正则化(Ridge)，Objective-aspect methods在深度学习中是这些传统方法的拓展，通过修改损失函数和正则化因子获取推断偏倚。这里Objective Aspect又可以分为两类，一类是Training Objective可以用特化能力来增强模型，另一类则引入正则化因子，增强模型的泛化能力。<br><strong>Training Objective</strong>：<em>PTaRL</em>构建了原型生成的投影空间并学习了全局原型的解耦表征。使用了一个多样性约束（diversification constraint），用于校准表示（representation calibration）并引入了一个矩阵正交化约束（matrix orthogonalization constraint），以保证不同原型之间的独立性（independence）。<br><strong>Training Regularization</strong>：<em>RLNs</em>通过在训练过程中引入了高效调参方案克服了难以驾驭的超参数，这种方法最小化一种特别的反事实损失。RLNs中，正则化因子与模型参数同时被优化并最终得到一个稀疏的网络。<em>TANGOS</em>使用了基于正则化的提升方法，它通过正则化神经元属性来保证神经元特化且正交。<em>Regularization cocktails for MLPs</em>通过特定数据集合的13种正则化方法，能让简单的神经网络效果大大提升，甚至超过树学习模型(XGboost)</p><h1 id="5-从特化模型到迁移模型-From-specialized-to-transferable-model"><a href="#5-从特化模型到迁移模型-From-specialized-to-transferable-model" class="headerlink" title="5 从特化模型到迁移模型(From specialized to transferable model)"></a>5 从特化模型到迁移模型(From specialized to transferable model)</h1><p>从头训练一个模型会非常困难，取而代之的是训练一个预训练的模型(PTM: Pre-Training Model)。<br>使用预训练模型主要分为两个阶段：1. 表格模型的预训练；2.根据下游任务使用特定的适应策略来训练模型。正式的说，一个well-trained模型$g_{\Theta}$可以被用于加速$\mathcal{D}$上的模型$f_{\theta}$。为了使用$g_{\Theta}$中的专业信息，一种适应策略被使用：$f_{\theta}&#x3D;\mathbf{Adapt}(f_{\theta_{0}} | \mathcal{D}, g_{\Theta})$其中$\theta_{0}$是模型的初始化。这种标注可以被拓展到PTM之外。使用PTM的挑战在于将PTM与表格模型相关联。基于PTM的来源，我们将PTM分为3种类型：<br><strong>Homogeneous Transferable Tabular Model</strong>：同质性迁移模型，PTM可能与表格模型共享相同的任务，但是却有不同的分布，即$Pr(\mathcal{D}’) \neq Pr(\mathcal{D}) \space or \space g \neq f$<br><strong>Heterogeneous Transferable Tabular Model</strong>：异质性迁移模型，任务不同。<br><strong>Cross-Modal Transferable Tabular Model</strong>：跨模态迁移模型，PTM可以是另外一种模态，比如视觉或者语言模型，比如属性的语义学信息，就是将大语言模型作为PTM用以提供潜在的语义学信息。<br><strong>迁移模型的好处与坏处</strong>：好处：加速收敛、减少数据量、减少可学习参数量，减少计算量和调参量。</p><h2 id="Homogeneous-Transferable-Tabular-Model"><a href="#Homogeneous-Transferable-Tabular-Model" class="headerlink" title="Homogeneous Transferable Tabular Model"></a>Homogeneous Transferable Tabular Model</h2><p>这方面研究在深度学习时代之前便已出现，一个代表性的方法就是有偏正则化(biased regularization：在深度学习和机器学习中引入先验偏好或结构性偏差的正则化技术，其核心目的是引导模型朝特定方向学习，而不仅仅是防止过拟合)，通过最小化PTM和目标模型的差别：<br>$$\min_{W}\mathscr{l}(W)+|W-W’|<em>{F}^2&#x3D;\min</em>{\Delta W}\mathscr{l}(\Delta W+W’)+|\Delta W|_{F}^2$$<br>对于相似的模型，可以通过修改训练目标为权重残差。对于MLP，可以通过比较两者的预测结果。<br><strong>Supervised Pre-training Objectives</strong>：一种将目标变量融入预训练的方法是使用输入干扰(例如对于某变量遮蔽后训练)作为一种对于标准监督学习目标的增强方法。<br><strong>Self-Supervised Pretraining Objectives</strong>：自监督预训练目标包括：masked language model, contrastive pre-training, hybrid method. <strong>masked language model(MLM)</strong>，无监督训练目标，每个样本中随机的特征会被遮蔽，遮蔽的值会通过多目标分类方法来预测。<em>VIME</em>使用干扰的表格数据预测哪部分向量被遮掩并试图为自监督学习重新构建特征向量。他们通过使用已经训练的编码器为每个样本产生多个增广的样本，具体方法就是1.对于每个样本使用多种遮蔽方法，2.然后使用模型对遮蔽的特征进行填充以恢复该值以实现数据的增强和表示学习。<em>SubTab</em>发现通过特征子集重构数据效果会比使用具有干扰的数据更好地捕捉潜在表示。<em>SEFS</em>通过随机选取输入特征重构初始的输入并同时估计用以定义哪个特征被选中的阈值向量(gate vector)。<em>MET</em>使用所有特征表征的连接代替平均，并使用对抗重建损失(Adversarial reconstruction loss：一种类似于GAN的损失函数，由重建损失和对抗损失组成，前者就是常见的损失，后者则是判别器判断重建数据是否真实的损失)；<strong>Contrastive Pre-training</strong>，对比预训练使用数据增广来生成正样本对或者同一个样本的两个不同的增广视图，损失函数鼓励一个特征提取器将正样本对映射为相似的特征。对比学习的主要因素就是产生特定案例的正例样本和负例样本。<em>SCARF</em>会为每一个输入样本生成一个增强版本，他的方式是从样本所有特征中随机选出一部分特征，并将这些选中的特征值替换为该特征的边缘分布中随机抽取的值；<em>STab</em>依赖于多个权重共享的神经网络，通过利用停止梯度操作，可以通过更加复杂的正则化策略来学习特征中的不变性，避免了崩溃到平凡解(即所有样本的表示均相同)；<em>DoRA</em>通过样本间的前置任务(pretext task)和样本间的对比学习来学习上下文化表示(Contextualized representations)；<em>DACL+</em> 为了克服对于特定领域的依赖，使用Mixup噪声来产生相似和不相似的样本。<strong>Hybrid Methods</strong>：结合了多种方法，包括有监督的、无监督的。<em>LFR</em>通过同时重构多个随机生成映射函数来训练；<em>ReConTab</em>同时使用自监督学习和半监督学习，它使用了正则化方法来筛选变量，同时使用有标签的对比学习来蒸馏最相关的信息用以下游任务。</p><h2 id="Heterogeneous-Transferable-Tabular-Model"><a href="#Heterogeneous-Transferable-Tabular-Model" class="headerlink" title="Heterogeneous Transferable Tabular Model"></a>Heterogeneous Transferable Tabular Model</h2><p>早期的异质性模型主要关注特征级别的异质性，一个主要的假设是：存在一部分特征是相同，另外一部分特征不同，我们可以利用那部分相同特征的权重。主要工作有<em>OPID</em>，<em>ReForm</em>。神经模型的有点就是我们可以很轻松的调参(fine-tuned)，我们可以冻结大部分的参数，只关注少部分的参数(例如分类头)来加速调参并减少过拟合。<br><strong>Reuse PTM Pre-trained from One Dataset</strong>：这种方法主要关注预训练模型和目标任务的数据集之间的不同。<br><strong>Reuse PTM Pre-trained from Multiple Datasets</strong>：<em>XTab</em>通过利用独立特征（independent features）和联邦学习（federated learning）来预训练共享组件（shared component）。</p><h2 id="Reusing-a-Pre-trained-Language-Model"><a href="#Reusing-a-Pre-trained-Language-Model" class="headerlink" title="Reusing a Pre-trained Language Model"></a>Reusing a Pre-trained Language Model</h2><p>标准情况下，有两种类型的语义学信息可以被使用：第一，每个特征的属性名称，$\mathcal{A}&#x3D; A_{1}, \dots, A_{d}$；第二，meta-information例如文本描述，被记录为”meta_descript”可以进一步增加理解，学习过程可以被公式化为:<br>$$\hat{y_{i}}&#x3D;f(x_{i}, \mathcal{A}|\mathcal{D},\mathbf{meta_{descript}})$$<br>这里语义学信息作为连接特征空间的桥梁和促进从预训练模型向下游任务知识迁移的工具。<br><strong>Language Models for Feature Tokenization</strong>：当特征空间改变时，语言学方法假设语义学关联性在特征描述之间存在且依赖于大语言模型捕捉这些关联的能力。例如，特征“occupation”和特征”organization”之间存在语义学关联，这使得这个特征可以被反复使用。<br><em>TransTab</em>根据表格数据中存在的词语训练一个分词器，并将列描述和表格作为输入，输入到一个门控transformer模型，这个模型时通过自监督学习或者有监督对比学习来训练的，并在迁移任务与特征连续学习的任务中验证；<em>PTab</em>使用一种相似的方式，使用多个被分词后的表格数据学习上下文表示；<em>UniTabE</em>编码并融合来自于列名称、数据类型和单元格值的信息并转化为一系列的tokens，使用Transformer与LSTM的编码器-解码器的架构。它使用了多单元格遮盖与对比学习进行预训练，在这里一个样本的子向量被当作正样本，其他样本或者其他样本的子集被作为负样本。<em>CM2</em>使用了一种提出了一个跨表格的预训练框架，能够整合属性名称与特征值。它使用了pMTM(prompt-based Masked Table Modeling)自监督目标，列名被作为prompt来帮助预测遮掩的特征；<em>TP-BERTa</em>按照类似的方法，但是加上了数值离散化策略、数量级标记化和微调更小的预训练语言模型(RoBERTa)；<em>CARTE</em>使用图注意力机制，关注列名和近邻输入，使用对比学习并构建了graphlet(图中所有不同构的子图)。<br><strong>Language Models for Features Engineering</strong>：<em>Binder</em>识别模型无法直接回答的问题并使用LLMs产生辅助特征；<em>CAAFE</em>探索使用LLMs，基于任务语义和特征语义进行生成，并用 TabPFN 来评估这些特征的质量；<em>FeatLLM</em>使用基于样本的prompting来加强特征生成，让LLMs有能力产生新的特征；<em>TaPTaP</em>为了捕捉广义表格数据中的数据分布，在大规模语义库中进行训练。训练完成后，可用于生成高质量的合成表格数据。<br><strong>Language Models for Textual Serialization</strong>：使用预训练语言模型的直接方法包括将表格数据转化为文本数据，让LLMs可以直接推断特征与标签之间的关系。<em>LIFT</em>、<em>TabLLM</em>、<em>UniPredict</em>。但是文本序列化方法依旧存在许多挑战，比如特征数过多时可能造成prompt过长、受限于语义学信息的可用性和外部模型能力。</p><h2 id="Reusing-a-Pre-trained-Vision-Model"><a href="#Reusing-a-Pre-trained-Vision-Model" class="headerlink" title="Reusing a Pre-trained Vision Model"></a>Reusing a Pre-trained Vision Model</h2><p>最主要的挑战在于：将表格数据转化为图像。在自然图片中，临近的像素经常有相同的语义学相关性，但是表格数据缺少这种空间结构。同时，表格数据的特征是插入不变性，意味着交换顺序不会影响样本的意义(有些类似于图神经网络)。<br><strong>Dimensionality Reduction Transformation</strong>：<em>DeepInsight</em>使用t-SNE将表格数据转入2D空间并通过凸包分析、旋转等方法构建图片；<em>REFINED</em>使用贝叶斯度量多维度放缩来保证样本在低维度表征中的距离以维持结构相似的模型依旧保有最近的关系。<br><strong>Table Reorganization Transformation</strong>：表格数据库可以被当作一个矩阵。<em>TAC</em>使用CNN；<em>ICTD</em>和<em>TablEye</em>有相同的思路，产生一个图像，其中像素点暗度对于特征值。<br><strong>Image Marker Transformation</strong>：将特征值编码为可视的标记。例如<em>Super-TML</em>、<em>Tab2Visual</em>。<br>通过将表格数据转为图像，这些方法可以让强大的图像处理模型用于表格数据。<br>最近时间有些紧张，因为已经进入考试月了(悲),所以先写一半，剩余部分有空再写吧(希望有时间)。</p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GNN</title>
      <link href="/2025/05/10/GNN/"/>
      <url>/2025/05/10/GNN/</url>
      
        <content type="html"><![CDATA[<p>图是我们身边非常常见的结构，最近的一些研究让我们能够使用图结构的优势，在许多领域，如抗生素的研究、物理仿真、虚假新闻的识别，交通预测和推荐系统都有了最新的研究与实践。<br>这篇学习&#x2F;总结博客参考了biliili上<a href="https://www.bilibili.com/video/BV1iT4y1d7zP">李沐</a>的带读以及<a href="https://distill.pub/2021/gnn-intro/">A Gentle Introduction to GNN</a><br>这篇文章探索并解释了现代图神经网络，我们将工作分为4个部分：1. 什么类型的数据可以以图的形式记录；2. 图结构的特点与优势：相较于CNN或者传统深层神经网络；3. 建造一个GNN模型：从一个骨架到SOTA；4. 提供一个GNN playground供读者探究(会超链接回原文章)。</p><h1 id="What-a-Graph-is"><a href="#What-a-Graph-is" class="headerlink" title="What a Graph is"></a>What a Graph is</h1><h2 id="图是一系列实体之间的关系"><a href="#图是一系列实体之间的关系" class="headerlink" title="图是一系列实体之间的关系"></a>图是一系列实体之间的关系</h2><p>如果我们用图论的知识来看，图的描述其实有多种方式，如：邻接矩阵、集合的表示。我们这里采用相对容易接受的集合表示方法：<br>一个图主要由 <strong>节点(Nodes)</strong> 和 <strong>边(Edges)</strong> 构成。以下图为例：其中存在5个节点，与6条边。<br><img src="/2025/05/10/GNN/graph_demo.png" alt="graph_demo" title="graph_demo"><br>其中点集合为$V &#x3D; { A,B,C,D,E }$。边集合为$E &#x3D; { AB, BC,CD,DE,AE, CE }$上图边为无向的，所以也被称为无向图(有向图); 又因为没有重复边，所以被称为简单图；上图可以通过集合套集合的方法表示，即$G&#x3D; { V,E }$<br>由于篇幅问题，我们仅仅引入简单的概念，图论是一个非常庞大的研究方向，如果对图论与图相关算法感兴趣，可以查看<a href="https://oi-wiki.org/graph/">图论相关博客</a></p><h2 id="GNN中的图"><a href="#GNN中的图" class="headerlink" title="GNN中的图"></a>GNN中的图</h2><p>有趣的是，在GNN中，每个节点与边并不是我们想象的用单个数字代表其权重，而是通常由一个向量表示，我们称其为embedding(嵌入)<br>此外，在V,E之外，还有一个全局嵌入(U)，其表示的是图中的边数与点数。</p><h2 id="可以转化为图的数据"><a href="#可以转化为图的数据" class="headerlink" title="可以转化为图的数据"></a>可以转化为图的数据</h2><ol><li>化学分子</li><li>图像(像素为节点)</li><li>文本(词语为节点)</li><li>社交网络</li></ol><h2 id="图解决的问题"><a href="#图解决的问题" class="headerlink" title="图解决的问题"></a>图解决的问题</h2><h3 id="图层面"><a href="#图层面" class="headerlink" title="图层面"></a>图层面</h3><p>寻找图中的环</p><h3 id="点层面"><a href="#点层面" class="headerlink" title="点层面"></a>点层面</h3><p>将一个图分为两张图</p><h3 id="边层面"><a href="#边层面" class="headerlink" title="边层面"></a>边层面</h3><p>学习社交网络中的关系(关系抽取)</p><h1 id="GNN"><a href="#GNN" class="headerlink" title="GNN"></a>GNN</h1><p>GNN是对图上所有的属性(边、点、全局属性)进行可优化的变换，这个变换依旧保持图的对称性。”graph-in, graph-out”输入是图，输出是图，修改图的属性但是不影响图片的联通性(不影响结构)</p><h2 id="最简单的GNN"><a href="#最简单的GNN" class="headerlink" title="最简单的GNN"></a>最简单的GNN</h2><p>对于点、边、全局向量输入MLP得出新的点、边、全局变量<br><em>例如：判断图中顶点属于1还是属于2，就是对于顶点中每个点的向量输入MLP并输出一个softmax的结果：1 or 2</em><br>如果点、边向量不存在，则需要通过pooling(池化？)来根据该点的附近点、边向量获得该点的向量。</p><h2 id="信息传递"><a href="#信息传递" class="headerlink" title="信息传递"></a>信息传递</h2><p>但是，我们很容易就会发现，这样的GNN对于图信息的利用效率其实是很低的：我们没有用到图中点与点之间的关系，而是简单的用3个独立MLP进行了向量的更新。<br>所以我们提出了<strong>信息传递</strong>的思路</p><ol><li>最简单的信息传递就是汇聚，将一个点的向量和与其相连的所有点的向量相加后再输入MLP内进行更新，这样就可以用到点的邻接关系了。<em>类似于卷积操作，但是这里的卷积权重均为1，且每次卷积就是对于每个点进行求和</em></li><li>那我们考虑，能不能把边的信息也纳入其中？所以可以首先把顶点的向量传入边，然后再把边的信息传入点。</li><li>但是到现在都没有用到全局信息，为了使用全局信息，我们会加入一个master node(context vector)，这就是U，其与所有边和点相连。所以在更新点与边的时候，会利用到U；同时，在更新U的时候也会使用边与点的信息。</li></ol><h1 id="Playground"><a href="#Playground" class="headerlink" title="Playground"></a>Playground</h1><p><a href="https://distill.pub/2021/gnn-intro/">A Gentle Introduction to GNN</a></p><hr><p>Cover image icon by <a href="https://www.flaticon.com/authors/becris" title="Becris">Becris</a> from <a href="https://www.flaticon.com/free-icons/deep-learning" title="deep learning icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>因果推断初步——反因果框架</title>
      <link href="/2025/05/10/CausalInferenceIntro/"/>
      <url>/2025/05/10/CausalInferenceIntro/</url>
      
        <content type="html"><![CDATA[<p>在这篇文章中，你将会了解到：什么是bias，为什么我们在研究中存在bias，以及如何消除bias。<br>We sometimes call the potential outcome that happened, factual, and the one that didn’t happen, counterfactual.<br>$Y_{0i}$ is the <strong>potential</strong> outcome for unit i without treatment, it can also be written as $Y_{i}(0)$<br>$Y_{1i}$ is the <strong>potential</strong> outcome for unit i with treatment, it can also be written as $Y_{i}(1)$<br>we define the <strong>individual effect</strong> as $Y_{1i}-Y_{0i}$ , which can not be accumulated for the counterfactual. so we can only accumulate <strong>Average treatment effect</strong> which is also denoted as <strong>ATE</strong>:<br>$$ATE &#x3D; E[Y_{1}-Y_{0}]$$<br>we can also estimate <strong>Average treatment effect on the treated</strong> which is also called <strong>ATT</strong><br>$$ATT&#x3D;E[Y_{1}-Y_{0}|T&#x3D;1]$$</p><h1 id="Bias"><a href="#Bias" class="headerlink" title="Bias"></a>Bias</h1><p>$$\begin{aligned}<br>E[Y|T&#x3D;1]-E[Y|T&#x3D;0]&amp;&#x3D;E[Y_{1}|T&#x3D;1]-E[Y_{0}|T&#x3D;0]<br>\\&amp;&#x3D;E[Y_{1}|T&#x3D;1]-E[Y_{0}|T&#x3D;0] + E[Y_{0}|T&#x3D;1] - E[Y_{0}|T&#x3D;1]<br>\\&amp;&#x3D;E[Y_{1}-Y_{0}|T&#x3D;1]+E[Y_{0}|T&#x3D;1]-E[Y_{0}|T&#x3D;0]<br>\end{aligned}$$<br>以上公式中，前者为ATT也就是我们所希望估计的, 后者为Bias<br>也就是说相关性&#x3D;ATT+Bias。<br>if $E[Y_{0}|T&#x3D;1]&#x3D;E[Y_{0}|T&#x3D;0]$<br>then <strong>assosiation &#x3D; causation</strong><br>furthermore, if we assume that the untreated and the treated only differ in the treatment itself, we can conclude that:<br>$$E[Y|T&#x3D;1]-E[Y|T&#x3D;0]&#x3D;E[Y_{1}-Y_{0}|T&#x3D;0]&#x3D;E[Y_{1}-Y_{0}|T&#x3D;1]$$<br>which means <strong>ATT&#x3D;ATE</strong><br>To eliminate bias, we should <strong>Randomized Trial</strong></p><hr><p>Thanks for watching! and this my learning note of the blog of <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>.<br>感谢观看，这是我学习<a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>博客的笔记。<br>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 因果推断 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 因果推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循证医学9-12周回顾</title>
      <link href="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="非参数检验"><a href="#非参数检验" class="headerlink" title="非参数检验"></a>非参数检验</h1><h2 id="非参数检验的适应条件"><a href="#非参数检验的适应条件" class="headerlink" title="非参数检验的适应条件"></a>非参数检验的适应条件</h2><ol><li>等级顺序资料</li><li>偏态资料</li><li>未知分布资料</li><li>各组资料的变异度大，方差不齐，变换也不能达到齐性</li><li>数据一端或两端有不确定值的资料</li><li>初步分析<br><em>可以举几个例子：1. 不满足参数检验的要求；2. 血糖水平高于最高值会显示high</em></li></ol><h2 id="非参数检验的缺点"><a href="#非参数检验的缺点" class="headerlink" title="非参数检验的缺点"></a>非参数检验的缺点</h2><p>容易出现第II类错误，即假阴性概率增大，本应显示出显著性差异的结果但是却并没有出现显著性差异。</p><h2 id="两组配对设计资料的比较"><a href="#两组配对设计资料的比较" class="headerlink" title="两组配对设计资料的比较"></a>两组配对设计资料的比较</h2><p>Wilcoxon符号秩和检验</p><ol><li>符号检验</li><li>配对设计差值的符号秩检验：其实就是对差值进行符号检验</li></ol><h2 id="单样本资料的符号秩和检验"><a href="#单样本资料的符号秩和检验" class="headerlink" title="单样本资料的符号秩和检验"></a>单样本资料的符号秩和检验</h2><p>Wilcoxon符号秩和检验。对标单样本正态检验</p><h2 id="成组设计两样本比较的秩和检验"><a href="#成组设计两样本比较的秩和检验" class="headerlink" title="成组设计两样本比较的秩和检验"></a>成组设计两样本比较的秩和检验</h2><p>Wilcoxon秩和检验</p><h2 id="成组设计多个样本比较的秩和检验"><a href="#成组设计多个样本比较的秩和检验" class="headerlink" title="成组设计多个样本比较的秩和检验"></a>成组设计多个样本比较的秩和检验</h2><p>Kruskal Wallis H检验</p><h3 id="原始数据的多个样本比较"><a href="#原始数据的多个样本比较" class="headerlink" title="原始数据的多个样本比较"></a>原始数据的多个样本比较</h3><p>对标参数检验中的ANOVA，用于揭示多组数据的中位数是否完全相同</p><h3 id="多个样本两两比较的秩和检验"><a href="#多个样本两两比较的秩和检验" class="headerlink" title="多个样本两两比较的秩和检验"></a>多个样本两两比较的秩和检验</h3><p>对标参数检验中的SNK-Q, LSD-T检验</p><h1 id="回归与相关"><a href="#回归与相关" class="headerlink" title="回归与相关"></a>回归与相关</h1><p>回归与相关并不相同，从概念上讲，相关其实是一种双重映射，而回归是单射。从直觉上讲，相关其实是一个相对模糊的概念，并不具有因果性，而回归其实是显示出一种简单的因果性：是自变量的改变会导致因变量改变程度的一种反映。</p><h2 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h2><h3 id="回归方程"><a href="#回归方程" class="headerlink" title="回归方程"></a>回归方程</h3><p>$$Y &#x3D; \alpha +\beta X + \epsilon$$<br>$\alpha$：回归直线的截距<br>$\beta$：回归直线的斜率，又称为回归系数<br>$\epsilon$：误差项，在线性回归中我们认为其满足均值为0，方差为1的假设，所以在完成线性回归后我们将会对其进行残差检验，以研究其是否满足我们的前提。</p><h3 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h3><h4 id="F检验"><a href="#F检验" class="headerlink" title="F检验"></a>F检验</h4>$$\begin{aligned}\sum(Y-\bar{Y})^2 &= \sum((\hat{Y}- \bar{Y}) + (Y - \hat{Y}))^2 \\&=\sum(\hat{Y} - \hat{Y})^2 + \sum(Y - \hat{Y})^2\end{aligned}$$<p>$Y$：真实值<br>$\hat{Y}$：预测值<br>$\bar{Y}$：均值</p>$$F = \frac{MS_{回归}}{MS_{误差}}=\frac{\frac{SS_{回归}}{\nu_{回归}}}{\frac{SS_{误差}}{\nu_{误差}}}$$<p>其中$\nu_{总}&#x3D;n-1, \nu_{回归} &#x3D; 1, \nu_{误差} &#x3D; n-2$</p><h4 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h4><p>回归系数的区间估计</p>$$b \pm t_{\frac{\alpha}{2},n-2}S_{b}, S_{b}=\sqrt{ \frac{MS_{误差}}{l_{XX}} }$$<p>均值的区间估计</p>$$\hat{Y}\pm t_{\frac{\alpha}{2},n-2}S_{\hat{Y}}, S_{\hat{Y}}=S_{YX}\sqrt{ \frac{1}{n} + \frac{(X_{0}-\hat{X})^2}{\sum(X-\bar{X})^2}}$$<p>其中$l_{XX}=\sum(X-\bar{X})^2, S_{YX}=\sqrt{ \frac{\sum(Y-\hat{Y})^2}{n-2} }=\sqrt{ \frac{SS_{剩}}{n-2} }$<br>个体Y值的容许区间</p>$$\hat{Y}\pm t_{\frac{\alpha}{2},n-2}S_{Y}, S_{Y}=S_{YX}\sqrt{ 1 + \frac{1}{n} + \frac{(X_{0}-\hat{X})^2}{\sum(X-\bar{X})^2}}$$<h3 id="残差分析"><a href="#残差分析" class="headerlink" title="残差分析"></a>残差分析</h3><p>线性回归模型满足以下四个前提要求：线性、独立、正态性、等方差。<br>这里线性的条件很容易理解；对于独立的条件，其实就是为了避免样本之间的相关性，例如我们要研究药物浓度与时间的关系，但是样本中存在相同人的不同时间的样本，那可能会出现该人的某个时间段的检查数值与之前某个时间的检查数值相关。那么我们在进行回归的时候会发现，如果前一个时间段浓度高，该时间段浓度也会高。也就意味着，有一部分的误差并不能通过对于时间的回归来解释，这里我们需要使用<strong>时间序列分析</strong>以最大化对于不同时间段相同人的数据的利用率。<br>正态性与等方差性则是进行线性回归的前提，如果不满足则优化的方法其实是有问题的。<br>为了验证以上4个前提，我们常使用残差分析。<br>残差分析我们可以认为是<strong>线性回归的粪便检查</strong>，线性回归完成后我们需要研究<strong>回归后还剩下什么</strong>，残差就是回归后的边角料，如果边角料中存在很明显的趋势，那我们就不能丢弃这一部分的数据，我们仍然需要进一步挖掘。而这一趋势其实就是数据不满足以上线性回归四前提的实际体现。所以也可以认为，线性回归的能力(消化能力)其实并不强，一但数据复杂度增高(消化难度增加)，就难以继续使用线性回归挖掘数据(消化并吸收营养)，所以需要进行残差回归以确定线性回归可以充分利用该数据。</p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>线性回归不能外推、要有实际意义、<strong>要先绘图</strong>(非常重要，这是线性回归乃至后面的时间序列分析、断点回归、样条插值的必需前提)、要假设检验(应该不会有人忘记，因为软件自动进行)</p><h2 id="相关"><a href="#相关" class="headerlink" title="相关"></a>相关</h2>$$r = \frac{\sum(X-\bar{X})(Y-\bar{Y})}{\sqrt{ \sum(X - \bar{X})^2\sum(Y-\bar{Y})^2 }}=\frac{l_{XY}}{\sqrt{ l_{XX}l_{YY} }}$$<p>大部分类似于回归</p><h2 id="秩相关"><a href="#秩相关" class="headerlink" title="秩相关"></a>秩相关</h2><p>适用于：不满足双变量正态分布、总体分布未知、等级表示的原始数据</p><h2 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h2><p>类似于线性回归</p><h2 id="筛选自变量"><a href="#筛选自变量" class="headerlink" title="筛选自变量"></a>筛选自变量</h2><p>后退法、前进法、逐步法<br>这里筛选自变量其实还有一个很重要的原因，就是可能原来不显著的结果在筛选变量后变得显著。</p><h1 id="重复测量资料的方差分析"><a href="#重复测量资料的方差分析" class="headerlink" title="重复测量资料的方差分析"></a>重复测量资料的方差分析</h1><p>重复测量实验能不能进行普通的成组检验(参数或非参数)？答案是否定的，因为不管是参数与非参数检验均需要保证样本之间的独立性和随机性，但是重复测量的数据一定有相关性。<br>为了避免时间因素，所以需要同时考虑分组与重复测量的时间点.</p><h2 id="随机区组设计方差分析法"><a href="#随机区组设计方差分析法" class="headerlink" title="随机区组设计方差分析法"></a>随机区组设计方差分析法</h2><p>前提：满足“球对称”假设</p><h3 id="重复测量数据的两因素两水平分析"><a href="#重复测量数据的两因素两水平分析" class="headerlink" title="重复测量数据的两因素两水平分析"></a>重复测量数据的两因素两水平分析</h3><p>当前后差值不满足方差齐性时。进行重复测量设计方差分析，分析表的阅读方式与之前的随机区组设计类似。</p><h3 id="两因素多水平重复测定资料的方差分析"><a href="#两因素多水平重复测定资料的方差分析" class="headerlink" title="两因素多水平重复测定资料的方差分析"></a>两因素多水平重复测定资料的方差分析</h3><p>进行重复测量设计方差分析，分析表的阅读方式与之前的随机区组设计类似。</p><h1 id="实验设计"><a href="#实验设计" class="headerlink" title="实验设计"></a>实验设计</h1><h2 id="交叉设计"><a href="#交叉设计" class="headerlink" title="交叉设计"></a>交叉设计</h2><p>分组同时需要分为2阶段，不同阶段进行不同处理。<br>前提：需要满足无延后效应</p><h2 id="拉丁方设计"><a href="#拉丁方设计" class="headerlink" title="拉丁方设计"></a>拉丁方设计</h2><p>通过拉丁字母组成方阵，在同一行或同一列内没有重复的字母。<br>这样你就会发现，在每个时间段每种处理方式都有1个样本。</p><h2 id="正交设计"><a href="#正交设计" class="headerlink" title="正交设计"></a>正交设计</h2><h3 id="表头设计"><a href="#表头设计" class="headerlink" title="表头设计"></a>表头设计</h3><p><img src="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_8.png" alt="picForEvibased_8" title="picForEvibased_8"><br>设计流程如下：</p><ol><li>如果我们希望研究的是每个因子的2阶交互因子。</li><li>将A，B放在1，2列内。</li><li>对于$A \times B$我们查看A,B因子所处的列1，2列，查交互作用表中1行2列，得到3。所以将$A \times B$放于第3列，</li><li>将C放在第4列，研究$A \times C$，我们查看1行4列得到第5列，将其放置在第5列。</li></ol><h1 id="生存时间资料分析"><a href="#生存时间资料分析" class="headerlink" title="生存时间资料分析"></a>生存时间资料分析</h1><h2 id="生存资料的特点"><a href="#生存资料的特点" class="headerlink" title="生存资料的特点"></a>生存资料的特点</h2><ol><li>存在删失值(如何处理？)</li><li>效应变量有2种</li><li>分布类型复杂</li></ol><h3 id="小样本生存率的K-M估计"><a href="#小样本生存率的K-M估计" class="headerlink" title="小样本生存率的K-M估计"></a>小样本生存率的K-M估计</h3><p>删失值不纳入死亡率的计算。</p><h3 id="大样本生存率的寿命表法估计"><a href="#大样本生存率的寿命表法估计" class="headerlink" title="大样本生存率的寿命表法估计"></a>大样本生存率的寿命表法估计</h3><p>删失人员只作为半个人。</p><h3 id="log-rank检验"><a href="#log-rank检验" class="headerlink" title="log-rank检验"></a>log-rank检验</h3><p>用于检验2组人群生存率是否存在差异性</p><h3 id="Cox风险比例模型"><a href="#Cox风险比例模型" class="headerlink" title="Cox风险比例模型"></a>Cox风险比例模型</h3><p>可以研究不同协变量对于生存率的影响</p><p>非参数检验的流程<br><img src="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/%E9%9D%9E%E5%8F%82%E6%95%B0%E6%A3%80%E9%AA%8C.drawio.png" alt="非参数检验" title="非参数检验"><br>生存分析的流程<br><img src="/2025/05/10/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A69-12%E5%91%A8%E5%9B%9E%E9%A1%BE/%E7%94%9F%E5%AD%98%E5%88%86%E6%9E%90.drawio.png" alt="生存分析" title="生存分析"></p><hr><p>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CLIP</title>
      <link href="/2025/05/08/CLIP/"/>
      <url>/2025/05/08/CLIP/</url>
      
        <content type="html"><![CDATA[<p>CLIP将计算机视觉与自然语言处理相结合，获得更加优秀的迁移性能与zero-shot效果。同时打破了固定标签的定式。</p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>针对目前已有的计算机视觉系统，大部分都是使用固定的标签集合，这限制了它的泛化性能和可用性。<br>于是作者选择通过图片的语言文本来进行图像识别。作者爬取了4亿张图片以进行模型的预训练。在预训练完成后，作者在30多个任务上进行了测试。<br>在ImageNet数据集内，CLIP模型在zero-shot的情况下便已经与训练完成的Resnet50打成平手。</p><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>GPT作为一个”Text-in-text-out”的经典案例，反映了弱监督工作的可行性，于是作者决定提出使用图片与文字结合，进行CLIP模型的研究。<br>已有相关研究VirTex, ICMLM和ConVIRT方法虽然接近，但是数据集规模较少，而有些弱监督模型的准确率较高，其依赖的是极度大量数据集，所以作者考虑到是否能够同时满足以上条件，进而研究出新的方法。在预实验结果中，使用已有模型(ConVIRT)与新的数据，其模型在zero-shot上成功体现出极好的效果。同时<strong>模型效果与模型大小呈现正相关</strong>。</p><h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>作者发现目前已有数据集不能满足训练需求，所以选择自己开发数据集。</p><h2 id="Pre-Training-Method"><a href="#Pre-Training-Method" class="headerlink" title="Pre-Training Method"></a>Pre-Training Method</h2><p>作者针对该数据的标签，决定使用“图像-文本配对”的方法来进行训练，这是因为如果采用标签生成或者词袋模型，训练过程较慢。<br>同时作者也采用对比学习的方法进行训练。<br>作者在训练过程中其实是发现了两个重要的事情。</p><h3 id="非线性映射"><a href="#非线性映射" class="headerlink" title="非线性映射"></a>非线性映射</h3><p>CLIP（Contrastive Language–Image Pre-training）在其两个编码器（图像编码器与文本编码器）末端各插入了一个 <strong>线性映射</strong>（linear projection）层，将各自的表示向量映射到同一多模态嵌入空间，以便计算余弦相似度并进行对比损失优化。在早期的对比或自监督学习框架（如 SimCLR、MoCo 等）中，人们常使用 <strong>非线性映射头</strong>（two-layer MLP + ReLU + BN）来获得更好的特征表示；而 CLIP 的作者发现，去掉这层非线性映射，仅保留简单的线性映射，训练效率与效果几乎无差异，因此选择了更为简洁的设计。</p><h3 id="未出现过拟合"><a href="#未出现过拟合" class="headerlink" title="未出现过拟合"></a>未出现过拟合</h3><p>作者在训练过程中未出现过拟合。<em>其实挺好理解的，这么大的数据集能过拟合也是神人了</em><br>作者对于数据的处理也仅仅只有裁剪，而并未采用更多的高级方法。作者对于温度系数 $t$ 也仅仅只是进行</p><h2 id="Choosing-and-Scaling-the-Model"><a href="#Choosing-and-Scaling-the-Model" class="headerlink" title="Choosing and Scaling the Model"></a>Choosing and Scaling the Model</h2><h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">image_encoder: Resnet or Vision Transformer</span><br><span class="line">text_encoder: CBOW or Text Transformer</span><br><span class="line">I: n * h * w * c, minibatch of aligned images</span><br><span class="line">T: n * l, minibatch of aligned texts</span><br><span class="line">t: learned temperature parameter</span><br><span class="line"></span><br><span class="line"># extract feature representations of each modality</span><br><span class="line">I_f = image_encoder(I) #[n, d_i]</span><br><span class="line">T_f = text_encoder(T) #[n, d_t]</span><br><span class="line"></span><br><span class="line"># joint multimodal embedding [n, d_e]</span><br><span class="line"># linear projectin</span><br><span class="line"># 这里是多模态常见的合成方法</span><br><span class="line">I_e = l2_normalize(np.dot(I_f, W_i), axis = 1)</span><br><span class="line">T_e = l2_normalize(np.dot(T_f, W_t), axis = 1)</span><br><span class="line"></span><br><span class="line"># scaled pairwise cosine similarities</span><br><span class="line">logits = np.dot(I_e, T_e.T) * np.exp(t)</span><br><span class="line"></span><br><span class="line"># symmetric loss function</span><br><span class="line"># 这里的正样本是对角线上的数据，也就是第一排第一个，第二排第二个。这里对比学习的思路。</span><br><span class="line">labels  = np.arrang(n)</span><br><span class="line">loss_i = cross_entropy_loss(logits, labels, aixs = 0)</span><br><span class="line">loss_t = cross_entropy_loss(logits, labels, aixs = 1)</span><br><span class="line">loss = (loss_i + loss_t)/2</span><br></pre></td></tr></table></figure><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>作者训练了5个ResNets和3个Vision Transformers<br>ResNet: ResNet-50, ResNet-101, EfficientNet-style model 4x, 16x and 64x the compute of a ResNet-50<br>Vision Transformer: ViT-B&#x2F;32 Vit-B&#x2F;16 ViT-L&#x2F;14<br>训练32个epoch，Adam优化器<br>作者对于ViT-L&#x2F;14在336像素的图片上又额外训练了一个epoch，并将其标注为ViT-L&#x2F;14@336px. 后面使用的模型均为ViT-L&#x2F;14@336px</p><h1 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h1><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p><img src="/2025/05/08/CLIP/CLIP_inference.png" alt="CLIP_inference" title="CLIP_inference"></p><ol><li>通过Prompt Engineering构造选项(备选方案如plane, car, dog -&gt; A photo of plane, car, dog)经过Text Encoder计算为向量。</li><li>将图片经过Encoder转化为图像，计算图像与词向量的余弦相似度</li></ol><h3 id="Prompt-Engineering-and-Ensembling"><a href="#Prompt-Engineering-and-Ensembling" class="headerlink" title="Prompt Engineering and Ensembling"></a>Prompt Engineering and Ensembling</h3><p>作者在该段提出了：多义性(polysemy)和标签多为短句的问题。并对于这两种问题，其提出使用提示词模板来解决，例如模板”A photo of a {label}”. 该方法提升准确率1.3%<br>同时，对于特定数据集，可以将模型进一步扩充，如对于Oxford-IIIT Pets, 则可将模板改为”A photo of a {label}, a type of pets”.</p><h3 id="效果分析"><a href="#效果分析" class="headerlink" title="效果分析"></a>效果分析</h3><ol><li>CLIP(zero-shot) vs linear probe Resnet50: 对于有具体物体的模型CLIP表现更佳，而抽象概念的数据则相对较差(如数字、纹理)。</li><li>CLIP vs previous few-shot method: 远超既往小样本学习结果。CLIP在zero-shot的情况下，准确率已经和BiT-M的16-shot的效果相近。但是在部分few-shot上CLIP反而不如自己的zero-shot。</li><li>CLIP使用linear probe效果，全数据集训练效果依旧强劲。</li></ol><h1 id="Comparison-to-Human-Performance"><a href="#Comparison-to-Human-Performance" class="headerlink" title="Comparison to Human Performance"></a>Comparison to Human Performance</h1><p><img src="/2025/05/08/CLIP/Comparison_to_human.png" alt="Comparison_to_human" title="Comparison_to_human"></p><h1 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h1><ol><li>距离已有模型的SOTA有较大距离，只是优于ResNet50的Baseline.</li><li>CLIP对于部分数据的效果不佳，比如细分类的数据集、抽象概念的数据(数字、异常提取)。</li><li>对于数据分布偏差极大的数据集，效果依旧较差。例如MNIST数据集效果较差，作者分析是因为400M图片中均无MNIST类似的图片。</li><li>CLIP不是生成式模型，仍然需要提供一些选项。</li><li>CLIP模型对于数据的应用并不高效。</li><li>希望能够产生一种新的，针对Zero-shot的数据集。</li><li>数据并无清洗，可能存在偏见。</li><li>CLIP在few-shot的情况下并不如zero-shot优秀。</li></ol><hr><p>Cover image icon by <a href="https://www.flaticon.com/authors/becris" title="Becris">Becris</a> from <a href="https://www.flaticon.com/free-icons/deep-learning" title="deep learning icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Propensity Score</title>
      <link href="/2025/05/06/Propensity-Score/"/>
      <url>/2025/05/06/Propensity-Score/</url>
      
        <content type="html"><![CDATA[<p>The propensity score makes it so that you don’t have to condition on the entirety of X to achieve independence of the potential outcomes on the treatment. It is sufficient to condition on this single variable, which is the propensity score<br>$$(Y_{0},Y_{1}) \perp T|e(x)$$<br><em>The propensity score is the conditional probability of receiving the treatment, right? So we can think of it as some sort of function that converts X into the treatment T. The propensity score makes this middle ground between the variable X and the treatment T. If we show this in a causal graph, this is what it would look like.</em><br><img src="/2025/05/06/Propensity-Score/casual_7.png" alt="casual_7" title="casual_7"></p><h1 id="law-of-iterated-expectations"><a href="#law-of-iterated-expectations" class="headerlink" title="law of iterated expectations"></a><strong>law of iterated expectations</strong></h1><p>$$E[X]&#x3D;E[E[X|Y]]$$<br><em>Proof</em></p>$$\begin{aligned}E[E[Y|X]]&=\int_{-\infty}^\infty\int_{-\infty}^\infty yp_{Y|X}(y|x)p_{X}(x)dydx\\\\&=\int_{-\infty}^\infty\int_{-\infty}^\infty yp(x,y)dydx\\\\&=\int_{-\infty}^\infty y\int_{-\infty}^\infty p(x,y)dxdy\\\\&=\int_{-\infty}^\infty yp_{Y}(y)dy\\\\&=E[Y]\end{aligned}$$<p>具体内容参考<a href="https://www.zhihu.com/question/22996373/answer/3274277491">统计学基础</a><br> 其实我们可以看出，所谓$e(x)$就是$E[T|X]$也就是情形X下收到treatment的概率<br> $$E[T|e(x)]&#x3D;E[E[T|e(x),X]|e(x)]&#x3D;E[e(x)|e(x)]&#x3D;e(x)$$<br>其中$E[T|e(x),X]&#x3D;E[T|X]&#x3D;e(x)$</p><h1 id="Inverse-Probability-of-Treatment-Weighting-IPTW"><a href="#Inverse-Probability-of-Treatment-Weighting-IPTW" class="headerlink" title="Inverse Probability of Treatment Weighting (IPTW)"></a>Inverse Probability of Treatment Weighting (IPTW)</h1>$$E[Y|X,T=1]-E[Y|X,T=0]=E\left[ \frac{Y}{e(x)}|X,T=1 \right]P(T)-E\left[ \frac{Y}{1-e(x)}|X,T=0 \right](1-P(T))$$<p>直观上理解就是本来应该不被治疗的样本如果接受了治疗，那这个样本在分析的过程中会更加有价值<br>我们可以将其化简为$$E\left[ Y\frac{{T-e(x)}}{e(x)(1-e(x))} \right]$$<br><em>Proof</em></p>$$\begin{aligned}E[Y|X,T=1]-E[Y|X,T=0]&=E\left[ \frac{Y}{e(x)}|X,T=1 \right]P(T)-E\left[ \frac{Y}{1-e(x)}|X,T=0 \right](1-P(T))\\\\&=E\left[ \frac{{YT}}{e(x)}\bigg|X \right]-E\left[ \frac{Y(1-T)}{1-e(x)}\bigg|X \right]\\\\&=E\left[ \frac{YT(1-e(x))}{e(x)(1-e(x))}-\frac{Y(1-T)e(x)}{e(x)(1-e(x))} \bigg| X\right]\\\\&=E\left[ Y\frac{{T-e(x)}}{e(x)(1-e(x))} \bigg | X\right ]\end{aligned}$$<p><strong>positivity assumption</strong> of causal inference: Notice that this estimator requires that $e(x)$ and $1−e(x)$ are larger than zero. In words, this means that everyone needs to have at least some chance of receiving the treatment and of not receiving it. Another way of stating this is that the treated and untreated distributions need to overlap.</p><h1 id="Propensity-Score-Estimation"><a href="#Propensity-Score-Estimation" class="headerlink" title="Propensity Score Estimation"></a>Propensity Score Estimation</h1><p>代码见<a href="https://matheusfacure.github.io/python-causality-handbook/11-Propensity-Score.html">11 - Propensity Score — Causal Inference for the Brave and True</a></p><h1 id="Standard-Error"><a href="#Standard-Error" class="headerlink" title="Standard Error"></a>Standard Error</h1><p>首先考虑加权平均的方差$$\sigma^2_{w}&#x3D;\frac{\sum_{i&#x3D;1}^nw_{i}(y_{i}-\hat{\mu})^2}{\sum_{i&#x3D;1}^nw_{i}}$$<br>However, we can only use this if we have the true propensity score. If we are using the estimated version of it, $\hat{P}(x)$, we need to account for the errors in this estimation process. The easiest way of doing this is by bootstrapping the whole procedure. This is achieved by sampling with replacement from the original data and computing the ATE like we did above. We then repeat this many times to get the distribution of the ATE estimate.</p><h1 id="Common-Issues-with-Propensity-Score"><a href="#Common-Issues-with-Propensity-Score" class="headerlink" title="Common Issues with Propensity Score"></a>Common Issues with Propensity Score</h1><p><strong>Propensity score doesn’t need to predict the treatment very well. It just needs to include all the confounding variables</strong>.<br><em>To see this, consider the following example (adapted from Hernán’s Book). You have 2 schools, one of them apply the growth mindset seminar to 99% of its students and the other to 1%. Suppose that the schools have no impact on the treatment effect (except through the treatment), so it’s not necessary to control for it. If you add the school variable to the propensity score model, it’s going to have a very high predictive power. However, by chance, we could end up with a sample where everyone in school A got the treatment, leading to a propensity score of 1 for that school, which would lead to an infinite variance. This is an extreme example, but let’s see how it would work with simulated data.</em><br>其实就是当treatment和non treatment组之间特征没有过多的重叠时，对于接近0.5的概率附近样本较少，这会让方差增大<strong>This lack of balancing can generate some bias, because we will have to extrapolate the treatment effect to unknown regions.As a general rule of thumb, you are in trouble if any weight is higher than 20 (which happens with an untreated with propensity score of 0.95 or a treated with a propensity score of 0.05).</strong><br><strong>if the distributions don’t overlap, your data is probably not enough to make a causal conclusion anyway. To gain some further intuition about this, we can look at a technique that combines propensity score and matching</strong><br><img src="/2025/05/06/Propensity-Score/casual_8.png" alt="casual_8" title="casual_8"></p><h1 id="Propensity-Score-Matching"><a href="#Propensity-Score-Matching" class="headerlink" title="Propensity Score Matching"></a>Propensity Score Matching</h1><p>就是针对Propensity Score进行一次matching，从这个角度看，Propensity Score其实就是一种维度压缩，而我们就是再计算经过维度压缩后的特征的matching<br>值得注意的是，倾向性评分匹配并不适合bootstrap以估计SE[ON THE FAILURE OF THE BOOTSTRAP FOR MATCHING ESTIMATORS](<a href="https://economics.mit.edu/sites/default/files/publications/ON%20THE%20FAILURE%20OF%20THE%20BOOTSTRAP%20FOR.pdf">On the Failure of the Bootstrap for Matching Estimators</a>)</p><hr><p>Thanks for watching! and this my learning note of the blog of <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>.<br>感谢观看，这是我学习<a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>博客的笔记。<br>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 因果推断 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 因果推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Stats Review</title>
      <link href="/2025/05/06/Stats-Review/"/>
      <url>/2025/05/06/Stats-Review/</url>
      
        <content type="html"><![CDATA[<blockquote><p><em>“Some equations are dangerous if you know them, and others are dangerous if you do not. The first category may pose danger because the secrets within its bounds open doors behind which lies terrible peril. The obvious winner in this is Einstein’s iconic equation $E&#x3D;mc^2$, for it provides a measure of the enormous energy hidden within ordinary matter. […] Instead I am interested in equations that unleash their danger not when we know about them, but rather when we do not. Kept close at hand, these equations allow us to understand things clearly, but their absence leaves us dangerously ignorant.”</em></p></blockquote><p align="right">——Howard Wainer</p># Moivre’s equation$$SE=\frac{\sigma}{\sqrt{ n }}$$SE: standard error; $\sigma$: standard deviation; n: sample sizeeg: fewer students $\neq$ better eduacation, sometimes just **Greater SE**<p><img src="/2025/05/06/Stats-Review/casual_1.png" alt="casual_1" title="casual_1"></p><p>As Taleb puts it in his book, Fooled by Randomness:</p><blockquote><p>Probability is not a mere computation of odds on the dice or more complicated variants; it is the acceptance of the lack of certainty in our knowledge and the development of methods for dealing with our ignorance.</p></blockquote><h1 id="Standard-Error-of-Our-Estimates"><a href="#Standard-Error-of-Our-Estimates" class="headerlink" title="Standard Error of Our Estimates"></a>Standard Error of Our Estimates</h1><p>first calculate standard deviation:<br>$$\hat{\sigma}&#x3D;\sqrt{ \frac{1}{N-1}\sum^N_{i&#x3D;1}(x_{i}-\bar{x})^2 }$$<br>$$SE&#x3D;\frac{\sigma}{\sqrt{ n }}$$</p><h1 id="Confidence-Intervals"><a href="#Confidence-Intervals" class="headerlink" title="Confidence Intervals"></a>Confidence Intervals</h1><p>To calculate the confidence interval, we use the <strong>central limit theorem</strong>. This theorem states that <strong>means of experiments are normally distributed</strong>. From statistical theory, we know that 95% of the mass of a normal distribution is between 2 standard deviations above and below the mean. Technically, 1.96, but 2 is close enough.<br>The Standard Error of the mean serves as our estimate of the distribution of the experiment means. So, if we multiply it by 2 and add and subtract it from the mean of one of our experiments, we will construct a 95% confidence interval for the true mean.<br>你提到的这个观点其实非常重要，关于信赖区间（Confidence Interval，简称CI）的解释确实有一些常见误解。在频率统计学中，信赖区间并不是直接描述“某个特定区间包含真实均值的概率”，而是描述了通过重复实验或样本抽取，使用相同的统计方法计算出的区间包含真实参数的频率。<br>具体来说，95%置信区间的解释是：如果你在同样的条件下进行很多次独立的实验，每次计算置信区间，那么有95%的置信区间会包含真实的总体参数（例如，均值）。但这并不意味着某一个特定的区间有95%的概率包含真实值，因为真实值要么在这个区间内，要么不在。<br>为了更清晰地理解，可以举个例子：<br>假设我们进行100次相同的实验，每次都计算一个95%的置信区间。假如有95次的区间包含了真实的总体均值，而5次不包含，那么我们可以说：我们的统计方法是可靠的，95%的信赖区间会包含真实的均值。但对于单个实验的结果，我们不能说“这个区间有95%的概率包含真实均值”。<br>简而言之，CI是描述统计方法的长期表现，而不是对某个具体实验结果的概率评估。</p><h1 id="Hypothesis-Testing"><a href="#Hypothesis-Testing" class="headerlink" title="Hypothesis Testing"></a>Hypothesis Testing</h1><p>$$\mathcal{N}(\mu_{1}, \sigma_{1}^2)+\mathcal N(\mu_{2}, \sigma_{2}^2)&#x3D;\mathcal{N}(\mu_{1}+\mu_{2}, \sigma^2_{1}+\sigma_{2}^2)$$<br>$$\mathcal{N}(\mu_{1}, \sigma_{1}^2)-\mathcal N(\mu_{2}, \sigma_{2}^2)&#x3D;\mathcal{N}(\mu_{1}-\mu_{2}, \sigma^2_{1}+\sigma_{2}^2)$$<br>And the same for SE<br>$$\begin{aligned}<br>&amp;\mu_{diff} &#x3D; \mu_{1} - \mu_{2}<br>\\<br>&amp;SE_{diff} &#x3D; \sqrt{ SE_{1}^2+ SE_{2}^2 }&#x3D;\sqrt{ \frac{\sigma_{1}^2}{N_{1}} + \frac{\sigma_{2}^2}{N_{2}} }<br>\end{aligned}$$</p><h2 id="z-statistic"><a href="#z-statistic" class="headerlink" title="z-statistic"></a>z-statistic</h2>$$\begin{aligned}z &=\frac{{\mu_{diff}-H_{0}}}{SE}\\\\&=\frac{{\mu_{1}-\mu_{2}-H_{0}}}{\sqrt{ \frac{\sigma_{1}^2}{N_{1}} + \frac{\sigma_{2}^2}{N_{2}} }}\end{aligned}$$<p>The z statistic is a measure of how extreme the observed difference is. We will use contradiction to test our hypothesis that the difference in the means is statistically different from zero. We will assume that the opposite is true; we will assume that the difference is zero. This is called a <strong>null hypothesis</strong>, or $H_{0}$ .<br>Under $H_{0}$, the z statistic follows a standard normal distribution. So, if the difference is indeed zero, we would see the z statistic within 2 standard deviations of the mean 95% of the time. The direct consequence is that if z falls above or below 2 standard deviations, we can reject the null hypothesis with 95% confidence.<br><strong>To specify, $H_{0}$ stands for $\mu_{1}-\mu_{2}$, which is always 0</strong><br><strong>z-statistic</strong>（z统计量）在假设检验中通常用于检验两个样本均值之间的差异，尤其是在满足某些条件下，比如样本量较大（通常n &gt; 30）或者总体标准差已知的情况下。z检验常见的应用有：</p><ol><li><strong>单样本z检验</strong>：用于检验一个样本的均值是否与已知的总体均值有显著差异。<ul><li>例如，假设你想检验某个工厂生产的产品的平均重量是否等于标称值。</li></ul></li><li><strong>两样本z检验</strong>：用于检验两个独立样本的均值是否有显著差异。<ul><li>例如，你想比较两个不同工厂生产的产品的平均重量是否相同。</li></ul></li><li><strong>z检验的条件</strong>：通常要求已知总体标准差，或者样本量足够大以使得样本标准差可以较好地估计总体标准差。这个条件也可以通过<strong>中心极限定理</strong>来理解，即大样本的分布趋近于正态分布。</li></ol><h1 id="P-value"><a href="#P-value" class="headerlink" title="P-value"></a>P-value</h1><p><strong>the p-value is the probability of obtaining test results at least as extreme as the results actually observed during the test, assuming that the null hypothesis is correct</strong><br>P值是假设零假设成立的前提下，获取至少与实验结果一样极端的数据的概率<br>It measures how unlikely it is that you are seeing a measurement if the null hypothesis is true. Naturally, this often gets confused with the probability of the null hypothesis being true. Note the difference here. The p-value is NOT $P(H_{0}|data)$, but rather $P(data|H_{0})$.<br>也就是说，P-value不是说给定数据的前提下，$H_{0}$成立的概率，而是假设$H_{0}$成立的前提下，获得该数据的概率<br><img src="/2025/05/06/Stats-Review/casual_2.png" alt="casual_2" title="casual_2"><br>以上为单边检验，此外还有双边检验，<strong>双边检验</strong>关注参数是否偏离某个值，无论偏离的方向是增大还是减小。双边检验相较于单边更加难以显著，这是因为双边同时需要考虑两边的偏差，而单边只需要考虑一边的偏差，也就意味着单边其实已经有了一个前提，也就是我们已知偏差会位于左侧(或者右侧)，正是这个已知的事实减少了样本空间的大小，让概率升高。</p><h2 id="双边检验的必要性"><a href="#双边检验的必要性" class="headerlink" title="双边检验的必要性"></a><strong>双边检验的必要性</strong></h2><h3 id="a-无法预知偏离的方向时"><a href="#a-无法预知偏离的方向时" class="headerlink" title="a. 无法预知偏离的方向时"></a><strong>a. 无法预知偏离的方向时</strong></h3><ul><li>如果没有足够的理论依据或先验知识来预测偏差的方向，双边检验是<strong>唯一合理的选择</strong>。在这种情况下，使用单边检验可能导致忽视另一个方向上的潜在效应。</li></ul><h3 id="b-安全性和准确性考虑"><a href="#b-安全性和准确性考虑" class="headerlink" title="b. 安全性和准确性考虑"></a><strong>b. 安全性和准确性考虑</strong></h3><ul><li>在医学、工程和其他关键领域，错误地选择单边检验可能会导致过度自信或误判。尤其在某些实验中，我们无法确保效应的方向，如果单边检验的假设方向错误，可能会导致严重的后果。例如，药物效果的测试，如果只假设药物会增强效果而忽视了副作用，可能会导致对副作用的忽视。</li></ul><h3 id="c-多假设检验中的一致性"><a href="#c-多假设检验中的一致性" class="headerlink" title="c. 多假设检验中的一致性"></a><strong>c. 多假设检验中的一致性</strong></h3><ul><li>在某些复杂的多假设检验场景中，使用双边检验可以保持检验的一致性。例如，分析基因表达时，如果我们事先不知道某个基因是否会上调或下调，双边检验可以确保我们对上调和下调的效应都进行充分检验。</li></ul><hr><p>Thanks for watching! and this my learning note of the blog of <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>.<br>感谢观看，这是我学习<a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>博客的笔记。<br>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 因果推断 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 因果推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Beyond Confounders</title>
      <link href="/2025/05/06/Beyond-Confounders/"/>
      <url>/2025/05/06/Beyond-Confounders/</url>
      
        <content type="html"><![CDATA[<h1 id="Good-Control"><a href="#Good-Control" class="headerlink" title="Good Control"></a>Good Control</h1><p>Sometimes treatment’s effect on the outcome is much smaller than other factors, in order to figure out the effect of treatment, we should control other factors because:<br><strong>If a variable is a good predictor of the outcome, it will explain away a lot of its variance.</strong><br>To demonstrate this, let’s resort to the partialling out way of breaking regression into 2 steps.<br>First, we will regress the treatment, email, and the outcome, payments, on the additional controls, credit limit and risk score.<br>Second, we will regress the residual of the treatment on the residuals of payments, both obtained in step 1. (This is purely pedagogical, in practice you won’t need to go through all the hassle).<br>To wrap it up, anytime we have a control that is a good predictor of the outcome, even if it is not a confounder, adding it to our model is a good idea. It helps lowering the variance of our treatment effect estimates. Here is a picture of what this situation looks like with causal graphs.<br><img src="/2025/05/06/Beyond-Confounders/casual_4.png" alt="casual_4" title="causal_4"></p><p>其实这里与我们之前将confounder针对treatment回归的有相似之处又有不同之处：<br>之前将confounder针对treatment的回归主要依赖于confounder同时对treatment和outcome有影响，所以我们需要打断confounder的路径，造成随机化的情况。<br>而这里的factor其实并非confounder，这里是由于多种因素同时存在造成的“大数吃小数”的情况，所以需要将factor对outcome回归后，在将残差对于treatment回归。</p><h1 id="Bad-Control"><a href="#Bad-Control" class="headerlink" title="Bad Control"></a>Bad Control</h1><p>we should <strong>NOT</strong> add controls that are just good predictors of the treatment, because they will increase the variance of our estimates.<br>控制与treatment强相关的因素将会导致treatment的分组不均匀，从而提高variance，进而导致结果的不显著。</p><h2 id="Selection-Bias"><a href="#Selection-Bias" class="headerlink" title="Selection Bias"></a>Selection Bias</h2><p><strong>selection bias is when we control for a common effect or a variable in between the path from cause to effect.</strong>(参考[[Graph Casual Model]]中的Selection Bias)<br>Here is some examples:</p><ol><li>Adding a dummy for paying the entire debt when trying to estimate the effect of a collections strategy on payments.</li><li>Controlling for white vs blue collar jobs when trying to estimate the effect of schooling on earnings</li><li>Controlling for conversion when estimating the impact of interest rates on loan duration</li><li>Controlling for marital happiness when estimating the impact of children on extramarital affairs</li><li>Breaking up payments modeling E[Payments] into one binary model that predict if payment will happen and another model that predict how much payment will happen given that some will: E[Payments|Payments&gt;0]*P(Payments&gt;0)</li></ol><h2 id="COP-A-special-case-of-Selection-Bias"><a href="#COP-A-special-case-of-Selection-Bias" class="headerlink" title="COP: A special case of Selection Bias"></a>COP: A special case of Selection Bias</h2><p>这个问题来自与一个常见的问题：如果遇到0，是否要将其舍去，其实这个问题就是针对舍去0的模型：<br>我们在针对一些相对稀疏的outcome进行推断时，常常倾向于删去0值，但是这样会导致我们舍去了一部分正常为0的数据，以基因表达为例；<br>如果我们对于某群体给予某种药物，则必然有一部分基因在大部分情况下均不表达，这时有人提出：为什么我们不只看那部分表达的个体在治疗前后的基因表达改变的情况。<br>但是，这个想法是错误的！<br>直观上讲，就是我们大可以将群体分为2群，一群是在药物治疗后基因表达增加，而这个群体本身就有基因表达；二群是在药物治疗后基因表达从0到1，这个群体本身无基因表达。如果我们简单去掉0数据，则可能带来：二群的治疗前的数据的丢失。最后在研究因果效应时会导致因果效应偏小。<br>理论上推导如下：</p>$$\begin{aligned}&E[Y|T=1]-E[Y|T=0]\\\\=&E[Y|Y>0,T=1]P(Y>0|T=1)+E[Y|Y>0,T=0]P(Y>0|T=0)(删去E[Y|Y=0])\\\\=&(P(Y>0|T=1)-P(Y>0|T=0))E[Y|Y>0,T=1]\\\\+&(E[Y|Y>0,T=1]-E[Y|Y>0,T=0])P(Y>0|T=0)\end{aligned}$$<p>上式子中，前者代表“Participation Effect”，及治疗前后值从0到1的改变情情况，即一群的预期效益；后者则代表”COP”，即治疗前后增加的基因表达数量，即二群的预期效益<br>数学上完全正确，问题出在估计$E[Y|Y&gt;0|T&#x3D;1]-E[Y|Y&gt;0|T&#x3D;0]$过程中</p>$$\begin{aligned}&E[Y|Y>0,T=1]-E[Y|Y>0,T=0]\\\\=&E[Y_{1}|Y_{1}>0]-E[Y_{0}|Y_{0}>0]\\\\=&E[Y_{1}-Y_{0}|Y_{1}>0] + (E[Y_{0}|Y_{1}>0]-E[Y_{0}|Y_{0}>0]) \end{aligned}$$<p>这就是我们常见的bias公式，我们可以看到，前面的那个估计正确，但是后面可能会出现bias，也就是说$E[Y_{0}|Y_{1}&gt;0]&lt;E[Y_{0}|Y_{0}&gt;0]$, 因为会有部分$Y_{0}&#x3D;0$的情况被排除。<br><img src="/2025/05/06/Beyond-Confounders/casual_5.png" alt="casual_5" title="casual_5"><br><strong>注意：上式子我们需要求得的是$E[Y_{1}-Y_{0}|Y_{1}&gt;0]$，其中$E[Y|T&#x3D;1]-E[Y|T&#x3D;0]$，是我们观察到的数据，主要问题就是我们在计算过程中可能会把$E[Y_{0}|Y_{1}&gt;0]-E[Y_{0}|Y_{0}&gt;0]$所忽视</strong><br><em>这里的思路类似于[[mathematic&#x2F;Casual inference&#x2F;Introduction]]中的思路，就是计算ATT，但是我们加了个前提就是要大于0，大于0就让无法ATT的转化无法正常进行，因为这使得引入了新的bias，很奇妙吧，虽然过程不同，但是最后归于公式的时候却是相同的</em><br>相当有趣的是这里我们依旧可以用Selection Bias解释，这是因为治疗与否影响了基因表达是否大于0，同时outcome也对基因表达是否大于0有影响，构成了一个Collider，一旦控制，就会带来Selection Bias.</p><hr><p>Thanks for watching! and this my learning note of the blog of <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>.<br>感谢观看，这是我学习<a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html#">Matheus Facure Alves</a>博客的笔记。<br>Cover image icon by <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Dewi Sari</a> from <a href="https://www.flaticon.com/free-icons/inference" title="inference icons">Flaticon</a></p>]]></content>
      
      
      <categories>
          
          <category> 因果推断 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 因果推断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循证医学7-8周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="二项分布与poisson分布及其应用"><a href="#二项分布与poisson分布及其应用" class="headerlink" title="二项分布与poisson分布及其应用"></a>二项分布与poisson分布及其应用</h1><h2 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h2>$$P(X) = C^x_{n} \pi^x (1-\pi)^{n-x}$$$$\mu = n\pi, \sigma^2={ n\pi(1-\pi) }$$<p>样本率的方差计算同正态分布时的均值的方差计算：<br>$$S_{p}&#x3D;\sqrt{ \frac{p(1-p)}{n} }$$<br>总体率置信区间计算：</p><ol><li>查表方法</li><li>正态近似法(样本容量&gt;100, $\pi \approx 0.5$)</li></ol>$$\begin{aligned}u &= \frac{{p-\pi_{0}}}{\sigma_{p}} \\\sigma_{p} &= \sqrt{ \frac{\pi_{0}(1-\pi_{0})}{n} }\end{aligned}$$*既往死亡率为40%，实验中120名病人死亡30名，统计推断：H_0: 均值不等H_1: 均值相等确定alpha值为0.05，双尾检验*$$\begin{aligned}\sigma_{p}&=\sqrt{ \frac{\pi_{0}(1-\pi_{0})}{n} }\\&=\sqrt{ \frac{0.4(1-0.4)}{120} }\\&\approx 0.045\\u&=\frac{{p-\pi_{0}}}{\sigma_{p}}\\&=\frac{{\frac{30}{120} - 0.4}}{0.045}\\&=-3.333\end{aligned}$$<p><em>显著：拒绝H_0，因为超过了3个标准差</em></p><h2 id="Poisson分布"><a href="#Poisson分布" class="headerlink" title="Poisson分布"></a>Poisson分布</h2><p>$$P(X)&#x3D; \frac{\lambda^x}{x!}e^{-\lambda}, X&#x3D;0,1,2,\dots$$<br>$$\mu&#x3D;\lambda, \sigma^2&#x3D;\lambda$$<br>总体率置信区间计算：</p><ol><li>查表方法</li><li>正态近似法($\mu \approx 0.5$)<br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_6.png" alt="分布间关系" title="分布间关系"></li></ol><h1 id="RR值和OR值的估计"><a href="#RR值和OR值的估计" class="headerlink" title="RR值和OR值的估计"></a>RR值和OR值的估计</h1><p>RR值适用于：队列研究(risk ratio)<br>OR值适用于：病例对照研究(odds ratio)</p><table><thead><tr><th>指标</th><th>全称</th><th>定义</th><th>适用研究</th></tr></thead><tbody><tr><td><strong>RR</strong></td><td>相对危险度（Relative Risk）</td><td>暴露组患病概率 &#x2F; 非暴露组患病概率</td><td><strong>队列研究</strong>（可以“跟踪”发病）</td></tr><tr><td><strong>OR</strong></td><td>比值比（Odds Ratio）</td><td>病例组的暴露几率 &#x2F; 对照组的暴露几率</td><td><strong>病例对照研究</strong>（不能计算发病率）</td></tr></tbody></table><h3 id="为何适用于不同研究类型？"><a href="#为何适用于不同研究类型？" class="headerlink" title="为何适用于不同研究类型？"></a>为何适用于不同研究类型？</h3><h4 id="队列研究-→-RR"><a href="#队列研究-→-RR" class="headerlink" title="队列研究 → RR"></a>队列研究 → <strong>RR</strong></h4><ul><li>从“暴露”开始观察，<strong>可以</strong>得到真正的“发病概率”。</li><li>所以可以直接算：<br>  $$RR &#x3D; \frac{P(\text{发病}|\text{暴露})}{P(\text{发病}|\text{非暴露})}$$​</li></ul><h4 id="病例对照研究-→-OR"><a href="#病例对照研究-→-OR" class="headerlink" title="病例对照研究 → OR"></a>病例对照研究 → <strong>OR</strong></h4><ul><li>从“疾病状态”出发选人（先有病例和对照），<strong>无法</strong>算发病率。</li><li>只能算暴露与非暴露的“比值”：<br>  $$OR &#x3D; \frac{\text{病例组中暴露&#x2F;非暴露}}{\text{对照组中暴露&#x2F;非暴露}}$$</li></ul><h4 id="生存分析-→-HR-harzard-ratio"><a href="#生存分析-→-HR-harzard-ratio" class="headerlink" title="生存分析 → HR(harzard ratio)"></a>生存分析 → <strong>HR(harzard ratio)</strong></h4><ul><li><p><strong>定义</strong>：HR 衡量暴露组相对于非暴露组在 <strong>随时间变化的事件发生速率</strong>（例如生存分析中的死亡率、疾病发生率等）的比率。它通常用于 <strong>生存分析</strong>，尤其是 <strong>Cox比例风险模型</strong> 中。</p></li><li><p><strong>计算方法</strong>：HR 基于时间的事件发生风险计算，可以理解为暴露组和非暴露组在单位时间内发生事件的风险比：<br>  $$HR &#x3D; \frac{\text{暴露组事件发生率}}{\text{非暴露组事件发生率}}$$</p><p>  它考虑了随时间推移的风险，而不仅仅是单纯的事件发生与否。</p></li></ul><h4 id="举个例子"><a href="#举个例子" class="headerlink" title="举个例子"></a>举个例子</h4><table><thead><tr><th></th><th>发病</th><th>未发病</th><th>总计</th></tr></thead><tbody><tr><td>暴露组</td><td>30</td><td>70</td><td>100</td></tr><tr><td>非暴露组</td><td>10</td><td>90</td><td>100</td></tr><tr><td>总计</td><td>40</td><td>160</td><td>200</td></tr></tbody></table>$$\begin{aligned}RR &= \frac{\frac{30}{100}}{\frac{10}{100}}=3 \\OR &= \frac{\frac{30}{10}}{\frac{70}{90}}=3.86\end{aligned}$$<p>口诀： <strong>“RR 看未来，OR 看过去”</strong></p><ul><li>RR 是“先暴露后观察结果” → 队列研究</li><li>OR 是“先有病例找原因” → 病例对照</li></ul><h1 id="卡方检验"><a href="#卡方检验" class="headerlink" title="卡方检验"></a>卡方检验</h1><p>理论频数的计算：</p><table><thead><tr><th></th><th>有效</th><th>无效</th><th>总数</th><th>概率</th></tr></thead><tbody><tr><td>A组</td><td>68(74*87.59%)</td><td>6</td><td>74</td><td>91.89%</td></tr><tr><td>B组</td><td>52</td><td>11</td><td>63</td><td>82.54%</td></tr><tr><td>总计</td><td>120</td><td>17</td><td>137</td><td>87.59%</td></tr></tbody></table><p>普通卡方：$n\geq40, E\geq5$<br>连续性校正卡方：$n\geq40, 1\leq E\leq5$<br>Fisher确切检验：$n\leq40$ 或 $E\leq {1}$</p><p><em>例题：15只4只发生癌变，对照组10只0只癌变</em></p><table><thead><tr><th></th><th>癌变</th><th>未癌变</th></tr></thead><tbody><tr><td>暴露组</td><td>4</td><td>11</td></tr><tr><td>非暴露组</td><td>0</td><td>10</td></tr></tbody></table><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_7.png" alt="卡方检验实例" title="卡方检验实例"></p><h2 id="配对卡方检验"><a href="#配对卡方检验" class="headerlink" title="配对卡方检验"></a>配对卡方检验</h2><h2 id="行列表卡方检验"><a href="#行列表卡方检验" class="headerlink" title="行列表卡方检验"></a>行列表卡方检验</h2><ol><li>多个率的比较</li><li>率的多重比较</li><li>多个构成比的比较</li><li>两种属性关联性检验</li></ol><h1 id="多种R-times-C表资料统计分析方法"><a href="#多种R-times-C表资料统计分析方法" class="headerlink" title="多种R $\times$ C表资料统计分析方法"></a>多种R $\times$ C表资料统计分析方法</h1><h2 id="卡方检验-1"><a href="#卡方检验-1" class="headerlink" title="卡方检验"></a>卡方检验</h2><ol><li>双向无序</li><li>单向有序：组别有序、结果无序</li></ol><h2 id="秩和检验"><a href="#秩和检验" class="headerlink" title="秩和检验"></a>秩和检验</h2><ol><li>单向有序：组别无序、结果有序</li></ol><h1 id="拟合优度的卡方检验"><a href="#拟合优度的卡方检验" class="headerlink" title="拟合优度的卡方检验"></a>拟合优度的卡方检验</h1><ol><li>单变量</li><li>二项分布</li><li>Poisson分布</li></ol><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A67-8%E5%91%A8%E5%9B%9E%E9%A1%BE/%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C.png" alt="卡方检验" title="卡方检验"></p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循证医学5-6周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="ANOVA"><a href="#ANOVA" class="headerlink" title="ANOVA"></a>ANOVA</h1><p>多组样本均数比较</p><h1 id="多重比较"><a href="#多重比较" class="headerlink" title="多重比较"></a>多重比较</h1><p>SNK-Q, Dunnet-t, LSD-t检验，其中SNK-q最难显著，LSD-t最容易显著<br>SNK-q: 任意两组进行均数的比较<br>Dunnet-t: k-1个实验组与一个对照组的比较<br>LSD-t: 特定几组的比较</p><h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>正态分布<br>方差齐性<br>Bartlett检验： 服从正态分布<br>Levene检验：服从任意分布</p><h1 id="双向方差分析"><a href="#双向方差分析" class="headerlink" title="双向方差分析"></a>双向方差分析</h1><p><em>方差分析不等于分析方差，方差分析分析均数</em><br>类似于ANOVA,仅可以做到比较多组是否全部相同。</p><h1 id="析因设计的方差分析"><a href="#析因设计的方差分析" class="headerlink" title="析因设计的方差分析"></a>析因设计的方差分析</h1><p>先确定有无交互效应<br>若无交互效应则进行主效应分析<br>若有交互效应则进行单独效应分析</p><p><em>F&amp;Q: 老师上课所使用的单变量回归该如何理解？单变量回归的作用是不是就是将不同正态分布的总体拉到同一基线上？</em><br>对于析因设计的方差检验，由于数据内部存在多组正态分布，导致数据总体不满足正态分布，所以需要分析其拟合后残差是否满足正态性与方差齐性<br>$$<br>\begin{aligned}<br>Y &#x3D; \beta_{0} + \beta_{1} X_{1} + \beta_{2}X_{2}<br>\end{aligned}$$<br>如果$X_{1}$: 肝脏&#x3D;0，心脏&#x3D;1；$X_{2}$: 15min&#x3D;0，60min&#x3D;1；$Y$: 药物浓度<br>如果我们研究不同时间的药物浓度是否相同:<br>$$<br>\begin{aligned}<br>Y &#x3D; \beta_{0} + \beta_{2}X_{2}\<br>Y - \beta_{1} &#x3D; \beta_{0}+\beta_{2}X_{2}<br>\end{aligned}$$<br>上面第一个式子是肝脏的药物浓度、第二个式子是心脏的药物浓度，但是我们给心脏的药物浓度做了个”修正”, 这个时候两数据的均值其实就”对齐”了</p><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/%E5%8F%82%E6%95%B0%E6%A3%80%E9%AA%8C.png" alt="参数检验" title="参数检验"></p><h1 id="二项分布"><a href="#二项分布" class="headerlink" title="二项分布"></a>二项分布</h1><blockquote><p>如果我们的数据不满足正态分布，而是满足二项分布，那我们该如何进行分析？</p></blockquote><h1 id="广义线性模型"><a href="#广义线性模型" class="headerlink" title="广义线性模型"></a>广义线性模型</h1><p><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A65-6%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_5.png" alt="logistic regression" title="logistic regression"></p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>循证医学3-4周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A63-4%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A63-4%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h1><ol><li>检验的对象：抽样样本的均值，均值分布满足正态分布、抽样所得样本不一定满足正态分布</li><li>从正态分布——u分布——t分布(方差未知时用，<em><strong>大部分时候</strong></em>)</li><li>可信区间的计算(CI)：依赖于标准正态分布$\mathcal{N}(0,1)$ ,双边检验和单边检验的区分<br>变换方法：<br>$$\begin{aligned}<br>X \sim \mathcal{N}(\mu, \sigma^2)\\<br>X-\mu \sim \mathcal{N}(0, \sigma^2)\\<br>\frac{X-\mu}{\sigma} \sim \mathcal{N}(0, 1)<br>\end{aligned}<br>$$</li></ol><h1 id="两组均数比较的参数检验"><a href="#两组均数比较的参数检验" class="headerlink" title="两组均数比较的参数检验"></a>两组均数比较的参数检验</h1><h2 id="单样本t检验"><a href="#单样本t检验" class="headerlink" title="单样本t检验"></a>单样本t检验</h2><p>和已知的均值比较。<br>假设我检测的样本均值为$\bar{X} \sim \mathcal{N}(\mu_{1}, \frac{\sigma_{1}^2}{n})$，总体均值为常数$\mu_{2}$，然后我们对这两个作差得到:<br>$$\bar{X}-\mu_{2}\sim \mathcal{N}(\mu_{1}-\mu_{2}, \frac{\sigma_{1}^2}{n})$$<br>我希望的是：证明作差得到的分布是一个均值为0的分布，这样就可以证明两个样本均值和总体均值是没有差别的。<br>所以，假设以上均值为0，然后计算出现以上事件的概率。</p><h2 id="配对设计"><a href="#配对设计" class="headerlink" title="配对设计"></a>配对设计</h2><p>这里是配对样本的差值作为上面单样本检验的样本数据</p><h2 id="两总体均数比较"><a href="#两总体均数比较" class="headerlink" title="两总体均数比较"></a>两总体均数比较</h2><p>两样本均数满足$$\begin{aligned}<br>\bar{X_{1}} \sim \mathcal{N}\left( \mu_{1}, \frac{\sigma_{1}^2}{n_{1}} \right)\\<br>\bar{X_{2}} \sim \mathcal{N}\left( \mu_{2}, \frac{\sigma_{2}^2}{n_{2}} \right)<br>\end{aligned}<br>$$<br>作差得到, 随机变量计算公式：<br>$$\bar{X_{1}}-\bar{X_{2}} \sim \mathcal{N}\left( \mu_{1} - \mu_{2}, \frac{\sigma_{1}^2}{n_{1}} + \frac{\sigma_{2}^2}{n_{2}}\right)$$<br>假设上面公式均值为0，计算概率<br>因为总体方差未知，所以用S代替$\sigma$</p><h2 id="方差齐性"><a href="#方差齐性" class="headerlink" title="方差齐性"></a><em><strong>方差齐性</strong></em></h2><p>我们所做的工作都是针对均值，所以不妨假设方差相同，因为不相同，那显然不是两个相同总体<br>但是在使用该前提的时候需要证明方差相同。<br>使用的证明方法就是F检验，F分布就是两个正态分布的比值<br>$$F&#x3D;\frac{\frac{\sum_{i&#x3D;1}^{n_{1}}X_{i}^2}{n_{1}}}{\frac{\sum_{i&#x3D;1}^{n_{2}}Y_{i}^2}{n_{2}}}$$<br>其中，$X_{i}$和$Y_{i}$均为来自标准正态分布的样本，则称统计量F满足F分布<br>$$F \sim F(n_{1},n_{2})$$<br>方差之比遵从F分布，计算方差之比在假设两方差相同的情况下出现的概率。<br><strong>有趣的是，后面我们计算多组均数的方差分析中，也是使用的F分布，那个时候我们做出的假设是——组内方差&#x3D;组间方差</strong></p><h1 id="LASSO"><a href="#LASSO" class="headerlink" title="LASSO"></a>LASSO</h1><p><em>文献例子: Development and validation of a model to predict cognitive impairment in traumatic brain injury patients: a prospective observational study</em><br>“Variable selection was conducted via the least absolute shrinkage and selection operator (LASSO) method. Independent variables with nonzero coefficients in the LASSO regression model were selected and subsequently analyzed via multivariate logistic regression (P &lt; 0.05) to identify potential predictive factors.”</p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第一篇文章</title>
      <link href="/2025/05/06/2025-5-6/"/>
      <url>/2025/05/06/2025-5-6/</url>
      
        <content type="html"><![CDATA[<h2 id="这是我的第一篇文章"><a href="#这是我的第一篇文章" class="headerlink" title="这是我的第一篇文章"></a>这是我的第一篇文章</h2><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="title function_">alert</span>(<span class="string">&#x27;Hello World!&#x27;</span>);</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>循证医学1-2周回顾</title>
      <link href="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/"/>
      <url>/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/</url>
      
        <content type="html"><![CDATA[<p>第一周的主要内容其实就是意识到概率论和数理统计之间的关系</p><h1 id="统计学中的基本概念"><a href="#统计学中的基本概念" class="headerlink" title="统计学中的基本概念"></a>统计学中的基本概念</h1><h2 id="PPT-1"><a href="#PPT-1" class="headerlink" title="PPT-1"></a>PPT-1</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>总体——参数——$\mu, \sigma$<br>样本——统计量——$\bar{X}, \bar{Y}$<br>同质性与异质性<br><strong>抽样误差(sampling error)</strong></p><p>计量资料——有序<br>计数资料——有序<br>等级资料——无序</p><h3 id="因果与联系："><a href="#因果与联系：" class="headerlink" title="因果与联系："></a>因果与联系：</h3><p>金字塔顶端RCT研究，RCT是揭示事物因果关系最重要的方法，但是由于价格原因，大部分时间只能使用他的替代方案。</p><h3 id="抽样误差的有趣知识SE"><a href="#抽样误差的有趣知识SE" class="headerlink" title="抽样误差的有趣知识SE"></a>抽样误差的有趣知识<strong>SE</strong></h3><p>为什么要有SE？<br>如下图所示，美国为了研究班级人数的多少和班级平均分的关系，他们发现分数高的是那些班级人数较少的班级，但事实上，只是因为班级人数过少导致SE增大带来的错误因果！<br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_4.png" alt="SE的解释" title="SE的解释"></p><h2 id="PPT-2"><a href="#PPT-2" class="headerlink" title="PPT-2"></a>PPT-2</h2><p>不同均数的适应情况，及为什么适应：</p><h3 id="算术均数"><a href="#算术均数" class="headerlink" title="算术均数"></a>算术均数</h3><p>算术均数适用于正态分布，因为算术均数其实是正态分布的通过<strong>极大似然估计</strong>得到的均值<br>$$P(x)&#x3D;\frac{1}{\sqrt{ 2\pi }\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$<br>$$\begin{aligned}<br>l(x_{1},x_{2},\dots,x_{n})&amp;&#x3D;\sum_{i&#x3D;1}^n \ln P(x_{i})\\<br>&amp;&#x3D;\sum_{i&#x3D;1}^n (\ln \frac{1}{\sqrt{ 2\pi }\sigma} + \ln e^{-\frac{(x_{i}-\mu)^2}{2\sigma^2}})\\<br>&amp;&#x3D;\sum_{i&#x3D;1}^n (\ln \frac{1}{\sqrt{ 2\pi }\sigma} -\frac{(x_{i}-\mu)^2}{2\sigma^2})<br>\end{aligned}$$<br>求使上式子最大的$\mu$<br>$$\frac{dl}{d\mu}&#x3D;\sum_{i&#x3D;1}^n \frac{x_{i}-\mu}{\sigma^2}&#x3D;0$$<br>so<br>$$\mu&#x3D;\frac{1}{n}\sum_{i&#x3D;1}^n x_{i}$$</p><h3 id="几何均数"><a href="#几何均数" class="headerlink" title="几何均数"></a>几何均数</h3><p>几何均数适用于<strong>对数转换后呈正态分布的资料</strong>，即右偏态<br><em><strong>存在部分数值特别大的</strong></em><br>为什么使用几何均数？<br>为什么能用累乘解释：<br><em>比如，某机械厂生产机器，设有毛坯、粗加工、精加工和装配4个连续作业的车间。某批产品其毛坯车间制品合格率为97%，接下来3个车间的合格率分别为93%、91%和87%，求产品的平均合格率。<br>产品的平均合格率受制于4个车间的坏品或损耗情况，由于是连续作业的车间，所以是在前者基础上变成了百分之多少的感觉，符合几何平均数的应用。<br>直接使用几何平均数的公式，计算得出：</em><br>$$G&#x3D;(0.97 \times 0.93 \times 0.91 \times 0.87)^{1&#x2F;4}&#x3D;0.9193$$</p><h3 id="中位数"><a href="#中位数" class="headerlink" title="中位数"></a>中位数</h3><p>$$M&#x3D;L_{M}+\frac{i_{M}}{f_{M}}\left( \frac{n}{2} -\sum f_{L}\right)$$<br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_2.png" alt="中位数" title="中位数"></p><h3 id="标准差"><a href="#标准差" class="headerlink" title="标准差"></a>标准差</h3><p>为什么会有一个$\sigma$和$S$<br>而且$S$下面的分母为$n-1$<br>这是因为在计算均数时已经消耗掉一个自由度，所以需要减去一个自由度。通俗的讲，均数其实是偏向于我们采样的数据，所以在计算方差时需要让除数小一点，这样让方差更大，更加接近真实方差。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>正态分布: 能使用<strong>算术均数</strong>和<strong>标准差</strong>描述<br>右偏态数据使用: <strong>几何均数</strong><br>所有分布都可以使用的: <strong>众数</strong>、<strong>四分位数间距</strong><br><img src="/2025/05/06/%E5%BE%AA%E8%AF%81%E5%8C%BB%E5%AD%A61-2%E5%91%A8%E5%9B%9E%E9%A1%BE/picForEvibased_3.png" alt="总结" title="总结"></p><hr>Cover image icon by <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Freepik</a> from <a href="https://www.flaticon.com/free-icons/epidemiology" title="epidemiology icons">Flaticon</a>]]></content>
      
      
      <categories>
          
          <category> 统计学与循证医学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 统计学 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
